<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Passes - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.80.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Passes/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>Passes</h1><p>This document describes the available MLIR passes and their contracts.</p><p><nav id=TableOfContents><ul><li><a href=#general-transformation-passes>General Transformation Passes</a><ul><li><a href=#-canonicalize-canonicalize-operations><code>-canonicalize</code>: Canonicalize operations</a></li><li><a href=#-control-flow-sink-sink-operations-into-conditional-blocks><code>-control-flow-sink</code>: Sink operations into conditional blocks</a></li><li><a href=#-cse-eliminate-common-sub-expressions><code>-cse</code>: Eliminate common sub-expressions</a></li><li><a href=#-inline-inline-function-calls><code>-inline</code>: Inline function calls</a></li><li><a href=#-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop><code>-loop-invariant-code-motion</code>: Hoist loop invariant instructions outside of the loop</a></li><li><a href=#-print-op-stats-print-statistics-of-operations><code>-print-op-stats</code>: Print statistics of operations</a></li><li><a href=#-sccp-sparse-conditional-constant-propagation><code>-sccp</code>: Sparse Conditional Constant Propagation</a></li><li><a href=#-snapshot-op-locations-generate-new-locations-from-the-current-ir><code>-snapshot-op-locations</code>: Generate new locations from the current IR</a></li><li><a href=#-strip-debuginfo-strip-debug-info-from-all-operations><code>-strip-debuginfo</code>: Strip debug info from all operations</a></li><li><a href=#-symbol-dce-eliminate-dead-symbols><code>-symbol-dce</code>: Eliminate dead symbols</a></li><li><a href=#-symbol-privatize-mark-symbols-private><code>-symbol-privatize</code>: Mark symbols private</a></li><li><a href=#-view-op-graph-print-graphviz-visualization-of-an-operation><code>-view-op-graph</code>: Print Graphviz visualization of an operation</a></li></ul></li><li><a href=#bufferization-passes>Bufferization Passes</a><ul><li><a href=#-buffer-deallocation-adds-all-required-dealloc-operations-for-all-allocations-in-the-input-program><code>-buffer-deallocation</code>: Adds all required dealloc operations for all allocations in the input program</a></li><li><a href=#-buffer-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-into-common-dominators-and-out-of-nested-regions><code>-buffer-hoisting</code>: Optimizes placement of allocation operations by moving them into common dominators and out of nested regions</a></li><li><a href=#-buffer-loop-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-out-of-loop-nests><code>-buffer-loop-hoisting</code>: Optimizes placement of allocation operations by moving them out of loop nests</a></li><li><a href=#-buffer-results-to-out-params-converts-memref-typed-function-results-to-out-params><code>-buffer-results-to-out-params</code>: Converts memref-typed function results to out-params</a></li><li><a href=#-finalizing-bufferize-finalize-a-partial-bufferization><code>-finalizing-bufferize</code>: Finalize a partial bufferization</a></li><li><a href=#-one-shot-bufferize-one-shot-bufferize><code>-one-shot-bufferize</code>: One-Shot Bufferize</a></li><li><a href=#-promote-buffers-to-stack-promotes-heap-based-allocations-to-automatically-managed-stack-based-allocations><code>-promote-buffers-to-stack</code>: Promotes heap-based allocations to automatically managed stack-based allocations</a></li></ul></li><li><a href=#conversion-passes>Conversion Passes</a><ul><li><a href=#-arm-neon-2d-to-intr-convert-arm-neon-structured-ops-to-intrinsics><code>-arm-neon-2d-to-intr</code>: Convert Arm NEON structured ops to intrinsics</a></li><li><a href=#-convert-affine-for-to-gpu-convert-top-level-affinefor-ops-to-gpu-kernels><code>-convert-affine-for-to-gpu</code>: Convert top-level AffineFor Ops to GPU kernels</a></li><li><a href=#-convert-arith-to-llvm-convert-arithmetic-dialect-to-llvm-dialect><code>-convert-arith-to-llvm</code>: Convert Arithmetic dialect to LLVM dialect</a></li><li><a href=#-convert-arith-to-spirv-convert-arithmetic-dialect-to-spir-v-dialect><code>-convert-arith-to-spirv</code>: Convert Arithmetic dialect to SPIR-V dialect</a></li><li><a href=#-convert-async-to-llvm-convert-the-operations-from-the-async-dialect-into-the-llvm-dialect><code>-convert-async-to-llvm</code>: Convert the operations from the async dialect into the LLVM dialect</a></li><li><a href=#-convert-bufferization-to-memref-convert-operations-from-the-bufferization-dialect-to-the-memref-dialect><code>-convert-bufferization-to-memref</code>: Convert operations from the Bufferization dialect to the MemRef dialect</a></li><li><a href=#-convert-cf-to-llvm-convert-controlflow-operations-to-the-llvm-dialect><code>-convert-cf-to-llvm</code>: Convert ControlFlow operations to the LLVM dialect</a></li><li><a href=#-convert-cf-to-spirv-convert-controlflow-dialect-to-spir-v-dialect><code>-convert-cf-to-spirv</code>: Convert ControlFlow dialect to SPIR-V dialect</a></li><li><a href=#-convert-complex-to-llvm-convert-complex-dialect-to-llvm-dialect><code>-convert-complex-to-llvm</code>: Convert Complex dialect to LLVM dialect</a></li><li><a href=#-convert-complex-to-standard-convert-complex-dialect-to-standard-dialect><code>-convert-complex-to-standard</code>: Convert Complex dialect to standard dialect</a></li><li><a href=#-convert-func-to-llvm-convert-from-the-func-dialect-to-the-llvm-dialect><code>-convert-func-to-llvm</code>: Convert from the Func dialect to the LLVM dialect</a></li><li><a href=#-convert-func-to-spirv-convert-func-dialect-to-spir-v-dialect><code>-convert-func-to-spirv</code>: Convert Func dialect to SPIR-V dialect</a></li><li><a href=#-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call><code>-convert-gpu-launch-to-vulkan-launch</code>: Convert gpu.launch_func to vulkanLaunch external call</a></li><li><a href=#-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations><code>-convert-gpu-to-nvvm</code>: Generate NVVM operations for gpu operations</a></li><li><a href=#-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations><code>-convert-gpu-to-rocdl</code>: Generate ROCDL operations for gpu operations</a></li><li><a href=#-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect><code>-convert-gpu-to-spirv</code>: Convert GPU dialect to SPIR-V dialect</a></li><li><a href=#-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect><code>-convert-linalg-to-llvm</code>: Convert the operations from the linalg dialect into the LLVM dialect</a></li><li><a href=#-convert-linalg-to-spirv-convert-linalg-dialect-to-spir-v-dialect><code>-convert-linalg-to-spirv</code>: Convert Linalg dialect to SPIR-V dialect</a></li><li><a href=#-convert-linalg-to-std-convert-the-operations-from-the-linalg-dialect-into-the-standard-dialect><code>-convert-linalg-to-std</code>: Convert the operations from the linalg dialect into the Standard dialect</a></li><li><a href=#-convert-math-to-libm-convert-math-dialect-to-libm-calls><code>-convert-math-to-libm</code>: Convert Math dialect to libm calls</a></li><li><a href=#-convert-math-to-llvm-convert-math-dialect-to-llvm-dialect><code>-convert-math-to-llvm</code>: Convert Math dialect to LLVM dialect</a></li><li><a href=#-convert-math-to-spirv-convert-math-dialect-to-spir-v-dialect><code>-convert-math-to-spirv</code>: Convert Math dialect to SPIR-V dialect</a></li><li><a href=#-convert-memref-to-llvm-convert-operations-from-the-memref-dialect-to-the-llvm-dialect><code>-convert-memref-to-llvm</code>: Convert operations from the MemRef dialect to the LLVM dialect</a></li><li><a href=#-convert-memref-to-spirv-convert-memref-dialect-to-spir-v-dialect><code>-convert-memref-to-spirv</code>: Convert MemRef dialect to SPIR-V dialect</a></li><li><a href=#-convert-nvgpu-to-nvvm-convert-nvgpu-dialect-to-nvvm-dialect><code>-convert-nvgpu-to-nvvm</code>: Convert NVGPU dialect to NVVM dialect</a></li><li><a href=#-convert-openacc-to-llvm-convert-the-openacc-ops-to-llvm-dialect><code>-convert-openacc-to-llvm</code>: Convert the OpenACC ops to LLVM dialect</a></li><li><a href=#-convert-openacc-to-scf-convert-the-openacc-ops-to-openacc-with-scf-dialect><code>-convert-openacc-to-scf</code>: Convert the OpenACC ops to OpenACC with SCF dialect</a></li><li><a href=#-convert-openmp-to-llvm-convert-the-openmp-ops-to-openmp-ops-with-llvm-dialect><code>-convert-openmp-to-llvm</code>: Convert the OpenMP ops to OpenMP ops with LLVM dialect</a></li><li><a href=#-convert-parallel-loops-to-gpu-convert-mapped-scfparallel-ops-to-gpu-launch-operations><code>-convert-parallel-loops-to-gpu</code>: Convert mapped scf.parallel ops to gpu launch operations</a></li><li><a href=#-convert-pdl-to-pdl-interp-convert-pdl-ops-to-pdl-interpreter-ops><code>-convert-pdl-to-pdl-interp</code>: Convert PDL ops to PDL interpreter ops</a></li><li><a href=#-convert-scf-to-cf-convert-scf-dialect-to-controlflow-dialect-replacing-structured-control-flow-with-a-cfg><code>-convert-scf-to-cf</code>: Convert SCF dialect to ControlFlow dialect, replacing structured control flow with a CFG</a></li><li><a href=#-convert-scf-to-openmp-convert-scf-parallel-loop-to-openmp-parallel--workshare-constructs><code>-convert-scf-to-openmp</code>: Convert SCF parallel loop to OpenMP parallel + workshare constructs.</a></li><li><a href=#-convert-scf-to-spirv-convert-scf-dialect-to-spir-v-dialect><code>-convert-scf-to-spirv</code>: Convert SCF dialect to SPIR-V dialect.</a></li><li><a href=#-convert-shape-constraints-convert-shape-constraint-operations-to-the-standard-dialect><code>-convert-shape-constraints</code>: Convert shape constraint operations to the standard dialect</a></li><li><a href=#-convert-shape-to-std-convert-operations-from-the-shape-dialect-into-the-standard-dialect><code>-convert-shape-to-std</code>: Convert operations from the shape dialect into the standard dialect</a></li><li><a href=#-convert-spirv-to-llvm-convert-spir-v-dialect-to-llvm-dialect><code>-convert-spirv-to-llvm</code>: Convert SPIR-V dialect to LLVM dialect</a></li><li><a href=#-convert-tensor-to-spirv-convert-tensor-dialect-to-spir-v-dialect><code>-convert-tensor-to-spirv</code>: Convert Tensor dialect to SPIR-V dialect</a></li><li><a href=#-convert-vector-to-gpu-lower-the-operations-from-the-vector-dialect-into-the-gpu-dialect><code>-convert-vector-to-gpu</code>: Lower the operations from the vector dialect into the GPU dialect</a></li><li><a href=#-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect><code>-convert-vector-to-llvm</code>: Lower the operations from the vector dialect into the LLVM dialect</a></li><li><a href=#-convert-vector-to-rocdl-lower-the-operations-from-the-vector-dialect-into-the-rocdl-dialect><code>-convert-vector-to-rocdl</code>: Lower the operations from the vector dialect into the ROCDL dialect</a></li><li><a href=#-convert-vector-to-scf-lower-the-operations-from-the-vector-dialect-into-the-scf-dialect><code>-convert-vector-to-scf</code>: Lower the operations from the vector dialect into the SCF dialect</a></li><li><a href=#-convert-vector-to-spirv-convert-vector-dialect-to-spir-v-dialect><code>-convert-vector-to-spirv</code>: Convert Vector dialect to SPIR-V dialect</a></li><li><a href=#-gpu-to-llvm-convert-gpu-dialect-to-llvm-dialect-with-gpu-runtime-calls><code>-gpu-to-llvm</code>: Convert GPU dialect to LLVM dialect with GPU runtime calls</a></li><li><a href=#-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls><code>-launch-func-to-vulkan</code>: Convert vulkanLaunch external call to Vulkan runtime external calls</a></li><li><a href=#-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-scf-operations><code>-lower-affine</code>: Lower Affine operations to a combination of Standard and SCF operations</a></li><li><a href=#-lower-host-to-llvm-lowers-the-host-module-code-and-gpulaunch_func-to-llvm><code>-lower-host-to-llvm</code>: Lowers the host module code and <code>gpu.launch_func</code> to LLVM</a></li><li><a href=#-reconcile-unrealized-casts-simplify-and-eliminate-unrealized-conversion-casts><code>-reconcile-unrealized-casts</code>: Simplify and eliminate unrealized conversion casts</a></li><li><a href=#-tosa-to-arith-lower-tosa-to-the-arith-dialect><code>-tosa-to-arith</code>: Lower TOSA to the Arith dialect</a></li><li><a href=#-tosa-to-linalg-lower-tosa-to-linalg-on-tensors><code>-tosa-to-linalg</code>: Lower TOSA to LinAlg on tensors</a></li><li><a href=#-tosa-to-linalg-named-lower-tosa-to-linalg-named-operations><code>-tosa-to-linalg-named</code>: Lower TOSA to LinAlg named operations</a></li><li><a href=#-tosa-to-scf-lower-tosa-to-the-scf-dialect><code>-tosa-to-scf</code>: Lower TOSA to the SCF dialect</a></li><li><a href=#-tosa-to-tensor-lower-tosa-to-the-tensor-dialect><code>-tosa-to-tensor</code>: Lower TOSA to the Tensor dialect</a></li></ul></li><li><a href=#async-dialect-passes><code>async</code> Dialect Passes</a><ul><li><a href=#-async-parallel-for-convert-scfparallel-operations-to-multiple-async-compute-ops-executed-concurrently-for-non-overlapping-iteration-ranges><code>-async-parallel-for</code>: Convert scf.parallel operations to multiple async compute ops executed concurrently for non-overlapping iteration ranges</a></li><li><a href=#-async-runtime-policy-based-ref-counting-policy-based-reference-counting-for-async-runtime-operations><code>-async-runtime-policy-based-ref-counting</code>: Policy based reference counting for Async runtime operations</a></li><li><a href=#-async-runtime-ref-counting-automatic-reference-counting-for-async-runtime-operations><code>-async-runtime-ref-counting</code>: Automatic reference counting for Async runtime operations</a></li><li><a href=#-async-runtime-ref-counting-opt-optimize-automatic-reference-counting-operations-for-theasync-runtime-by-removing-redundant-operations><code>-async-runtime-ref-counting-opt</code>: Optimize automatic reference counting operations for theAsync runtime by removing redundant operations</a></li><li><a href=#-async-to-async-runtime-lower-high-level-async-operations-eg-asyncexecute-to-theexplicit-asyncruntime-and-asynccoro-operations><code>-async-to-async-runtime</code>: Lower high level async operations (e.g. async.execute) to theexplicit async.runtime and async.coro operations</a></li></ul></li><li><a href=#affine-dialect-passes><code>affine</code> Dialect Passes</a><ul><li><a href=#-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations><code>-affine-data-copy-generate</code>: Generate explicit copying for affine memory operations</a></li><li><a href=#-affine-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop><code>-affine-loop-coalescing</code>: Coalesce nested loops with independent bounds into a single loop</a></li><li><a href=#-affine-loop-fusion-fuse-affine-loop-nests><code>-affine-loop-fusion</code>: Fuse affine loop nests</a></li><li><a href=#-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops><code>-affine-loop-invariant-code-motion</code>: Hoist loop invariant instructions outside of affine loops</a></li><li><a href=#-affine-loop-normalize-apply-normalization-transformations-to-affine-loop-like-ops><code>-affine-loop-normalize</code>: Apply normalization transformations to affine loop-like ops</a></li><li><a href=#-affine-loop-tile-tile-affine-loop-nests><code>-affine-loop-tile</code>: Tile affine loop nests</a></li><li><a href=#-affine-loop-unroll-unroll-affine-loops><code>-affine-loop-unroll</code>: Unroll affine loops</a></li><li><a href=#-affine-loop-unroll-jam-unroll-and-jam-affine-loops><code>-affine-loop-unroll-jam</code>: Unroll and jam affine loops</a></li><li><a href=#-affine-parallelize-convert-affinefor-ops-into-1-d-affineparallel><code>-affine-parallelize</code>: Convert affine.for ops into 1-D affine.parallel</a></li><li><a href=#-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy><code>-affine-pipeline-data-transfer</code>: Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy</a></li><li><a href=#-affine-scalrep-replace-affine-memref-acceses-by-scalars-by-forwarding-stores-to-loads-and-eliminating-redundant-loads><code>-affine-scalrep</code>: Replace affine memref acceses by scalars by forwarding stores to loads and eliminating redundant loads</a></li><li><a href=#-affine-simplify-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs><code>-affine-simplify-structures</code>: Simplify affine expressions in maps/sets and normalize memrefs</a></li><li><a href=#-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction><code>-affine-super-vectorize</code>: Vectorize to a target independent n-D vector abstraction</a></li></ul></li><li><a href=#arith-dialect-passes><code>arith</code> Dialect Passes</a><ul><li><a href=#-arith-bufferize-bufferize-arithmetic-dialect-ops><code>-arith-bufferize</code>: Bufferize Arithmetic dialect ops.</a></li><li><a href=#-arith-expand-legalize-arithmetic-ops-to-be-convertible-to-llvm><code>-arith-expand</code>: Legalize Arithmetic ops to be convertible to LLVM.</a></li></ul></li><li><a href=#func-dialect-passes><code>func</code> Dialect Passes</a><ul><li><a href=#-func-bufferize-bufferize-funccallreturn-ops><code>-func-bufferize</code>: Bufferize func/call/return ops</a></li></ul></li><li><a href=#gpu-dialect-passes><code>gpu</code> Dialect Passes</a><ul><li><a href=#-gpu-async-region-make-gpu-ops-async><code>-gpu-async-region</code>: Make GPU ops async</a></li><li><a href=#-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions><code>-gpu-kernel-outlining</code>: Outline gpu.launch bodies to kernel functions</a></li><li><a href=#-gpu-launch-sink-index-computations-sink-index-computations-into-gpulaunch-body><code>-gpu-launch-sink-index-computations</code>: Sink index computations into gpu.launch body</a></li></ul></li><li><a href=#linalg-dialect-passes><code>linalg</code> Dialect Passes</a><ul><li><a href=#-convert-elementwise-to-linalg-convert-elementwisemappable-ops-to-linalg><code>-convert-elementwise-to-linalg</code>: Convert ElementwiseMappable ops to linalg</a></li><li><a href=#-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops><code>-convert-linalg-to-affine-loops</code>: Lower the operations from the linalg dialect into affine loops</a></li><li><a href=#-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops><code>-convert-linalg-to-loops</code>: Lower the operations from the linalg dialect into loops</a></li><li><a href=#-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops><code>-convert-linalg-to-parallel-loops</code>: Lower the operations from the linalg dialect into parallel loops</a></li><li><a href=#-linalg-bufferize-bufferize-the-linalg-dialect><code>-linalg-bufferize</code>: Bufferize the linalg dialect</a></li><li><a href=#-linalg-detensorize-detensorize-linalg-ops><code>-linalg-detensorize</code>: Detensorize linalg ops</a></li><li><a href=#-linalg-eliminate-init-tensors-try-to-eliminate-all-init_tensor-ops><code>-linalg-eliminate-init-tensors</code>: Try to eliminate all init_tensor ops.</a></li><li><a href=#-linalg-fold-unit-extent-dims-remove-unit-extent-dimension-in-linalg-ops-on-tensors><code>-linalg-fold-unit-extent-dims</code>: Remove unit-extent dimension in Linalg ops on tensors</a></li><li><a href=#-linalg-fuse-elementwise-ops-fuse-elementwise-operations-on-tensors><code>-linalg-fuse-elementwise-ops</code>: Fuse elementwise operations on tensors</a></li><li><a href=#-linalg-generalize-named-ops-convert-named-ops-into-generic-ops><code>-linalg-generalize-named-ops</code>: Convert named ops into generic ops</a></li><li><a href=#-linalg-inline-scalar-operands-inline-scalar-operands-into-linalg-generic-ops><code>-linalg-inline-scalar-operands</code>: Inline scalar operands into linalg generic ops</a></li><li><a href=#-linalg-named-op-conversion-convert-from-one-named-linalg-op-to-another><code>-linalg-named-op-conversion</code>: Convert from one named linalg op to another.</a></li><li><a href=#-linalg-promote-subviews-promote-subview-ops-to-local-buffers><code>-linalg-promote-subviews</code>: Promote subview ops to local buffers</a></li><li><a href=#-linalg-strategy-decompose-pass-configurable-pass-to-apply-pattern-based-generalization><code>-linalg-strategy-decompose-pass</code>: Configurable pass to apply pattern-based generalization.</a></li><li><a href=#-linalg-strategy-enable-pass-configurable-pass-to-enable-the-application-of-other-pattern-based-linalg-passes><code>-linalg-strategy-enable-pass</code>: Configurable pass to enable the application of other pattern-based linalg passes.</a></li><li><a href=#-linalg-strategy-generalize-pass-configurable-pass-to-apply-pattern-based-generalization><code>-linalg-strategy-generalize-pass</code>: Configurable pass to apply pattern-based generalization.</a></li><li><a href=#-linalg-strategy-interchange-pass-configurable-pass-to-apply-pattern-based-iterator-interchange><code>-linalg-strategy-interchange-pass</code>: Configurable pass to apply pattern-based iterator interchange.</a></li><li><a href=#-linalg-strategy-lower-vectors-pass-configurable-pass-to-lower-vector-operations><code>-linalg-strategy-lower-vectors-pass</code>: Configurable pass to lower vector operations.</a></li><li><a href=#-linalg-strategy-pad-pass-configurable-pass-to-apply-padding-and-hoisting><code>-linalg-strategy-pad-pass</code>: Configurable pass to apply padding and hoisting.</a></li><li><a href=#-linalg-strategy-promote-pass-configurable-pass-to-apply-pattern-based-linalg-promotion><code>-linalg-strategy-promote-pass</code>: Configurable pass to apply pattern-based linalg promotion.</a></li><li><a href=#-linalg-strategy-remove-markers-pass-cleanup-pass-that-drops-markers><code>-linalg-strategy-remove-markers-pass</code>: Cleanup pass that drops markers.</a></li><li><a href=#-linalg-strategy-tile-and-fuse-pass-configurable-pass-to-apply-pattern-based-tiling-and-fusion><code>-linalg-strategy-tile-and-fuse-pass</code>: Configurable pass to apply pattern-based tiling and fusion.</a></li><li><a href=#-linalg-strategy-tile-pass-configurable-pass-to-apply-pattern-based-linalg-tiling><code>-linalg-strategy-tile-pass</code>: Configurable pass to apply pattern-based linalg tiling.</a></li><li><a href=#-linalg-strategy-vectorize-pass-configurable-pass-to-apply-pattern-based-linalg-vectorization><code>-linalg-strategy-vectorize-pass</code>: Configurable pass to apply pattern-based linalg vectorization.</a></li><li><a href=#-linalg-tile-tile-operations-in-the-linalg-dialect><code>-linalg-tile</code>: Tile operations in the linalg dialect</a></li></ul></li><li><a href=#llvm-dialect-passes><code>llvm</code> Dialect Passes</a><ul><li><a href=#-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir><code>-llvm-legalize-for-export</code>: Legalize LLVM dialect to be convertible to LLVM IR</a></li></ul></li><li><a href=#memref-dialect-passes><code>memref</code> Dialect Passes</a><ul><li><a href=#-fold-memref-subview-ops-fold-memrefsubview-ops-into-consumer-loadstore-ops><code>-fold-memref-subview-ops</code>: Fold memref.subview ops into consumer load/store ops</a></li><li><a href=#-memref-expand-legalize-memref-operations-to-be-convertible-to-llvm><code>-memref-expand</code>: Legalize memref operations to be convertible to LLVM.</a></li><li><a href=#-normalize-memrefs-normalize-memrefs><code>-normalize-memrefs</code>: Normalize memrefs</a></li><li><a href=#-resolve-ranked-shaped-type-result-dims-resolve-memrefdim-of-result-values-of-ranked-shape-type><code>-resolve-ranked-shaped-type-result-dims</code>: Resolve memref.dim of result values of ranked shape type</a></li><li><a href=#-resolve-shaped-type-result-dims-resolve-memrefdim-of-result-values><code>-resolve-shaped-type-result-dims</code>: Resolve memref.dim of result values</a></li></ul></li><li><a href=#quant-dialect-passes><code>quant</code> Dialect Passes</a><ul><li><a href=#-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values><code>-quant-convert-const</code>: Converts constants followed by qbarrier to actual quantized values</a></li><li><a href=#-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts><code>-quant-convert-simulated-quantization</code>: Converts training-time simulated quantization ops to corresponding quantize/dequantize casts</a></li></ul></li><li><a href=#reducer-passes>Reducer Passes</a><ul><li><a href=#-opt-reduction-pass-a-wrapper-pass-that-reduces-the-file-with-optimization-passes><code>-opt-reduction-pass</code>: A wrapper pass that reduces the file with optimization passes</a></li><li><a href=#-reduction-tree-reduce-the-input-with-reduction-tree-algorithm><code>-reduction-tree</code>: Reduce the input with reduction-tree algorithm</a></li></ul></li><li><a href=#scf-dialect-passes><code>scf</code> Dialect Passes</a><ul><li><a href=#-scf-bufferize-bufferize-the-scf-dialect><code>-scf-bufferize</code>: Bufferize the scf dialect.</a></li><li><a href=#-scf-for-loop-canonicalization-canonicalize-operations-within-scffor-loop-bodies><code>-scf-for-loop-canonicalization</code>: Canonicalize operations within scf.for loop bodies</a></li><li><a href=#-scf-for-loop-peeling-peel-for-loops-at-their-upper-bounds><code>-scf-for-loop-peeling</code>: Peel <code>for</code> loops at their upper bounds.</a></li><li><a href=#-scf-for-loop-range-folding-fold-addmul-ops-into-loop-range><code>-scf-for-loop-range-folding</code>: Fold add/mul ops into loop range</a></li><li><a href=#-scf-for-loop-specialization-specialize-for-loops-for-vectorization><code>-scf-for-loop-specialization</code>: Specialize <code>for</code> loops for vectorization</a></li><li><a href=#-scf-for-to-while-convert-scf-for-loops-to-scf-while-loops><code>-scf-for-to-while</code>: Convert SCF for loops to SCF while loops</a></li><li><a href=#-scf-parallel-loop-collapsing-collapse-parallel-loops-to-use-less-induction-variables><code>-scf-parallel-loop-collapsing</code>: Collapse parallel loops to use less induction variables</a></li><li><a href=#-scf-parallel-loop-fusion-fuse-adjacent-parallel-loops><code>-scf-parallel-loop-fusion</code>: Fuse adjacent parallel loops</a></li><li><a href=#-scf-parallel-loop-specialization-specialize-parallel-loops-for-vectorization><code>-scf-parallel-loop-specialization</code>: Specialize parallel loops for vectorization</a></li><li><a href=#-scf-parallel-loop-tiling-tile-parallel-loops><code>-scf-parallel-loop-tiling</code>: Tile parallel loops</a></li></ul></li><li><a href=#shape-dialect-passes><code>shape</code> Dialect Passes</a><ul><li><a href=#-remove-shape-constraints-replace-all-cstr_-ops-with-a-true-witness><code>-remove-shape-constraints</code>: Replace all cstr_ ops with a true witness</a></li><li><a href=#-shape-bufferize-bufferize-the-shape-dialect><code>-shape-bufferize</code>: Bufferize the shape dialect.</a></li><li><a href=#-shape-to-shape-lowering-legalize-shape-dialect-to-be-convertible-to-arithmetic><code>-shape-to-shape-lowering</code>: Legalize Shape dialect to be convertible to Arithmetic</a></li></ul></li><li><a href=#sparse_tensor-dialect-passes><code>sparse_tensor</code> Dialect Passes</a><ul><li><a href=#-sparse-tensor-conversion-apply-conversion-rules-to-sparse-tensor-primitives-and-types><code>-sparse-tensor-conversion</code>: Apply conversion rules to sparse tensor primitives and types</a></li><li><a href=#-sparsification-automatically-generate-sparse-tensor-code-from-sparse-tensor-types><code>-sparsification</code>: Automatically generate sparse tensor code from sparse tensor types</a></li></ul></li><li><a href=#spv-dialect-passes><code>spv</code> Dialect Passes</a><ul><li><a href=#-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info><code>-decorate-spirv-composite-type-layout</code>: Decorate SPIR-V composite type with layout info</a></li><li><a href=#-spirv-canonicalize-glsl-run-canonicalization-involving-glsl-ops><code>-spirv-canonicalize-glsl</code>: Run canonicalization involving GLSL ops</a></li><li><a href=#-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info><code>-spirv-lower-abi-attrs</code>: Decorate SPIR-V composite type with layout info</a></li><li><a href=#-spirv-rewrite-inserts-rewrite-sequential-chains-of-spvcompositeinsert-operations-into-spvcompositeconstruct-operations><code>-spirv-rewrite-inserts</code>: Rewrite sequential chains of spv.CompositeInsert operations into spv.CompositeConstruct operations</a></li><li><a href=#-spirv-unify-aliased-resource-unify-access-of-multiple-aliased-resources-into-access-of-one-single-resource><code>-spirv-unify-aliased-resource</code>: Unify access of multiple aliased resources into access of one single resource</a></li><li><a href=#-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops><code>-spirv-update-vce</code>: Deduce and attach minimal (version, capabilities, extensions) requirements to spv.module ops</a></li></ul></li><li><a href=#tensor-dialect-passes><code>tensor</code> Dialect Passes</a><ul><li><a href=#-tensor-bufferize-bufferize-the-tensor-dialect><code>-tensor-bufferize</code>: Bufferize the <code>tensor</code> dialect</a></li></ul></li><li><a href=#vector-dialect-passes><code>vector</code> Dialect Passes</a><ul><li><a href=#-vector-bufferize-bufferize-vector-dialect-ops><code>-vector-bufferize</code>: Bufferize Vector dialect ops</a></li></ul></li><li><a href=#tosa-dialect-passes>TOSA Dialect Passes</a><ul><li><a href=#-tosa-infer-shapes-propagate-shapes-across-tosa-operations><code>-tosa-infer-shapes</code>: Propagate shapes across TOSA operations</a></li><li><a href=#-tosa-make-broadcastable-tosa-rank-reshape-to-enable-broadcasting><code>-tosa-make-broadcastable</code>: TOSA rank Reshape to enable Broadcasting</a></li><li><a href=#-tosa-optional-decompositions-applies-tosa-operations-optional-decompositions><code>-tosa-optional-decompositions</code>: Applies Tosa operations optional decompositions</a></li></ul></li></ul></nav><h2 id=general-transformation-passes>General Transformation Passes&nbsp;<a class=headline-hash href=#general-transformation-passes>¶</a></h2><h3 id=-canonicalize-canonicalize-operations><code>-canonicalize</code>: Canonicalize operations&nbsp;<a class=headline-hash href=#-canonicalize-canonicalize-operations>¶</a></h3><p>This pass performs various types of canonicalizations over a set of
operations. See
<a href=/docs/Canonicalization/>Operation Canonicalization</a> for more
details.</p><h4 id=options>Options&nbsp;<a class=headline-hash href=#options>¶</a></h4><pre><code>-top-down         : Seed the worklist in general top-down order
-region-simplify  : Seed the worklist in general top-down order
-max-iterations   : Seed the worklist in general top-down order
-disable-patterns : Labels of patterns that should be filtered out during application
-enable-patterns  : Labels of patterns that should be used during application, all other patterns are filtered out
</code></pre><h3 id=-control-flow-sink-sink-operations-into-conditional-blocks><code>-control-flow-sink</code>: Sink operations into conditional blocks&nbsp;<a class=headline-hash href=#-control-flow-sink-sink-operations-into-conditional-blocks>¶</a></h3><p>This pass implements control-flow sink on operations that implement
<code>RegionBranchOpInterface</code> by moving dominating operations whose only uses
are in a conditionally-executed regions into those regions so that
executions paths where their results are not needed do not perform
unnecessary computations.</p><p>This is similar (but opposite) to loop-invariant code motion, which hoists
operations out of regions executed more than once. The implementation of
control-flow sink uses a simple and conversative cost model: operations are
never duplicated and are only moved into singly-executed regions.</p><p>It is recommended to run canonicalization first to remove unreachable
blocks: ops in unreachable blocks may prevent other operations from being
sunk as they may contain uses of their results</p><h4 id=statistics>Statistics&nbsp;<a class=headline-hash href=#statistics>¶</a></h4><pre><code>num-sunk : Number of operations sunk
</code></pre><h3 id=-cse-eliminate-common-sub-expressions><code>-cse</code>: Eliminate common sub-expressions&nbsp;<a class=headline-hash href=#-cse-eliminate-common-sub-expressions>¶</a></h3><p>This pass implements a generalized algorithm for common sub-expression
elimination. This pass relies on information provided by the
<code>Memory SideEffect</code> interface to identify when it is safe to eliminate
operations. See
<a href=https://en.wikipedia.org/wiki/Common_subexpression_elimination>Common subexpression elimination</a>
for more general details on this optimization.</p><h4 id=statistics-1>Statistics&nbsp;<a class=headline-hash href=#statistics-1>¶</a></h4><pre><code>num-cse'd : Number of operations CSE'd
num-dce'd : Number of operations DCE'd
</code></pre><h3 id=-inline-inline-function-calls><code>-inline</code>: Inline function calls&nbsp;<a class=headline-hash href=#-inline-inline-function-calls>¶</a></h3><h4 id=options-1>Options&nbsp;<a class=headline-hash href=#options-1>¶</a></h4><pre><code>-default-pipeline : The default optimizer pipeline used for callables
-op-pipelines     : Callable operation specific optimizer pipelines (in the form of `dialect.op(pipeline)`)
-max-iterations   : Maximum number of iterations when inlining within an SCC
</code></pre><h3 id=-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop><code>-loop-invariant-code-motion</code>: Hoist loop invariant instructions outside of the loop&nbsp;<a class=headline-hash href=#-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop>¶</a></h3><h3 id=-print-op-stats-print-statistics-of-operations><code>-print-op-stats</code>: Print statistics of operations&nbsp;<a class=headline-hash href=#-print-op-stats-print-statistics-of-operations>¶</a></h3><h3 id=-sccp-sparse-conditional-constant-propagation><code>-sccp</code>: Sparse Conditional Constant Propagation&nbsp;<a class=headline-hash href=#-sccp-sparse-conditional-constant-propagation>¶</a></h3><p>This pass implements a general algorithm for sparse conditional constant
propagation. This algorithm detects values that are known to be constant and
optimistically propagates this throughout the IR. Any values proven to be
constant are replaced, and removed if possible.</p><p>This implementation is based on the algorithm described by Wegman and Zadeck
in
<a href=https://dl.acm.org/doi/10.1145/103135.103136>“Constant Propagation with Conditional Branches”</a> (1991).</p><h3 id=-snapshot-op-locations-generate-new-locations-from-the-current-ir><code>-snapshot-op-locations</code>: Generate new locations from the current IR&nbsp;<a class=headline-hash href=#-snapshot-op-locations-generate-new-locations-from-the-current-ir>¶</a></h3><p>This pass allows for generating new locations from the IR during any stage
of compilation, by snapshotting the IR to a file and using that file to
generate new locations for the operations.</p><p>Depending on the value of the <code>tag</code> option, different resulting locations
may be generated:</p><ul><li>If unset, the original location of the operation is replaced.</li></ul><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// old:
</span><span class=c></span><span class=p>...</span> <span class=kt>loc</span><span class=p>(</span><span class=s>&#34;original_source.cpp&#34;</span><span class=p>:</span><span class=m>1</span><span class=p>:</span><span class=m>1</span><span class=p>)</span>

<span class=c>// new:
</span><span class=c></span><span class=p>...</span> <span class=kt>loc</span><span class=p>(</span><span class=s>&#34;snapshot_source.mlir&#34;</span><span class=p>:</span><span class=m>10</span><span class=p>:</span><span class=m>10</span><span class=p>)</span>
</code></pre></div><ul><li>If set, the new location is fused with the original location in the form
of a
<a href=/docs/Diagnostics/><code>Name Location</code></a> with the specified tag.</li></ul><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// old:
</span><span class=c></span><span class=p>...</span> <span class=kt>loc</span><span class=p>(</span><span class=s>&#34;original_source.cpp&#34;</span><span class=p>:</span><span class=m>1</span><span class=p>:</span><span class=m>1</span><span class=p>)</span>

<span class=c>// new:
</span><span class=c></span><span class=p>...</span> <span class=kt>loc</span><span class=p>(</span>fused<span class=p>[</span><span class=s>&#34;original_source.cpp&#34;</span><span class=p>:</span><span class=m>1</span><span class=p>:</span><span class=m>1</span><span class=p>,</span> <span class=s>&#34;snapshot&#34;</span><span class=p>(</span><span class=s>&#34;snapshot_source.mlir&#34;</span><span class=p>:</span><span class=m>10</span><span class=p>:</span><span class=m>10</span><span class=p>)])</span>
</code></pre></div><h4 id=options-2>Options&nbsp;<a class=headline-hash href=#options-2>¶</a></h4><pre><code>-filename : The filename to print the generated IR
-tag      : A tag to use when fusing the new locations with the original. If unset, the locations are replaced.
</code></pre><h3 id=-strip-debuginfo-strip-debug-info-from-all-operations><code>-strip-debuginfo</code>: Strip debug info from all operations&nbsp;<a class=headline-hash href=#-strip-debuginfo-strip-debug-info-from-all-operations>¶</a></h3><p>This pass strips the IR of any location information, by replacing all
operation locations with
<a href=/docs/Diagnostics/><code>unknown</code></a>.</p><h3 id=-symbol-dce-eliminate-dead-symbols><code>-symbol-dce</code>: Eliminate dead symbols&nbsp;<a class=headline-hash href=#-symbol-dce-eliminate-dead-symbols>¶</a></h3><p>This pass deletes all symbols that are found to be unreachable. This is done
by computing the set of operations that are known to be live, propagating
that liveness to other symbols, and then deleting all symbols that are not
within this live set. Live symbols are those that have a
<a href=/docs/SymbolsAndSymbolTables/>visibility</a> that extends
beyond the IR, e.g. <code>public</code>, or those that are referenced by live symbols
or other non-Symbol operations.</p><p>For example, consider the following input:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> private <span class=nf>@dead_private_function</span><span class=p>()</span>
<span class=kt>func</span><span class=p>.</span><span class=kt>func</span> private <span class=nf>@live_private_function</span><span class=p>()</span>

<span class=c>// Note: The `public` isn&#39;t necessary here, as this is the default.
</span><span class=c></span><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> public <span class=nf>@public_function</span><span class=p>()</span> <span class=p>{</span>
  <span class=s>&#34;foo.return&#34;</span><span class=p>()</span> <span class=p>{</span><span class=nl>uses =</span> <span class=p>[</span><span class=nf>@live_private_function</span><span class=p>]}</span> <span class=p>:</span> <span class=p>()</span> <span class=p>-&gt;</span> <span class=p>()</span>
<span class=p>}</span>
</code></pre></div><p>A known live function, <code>public_function</code>, contains a reference to an
otherwise non-live function <code>live_private_function</code>. After running
<code>symbol-dce</code>, only these two symbols should remain, as the final symbol
<code>dead_private_function</code> is not visible outside of the current IR and there
are no links to known-live operations. After running, we get the expected:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> private <span class=nf>@live_private_function</span><span class=p>()</span>

<span class=kt>func</span><span class=p>.</span><span class=kt>func</span> public <span class=nf>@public_function</span><span class=p>()</span> <span class=p>{</span>
  <span class=s>&#34;foo.return&#34;</span><span class=p>()</span> <span class=p>{</span><span class=nl>uses =</span> <span class=p>[</span><span class=nf>@live_private_function</span><span class=p>]}</span> <span class=p>:</span> <span class=p>()</span> <span class=p>-&gt;</span> <span class=p>()</span>
<span class=p>}</span>
</code></pre></div><p>See
<a href=/docs/SymbolsAndSymbolTables/>Symbols and SymbolTables</a> for more
information on <code>Symbols</code>.</p><h4 id=statistics-2>Statistics&nbsp;<a class=headline-hash href=#statistics-2>¶</a></h4><pre><code>num-dce'd : Number of symbols DCE'd
</code></pre><h3 id=-symbol-privatize-mark-symbols-private><code>-symbol-privatize</code>: Mark symbols private&nbsp;<a class=headline-hash href=#-symbol-privatize-mark-symbols-private>¶</a></h3><p>This pass marks all top-level symbols of the operation run as <code>private</code>
except if listed in <code>exclude</code> pass option.</p><h4 id=options-3>Options&nbsp;<a class=headline-hash href=#options-3>¶</a></h4><pre><code>-exclude : Comma separated list of symbols that should not be marked private
</code></pre><h3 id=-view-op-graph-print-graphviz-visualization-of-an-operation><code>-view-op-graph</code>: Print Graphviz visualization of an operation&nbsp;<a class=headline-hash href=#-view-op-graph-print-graphviz-visualization-of-an-operation>¶</a></h3><p>This pass prints a Graphviz graph of a module.</p><ul><li>Operations are represented as nodes;</li><li>Uses (data flow) as edges;</li><li>Control flow as dashed edges;</li><li>Regions/blocks as subgraphs.</li></ul><p>By default, only data flow edges are printed.</p><p>Note: See <a href=https://www.graphviz.org/doc/info/lang.html>https://www.graphviz.org/doc/info/lang.html</a> for more information
about the Graphviz DOT language.</p><h4 id=options-4>Options&nbsp;<a class=headline-hash href=#options-4>¶</a></h4><pre><code>-max-label-len            : Limit attribute/type length to number of chars
-print-attrs              : Print attributes of operations
-print-control-flow-edges : Print control flow edges
-print-data-flow-edges    : Print data flow edges
-print-result-types       : Print result types of operations
</code></pre><h2 id=bufferization-passes>Bufferization Passes&nbsp;<a class=headline-hash href=#bufferization-passes>¶</a></h2><h3 id=-buffer-deallocation-adds-all-required-dealloc-operations-for-all-allocations-in-the-input-program><code>-buffer-deallocation</code>: Adds all required dealloc operations for all allocations in the input program&nbsp;<a class=headline-hash href=#-buffer-deallocation-adds-all-required-dealloc-operations-for-all-allocations-in-the-input-program>¶</a></h3><p>This pass implements an algorithm to automatically introduce all required
deallocation operations for all buffers in the input program. This ensures
that the resulting program does not have any memory leaks.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>#map0</span> <span class=p>=</span> affine_map<span class=p>&lt;(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>)&gt;</span>
module <span class=p>{</span>
  <span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@condBranch</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=k>i1</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>{</span>
    cf<span class=p>.</span>cond_br <span class=nv>%arg0</span><span class=p>,</span> <span class=nl>^bb1</span><span class=p>,</span> <span class=nl>^bb2
</span><span class=nl>  ^bb1</span><span class=p>:</span>
    cf<span class=p>.</span>br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%arg1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span>
  <span class=nl>^bb2</span><span class=p>:</span>
    <span class=nv>%0</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    linalg<span class=p>.</span>generic <span class=p>{</span>
      <span class=nl>args_in =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span>
      <span class=nl>args_out =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span>
      <span class=nl>indexing_maps =</span> <span class=p>[</span><span class=nv>#map0</span><span class=p>,</span> <span class=nv>#map0</span><span class=p>],</span>
      <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>]}</span> <span class=nv>%arg1</span><span class=p>,</span> <span class=nv>%0</span> <span class=p>{</span>
    <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%gen1_arg0</span><span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>%gen1_arg1</span><span class=p>:</span> <span class=k>f32</span><span class=p>):</span>
      <span class=nv>%tmp1</span> <span class=p>=</span> exp <span class=nv>%gen1_arg0</span> <span class=p>:</span> <span class=k>f32</span>
      linalg<span class=p>.</span>yield <span class=nv>%tmp1</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=p>}:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    cf<span class=p>.</span>br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span>
  <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;):</span>
    <span class=s>&#34;memref.copy&#34;</span><span class=p>(</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=p>()</span>
    <span class=kt>return</span>
  <span class=p>}</span>
<span class=p>}</span>

</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>#map0</span> <span class=p>=</span> affine_map<span class=p>&lt;(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>)&gt;</span>
module <span class=p>{</span>
  <span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@condBranch</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=k>i1</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>{</span>
    cf<span class=p>.</span>cond_br <span class=nv>%arg0</span><span class=p>,</span> <span class=nl>^bb1</span><span class=p>,</span> <span class=nl>^bb2
</span><span class=nl>  ^bb1</span><span class=p>:</span>  <span class=c>// pred: ^bb0
</span><span class=c></span>    <span class=nv>%0</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=kt>memref</span><span class=p>.</span>copy<span class=p>(</span><span class=nv>%arg1</span><span class=p>,</span> <span class=nv>%0</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    cf<span class=p>.</span>br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span>
  <span class=nl>^bb2</span><span class=p>:</span>  <span class=c>// pred: ^bb0
</span><span class=c></span>    <span class=nv>%1</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    linalg<span class=p>.</span>generic <span class=p>{</span>
      <span class=nl>args_in =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span>
      <span class=nl>args_out =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span>
      <span class=nl>indexing_maps =</span> <span class=p>[</span><span class=nv>#map0</span><span class=p>,</span> <span class=nv>#map0</span><span class=p>],</span>
      <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>]}</span> <span class=nv>%arg1</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>{</span>
    <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg3</span><span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>%arg4</span><span class=p>:</span> <span class=k>f32</span><span class=p>):</span>
      <span class=nv>%4</span> <span class=p>=</span> exp <span class=nv>%arg3</span> <span class=p>:</span> <span class=k>f32</span>
      linalg<span class=p>.</span>yield <span class=nv>%4</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=p>}:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%2</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=kt>memref</span><span class=p>.</span>copy<span class=p>(</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    dealloc <span class=nv>%1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    cf<span class=p>.</span>br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%2</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span>
  <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%3</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;):</span>  <span class=c>// 2 preds: ^bb1, ^bb2
</span><span class=c></span>    <span class=kt>memref</span><span class=p>.</span>copy<span class=p>(</span><span class=nv>%3</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    dealloc <span class=nv>%3</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=kt>return</span>
  <span class=p>}</span>

<span class=p>}</span>
</code></pre></div><h3 id=-buffer-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-into-common-dominators-and-out-of-nested-regions><code>-buffer-hoisting</code>: Optimizes placement of allocation operations by moving them into common dominators and out of nested regions&nbsp;<a class=headline-hash href=#-buffer-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-into-common-dominators-and-out-of-nested-regions>¶</a></h3><p>This pass implements an approach to aggressively move allocations upwards
into common dominators and out of nested regions.</p><h3 id=-buffer-loop-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-out-of-loop-nests><code>-buffer-loop-hoisting</code>: Optimizes placement of allocation operations by moving them out of loop nests&nbsp;<a class=headline-hash href=#-buffer-loop-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-out-of-loop-nests>¶</a></h3><p>This pass implements an approach to aggressively move allocations upwards
out of loop nests. It does not move allocations into common dominators.</p><h3 id=-buffer-results-to-out-params-converts-memref-typed-function-results-to-out-params><code>-buffer-results-to-out-params</code>: Converts memref-typed function results to out-params&nbsp;<a class=headline-hash href=#-buffer-results-to-out-params-converts-memref-typed-function-results-to-out-params>¶</a></h3><p>Some calling conventions prefer to pass output memrefs as &ldquo;out params&rdquo;. The
conversion to this calling convention must be done as an atomic
transformation of the entire program (hence this is a module pass).</p><p>For example, if a call is rewritten, the callee needs to be rewritten
otherwise the IR will end up invalid. Thus, this transformation
require an atomic change to the entire program (e.g. the whole module).</p><p>This pass is expected to run immediately after bufferization is finished.
At that point, tensor-typed results will have been converted to memref-typed
results, and can be consistently converted to out params.</p><p>All memref-typed results are appended to the function argument list.</p><p>The main issue with this pass (and the out-param calling convention) is that
buffers for results need to be allocated in the caller. This currently only
works for static shaped memrefs.</p><h3 id=-finalizing-bufferize-finalize-a-partial-bufferization><code>-finalizing-bufferize</code>: Finalize a partial bufferization&nbsp;<a class=headline-hash href=#-finalizing-bufferize-finalize-a-partial-bufferization>¶</a></h3><p>A bufferize pass that finalizes a partial bufferization by removing
remaining <code>bufferization.to_tensor</code> and <code>bufferization.to_buffer</code> operations.</p><p>The removal of those operations is only possible if the operations only
exist in pairs, i.e., all uses of <code>bufferization.to_tensor</code> operations are
<code>bufferization.to_buffer</code> operations.</p><p>This pass will fail if not all operations can be removed or if any operation
with tensor typed operands remains.</p><h3 id=-one-shot-bufferize-one-shot-bufferize><code>-one-shot-bufferize</code>: One-Shot Bufferize&nbsp;<a class=headline-hash href=#-one-shot-bufferize-one-shot-bufferize>¶</a></h3><p>This pass bufferizes all ops that implement <code>BufferizableOpInterface</code>. It
first performs an inplacability analysis on SSA use-def chains of tensor
values to determine which OpOperands may bufferize in-place, i.e., without
inserting a buffer copy. It then rewrites the IR, inserting a buffer
allocation and copy for each OpOperand that was decided to bufferize
out-of-place.</p><p>One-Shot Bufferize (and <code>BufferizableOpInterface</code>) was designed for ops that
are in destination-passing style. When bufferizing such ops, it is possible
to reuse the buffer of a tensor OpOperand for a tensor OpResult. In essence,
a possible destination of an operation is already passed as an SSA value.</p><p><code>tensor.insert</code> is an example for an op in destination-passing style. E.g.,
when bufferizing <code>%t0 = tensor.insert %f into %dest[%idx]</code>, <code>buffer(%t0)</code> is
identical to <code>buffer(%dest)</code> in the absence of RaW conflicts. As a counter
example, <code>tensor.generate</code> is not in destination-passing style and always
results in a new buffer allocation.</p><p>One-Shot Bufferize deallocates all buffers that it allocates. Returning or
yielding newly allocated buffers from a block can lead to bad performance
because additional buffer copies would be inserted. By default, such IR is
rejected by One-Shot Bufferize. If performance is not important, such IR can
be allowed with <code>allow-return-allocs=1</code>.</p><p>One-Shot Bufferize will by default reject IR that contains non-bufferizable
op, i.e., ops that do not implemement BufferizableOpInterface. Such IR can
be allowed with <code>allow-unknown-ops=1</code>. In that case, to_memref and to_tensor
ops will be generated at the bufferization boundary. This is useful for
compatibility with existing partial bufferization passes: These can
bufferize the remaining IR after running One-Shot Bufferize.</p><p>Note: Running One-Shot Bufferize after a partial bufferization pass is
currently not supported. Running partial bufferization passes after running
One-Shot Bufferize is supported and the recommended way to gradually
migrate from partial bufferization to One-Shot Bufferize.</p><p>With <code>dialect-filter</code>, bufferization can be restricted to a set of dialects.
If no filter is specified, all ops that implement <code>BufferizableOpInterface</code>
are bufferized. Ops from the <code>std</code> dialect are an exception: These ops are
always ignored, even if no filter is specified. When specifying a dialect
filter and <code>allow-unknown-ops</code> is not turned on, bufferization would fail
when encountering an op that is not included in the filter (even if it is
bufferizable).</p><p>For testing/debugging purposes, <code>test-analysis-only=1 print-conflicts=1</code>
prints analysis results and explains why an OpOperand was decided to
bufferize out-of-place. This is useful for understanding why One-Shot
Bufferize chose to insert a certain buffer copy.</p><p><code>bufferize-function-boundaries</code> is an experimental flag for bufferizing
<code>FuncOp</code>, <code>ReturnOp</code> and <code>CallOp</code>. This feature is still under development
and supports only simple cases at the moment. In particular:</p><ul><li>Recursive or circular function call graphs are not supported.</li><li>If a newly allocated buffer is returned from a function (with
<code>allow-return-allocs</code>), the buffer will never be deallocated and leak.
Such IR needs special handling, e.g., allocation hoisting or reference
counting.</li><li>External functions (without bodies) that return a tensor are not
supported.</li><li>Function with multiple blocks or multiple ReturnOps are not supported.</li></ul><p>One-Shot Bufferize implements the following contract around function calls:
The buffer of function arguments is always writable (unless annotated with
<code>bufferization.writable = false</code>). A buffer copy may be inserted at the call
site where necessary. Alias sets and equivalence info is propagated through
function calls. Whenever a function is bufferized, all other functions that
are being called were already analyzed and bufferized, so exact alias and
equivalence information is available. This is why recursive function calls
are not yet supported.</p><p>One-Shot Bufferize gathers additional information during the analysis phase
when function boundary bufferization is activated. E.g., whether a function
argument is read/written and which returned values are aliasing/equivalent.
For debugging purposes, such information can be printed with
<code>test-analysis-only</code>.</p><h4 id=options-5>Options&nbsp;<a class=headline-hash href=#options-5>¶</a></h4><pre><code>-drop-equivalent-func-results  : Drop buffer return values that are equivalent to a FuncOp arg.
-allow-return-allocs           : Allows returning/yielding new allocations from a block.
-allow-unknown-ops             : Allows unknown (not bufferizable) ops in the input IR.
-always-aliasing-with-dest     : Tensor OpResult cannot bufferize inplace OpOperands other than out/dest OpOperands (if the op has such operands; experimental)
-analysis-fuzzer-seed          : Test only: Analyze ops in random order with a given seed (fuzzer)
-bufferize-function-boundaries : Bufferize function boundaries (experimental).
-create-deallocs               : Specify if buffers should be deallocated. For compatibility with core bufferization passes.
-dialect-filter                : Restrict bufferization to ops from these dialects.
-fully-dynamic-layout-maps     : Generate MemRef types with dynamic offset+strides by default.
-test-analysis-only            : Test only: Only run inplaceability analysis and annotate IR
-print-conflicts               : Test only: Annotate IR with RaW conflicts. Requires test-analysis-only.
</code></pre><h3 id=-promote-buffers-to-stack-promotes-heap-based-allocations-to-automatically-managed-stack-based-allocations><code>-promote-buffers-to-stack</code>: Promotes heap-based allocations to automatically managed stack-based allocations&nbsp;<a class=headline-hash href=#-promote-buffers-to-stack-promotes-heap-based-allocations-to-automatically-managed-stack-based-allocations>¶</a></h3><p>This pass implements a simple algorithm to convert heap-based memory
allocations to stack-based ones. It uses a built-in heuristic to decide
whether it makes sense to convert an allocation. Furthermore, dynamic
shaped buffers that are limited by the rank of the tensor can be
converted. They are only transformed if they are considered to be small.</p><h4 id=options-6>Options&nbsp;<a class=headline-hash href=#options-6>¶</a></h4><pre><code>-max-alloc-size-in-bytes      : Maximal size in bytes to promote allocations to stack.
-max-rank-of-allocated-memref : Maximal memref rank to promote dynamic buffers.
</code></pre><h2 id=conversion-passes>Conversion Passes&nbsp;<a class=headline-hash href=#conversion-passes>¶</a></h2><h3 id=-arm-neon-2d-to-intr-convert-arm-neon-structured-ops-to-intrinsics><code>-arm-neon-2d-to-intr</code>: Convert Arm NEON structured ops to intrinsics&nbsp;<a class=headline-hash href=#-arm-neon-2d-to-intr-convert-arm-neon-structured-ops-to-intrinsics>¶</a></h3><h3 id=-convert-affine-for-to-gpu-convert-top-level-affinefor-ops-to-gpu-kernels><code>-convert-affine-for-to-gpu</code>: Convert top-level AffineFor Ops to GPU kernels&nbsp;<a class=headline-hash href=#-convert-affine-for-to-gpu-convert-top-level-affinefor-ops-to-gpu-kernels>¶</a></h3><h4 id=options-7>Options&nbsp;<a class=headline-hash href=#options-7>¶</a></h4><pre><code>-gpu-block-dims  : Number of GPU block dimensions for mapping
-gpu-thread-dims : Number of GPU thread dimensions for mapping
</code></pre><h3 id=-convert-arith-to-llvm-convert-arithmetic-dialect-to-llvm-dialect><code>-convert-arith-to-llvm</code>: Convert Arithmetic dialect to LLVM dialect&nbsp;<a class=headline-hash href=#-convert-arith-to-llvm-convert-arithmetic-dialect-to-llvm-dialect>¶</a></h3><p>This pass converts supported Arithmetic ops to LLVM dialect instructions.</p><h4 id=options-8>Options&nbsp;<a class=headline-hash href=#options-8>¶</a></h4><pre><code>-index-bitwidth : Bitwidth of the index type, 0 to use size of machine word
</code></pre><h3 id=-convert-arith-to-spirv-convert-arithmetic-dialect-to-spir-v-dialect><code>-convert-arith-to-spirv</code>: Convert Arithmetic dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-arith-to-spirv-convert-arithmetic-dialect-to-spir-v-dialect>¶</a></h3><h4 id=options-9>Options&nbsp;<a class=headline-hash href=#options-9>¶</a></h4><pre><code>-emulate-non-32-bit-scalar-types : Emulate non-32-bit scalar types with 32-bit ones if missing native support
</code></pre><h3 id=-convert-async-to-llvm-convert-the-operations-from-the-async-dialect-into-the-llvm-dialect><code>-convert-async-to-llvm</code>: Convert the operations from the async dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-async-to-llvm-convert-the-operations-from-the-async-dialect-into-the-llvm-dialect>¶</a></h3><p>Convert <code>async.execute</code> operations to LLVM coroutines and use async runtime
API to execute them.</p><h3 id=-convert-bufferization-to-memref-convert-operations-from-the-bufferization-dialect-to-the-memref-dialect><code>-convert-bufferization-to-memref</code>: Convert operations from the Bufferization dialect to the MemRef dialect&nbsp;<a class=headline-hash href=#-convert-bufferization-to-memref-convert-operations-from-the-bufferization-dialect-to-the-memref-dialect>¶</a></h3><p>This pass converts bufferization operations into memref operations.</p><p>In the current state, this pass only transforms a <code>bufferization.clone</code>
operation into <code>memref.alloc</code> and <code>memref.copy</code> operations. This conversion
is needed, since some clone operations could remain after applying several
transformation processes. Currently, only <code>canonicalize</code> transforms clone
operations or even eliminates them. This can lead to errors if any clone op
survived after all conversion passes (starting from the bufferization
dialect) are performed.</p><p>See:
<a href=https://llvm.discourse.group/t/bufferization-error-related-to-memref-clone/4665>https://llvm.discourse.group/t/bufferization-error-related-to-memref-clone/4665</a></p><p>To avoid these errors, this pass can be performed as a last clean-up pass to
transform remaining operations and to proceed in other dialects (memref
e.g.).</p><p>Note that this pass only transforms the operation without any further
analyses. This pass does not consider any memory analysis or optimization
and hence does not resolve any memory leaks.</p><h3 id=-convert-cf-to-llvm-convert-controlflow-operations-to-the-llvm-dialect><code>-convert-cf-to-llvm</code>: Convert ControlFlow operations to the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-cf-to-llvm-convert-controlflow-operations-to-the-llvm-dialect>¶</a></h3><p>Convert ControlFlow operations into LLVM IR dialect operations.</p><p>If other operations are present and their results are required by the LLVM
IR dialect operations, the pass will fail. Any LLVM IR operations or types
already present in the IR will be kept as is.</p><h4 id=options-10>Options&nbsp;<a class=headline-hash href=#options-10>¶</a></h4><pre><code>-index-bitwidth : Bitwidth of the index type, 0 to use size of machine word
</code></pre><h3 id=-convert-cf-to-spirv-convert-controlflow-dialect-to-spir-v-dialect><code>-convert-cf-to-spirv</code>: Convert ControlFlow dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-cf-to-spirv-convert-controlflow-dialect-to-spir-v-dialect>¶</a></h3><h4 id=options-11>Options&nbsp;<a class=headline-hash href=#options-11>¶</a></h4><pre><code>-emulate-non-32-bit-scalar-types : Emulate non-32-bit scalar types with 32-bit ones if missing native support
</code></pre><h3 id=-convert-complex-to-llvm-convert-complex-dialect-to-llvm-dialect><code>-convert-complex-to-llvm</code>: Convert Complex dialect to LLVM dialect&nbsp;<a class=headline-hash href=#-convert-complex-to-llvm-convert-complex-dialect-to-llvm-dialect>¶</a></h3><h3 id=-convert-complex-to-standard-convert-complex-dialect-to-standard-dialect><code>-convert-complex-to-standard</code>: Convert Complex dialect to standard dialect&nbsp;<a class=headline-hash href=#-convert-complex-to-standard-convert-complex-dialect-to-standard-dialect>¶</a></h3><h3 id=-convert-func-to-llvm-convert-from-the-func-dialect-to-the-llvm-dialect><code>-convert-func-to-llvm</code>: Convert from the Func dialect to the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-func-to-llvm-convert-from-the-func-dialect-to-the-llvm-dialect>¶</a></h3><p>Convert Func dialect operations into the LLVM IR dialect operations.</p><h4 id=input-invariant>Input invariant&nbsp;<a class=headline-hash href=#input-invariant>¶</a></h4><ul><li>no <code>tensor</code> types;</li><li>all <code>vector</code> are one-dimensional;</li><li>all blocks are reachable by following the successors of the first basic
block;</li></ul><p>If other operations are present and their results are required by the LLVM
IR dialect operations, the pass will fail. Any LLVM IR operations or types
already present in the IR will be kept as is.</p><h4 id=output-ir>Output IR&nbsp;<a class=headline-hash href=#output-ir>¶</a></h4><p>Functions converted to LLVM IR. Function arguments types are converted
one-to-one. Function results are converted one-to-one and, in case more than
1 value is returned, packed into an LLVM IR struct type. Function calls and
returns are updated accordingly. Block argument types are updated to use
LLVM IR types.</p><h4 id=options-12>Options&nbsp;<a class=headline-hash href=#options-12>¶</a></h4><pre><code>-use-bare-ptr-memref-call-conv : Replace FuncOp's MemRef arguments with bare pointers to the MemRef element types
-emit-c-wrappers               : Emit wrappers for C-compatible pointer-to-struct memref descriptors
-index-bitwidth                : Bitwidth of the index type, 0 to use size of machine word
-data-layout                   : String description (LLVM format) of the data layout that is expected on the produced module
</code></pre><h3 id=-convert-func-to-spirv-convert-func-dialect-to-spir-v-dialect><code>-convert-func-to-spirv</code>: Convert Func dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-func-to-spirv-convert-func-dialect-to-spir-v-dialect>¶</a></h3><h4 id=options-13>Options&nbsp;<a class=headline-hash href=#options-13>¶</a></h4><pre><code>-emulate-non-32-bit-scalar-types : Emulate non-32-bit scalar types with 32-bit ones if missing native support
</code></pre><h3 id=-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call><code>-convert-gpu-launch-to-vulkan-launch</code>: Convert gpu.launch_func to vulkanLaunch external call&nbsp;<a class=headline-hash href=#-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call>¶</a></h3><p>This pass is only intended for the mlir-vulkan-runner.</p><h3 id=-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations><code>-convert-gpu-to-nvvm</code>: Generate NVVM operations for gpu operations&nbsp;<a class=headline-hash href=#-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations>¶</a></h3><h4 id=options-14>Options&nbsp;<a class=headline-hash href=#options-14>¶</a></h4><pre><code>-index-bitwidth : Bitwidth of the index type, 0 to use size of machine word
</code></pre><h3 id=-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations><code>-convert-gpu-to-rocdl</code>: Generate ROCDL operations for gpu operations&nbsp;<a class=headline-hash href=#-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations>¶</a></h3><h4 id=options-15>Options&nbsp;<a class=headline-hash href=#options-15>¶</a></h4><pre><code>-index-bitwidth : Bitwidth of the index type, 0 to use size of machine word
-runtime        : Runtime code will be run on (default is Unknown, can also use HIP or OpenCl)
</code></pre><h3 id=-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect><code>-convert-gpu-to-spirv</code>: Convert GPU dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect>¶</a></h3><p>This pass converts supported GPU device ops to SPIR-V ops. It does not
handle GPU host ops.</p><p>A <code>gpu.func</code> op can have parameters to pass in resources. But in SPIR-V
entry functions cannot take parameters; they use descriptors to access
resources. By default, parameters to a <code>gpu.func</code> op will be converted to
global variables. These global variables will be assigned sequential binding
numbers following their order in the original <code>gpu.func</code> op, starting from
0, in set 0. One can attach <code>spv.interface_var_abi</code> to those parameters
to control the set and binding if wanted.</p><h3 id=-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect><code>-convert-linalg-to-llvm</code>: Convert the operations from the linalg dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect>¶</a></h3><h3 id=-convert-linalg-to-spirv-convert-linalg-dialect-to-spir-v-dialect><code>-convert-linalg-to-spirv</code>: Convert Linalg dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-linalg-to-spirv-convert-linalg-dialect-to-spir-v-dialect>¶</a></h3><p>This pass converts supported Linalg ops to SPIR-V ops. It&rsquo;s quite
experimental and are expected to migrate to other proper conversions.</p><h3 id=-convert-linalg-to-std-convert-the-operations-from-the-linalg-dialect-into-the-standard-dialect><code>-convert-linalg-to-std</code>: Convert the operations from the linalg dialect into the Standard dialect&nbsp;<a class=headline-hash href=#-convert-linalg-to-std-convert-the-operations-from-the-linalg-dialect-into-the-standard-dialect>¶</a></h3><h3 id=-convert-math-to-libm-convert-math-dialect-to-libm-calls><code>-convert-math-to-libm</code>: Convert Math dialect to libm calls&nbsp;<a class=headline-hash href=#-convert-math-to-libm-convert-math-dialect-to-libm-calls>¶</a></h3><p>This pass converts supported Math ops to libm calls.</p><h3 id=-convert-math-to-llvm-convert-math-dialect-to-llvm-dialect><code>-convert-math-to-llvm</code>: Convert Math dialect to LLVM dialect&nbsp;<a class=headline-hash href=#-convert-math-to-llvm-convert-math-dialect-to-llvm-dialect>¶</a></h3><p>This pass converts supported Math ops to LLVM dialect intrinsics.</p><h3 id=-convert-math-to-spirv-convert-math-dialect-to-spir-v-dialect><code>-convert-math-to-spirv</code>: Convert Math dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-math-to-spirv-convert-math-dialect-to-spir-v-dialect>¶</a></h3><h3 id=-convert-memref-to-llvm-convert-operations-from-the-memref-dialect-to-the-llvm-dialect><code>-convert-memref-to-llvm</code>: Convert operations from the MemRef dialect to the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-memref-to-llvm-convert-operations-from-the-memref-dialect-to-the-llvm-dialect>¶</a></h3><h4 id=options-16>Options&nbsp;<a class=headline-hash href=#options-16>¶</a></h4><pre><code>-use-aligned-alloc : Use aligned_alloc in place of malloc for heap allocations
-index-bitwidth    : Bitwidth of the index type, 0 to use size of machine word
</code></pre><h3 id=-convert-memref-to-spirv-convert-memref-dialect-to-spir-v-dialect><code>-convert-memref-to-spirv</code>: Convert MemRef dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-memref-to-spirv-convert-memref-dialect-to-spir-v-dialect>¶</a></h3><h4 id=options-17>Options&nbsp;<a class=headline-hash href=#options-17>¶</a></h4><pre><code>-bool-num-bits : The number of bits to store a boolean value
</code></pre><h3 id=-convert-nvgpu-to-nvvm-convert-nvgpu-dialect-to-nvvm-dialect><code>-convert-nvgpu-to-nvvm</code>: Convert NVGPU dialect to NVVM dialect&nbsp;<a class=headline-hash href=#-convert-nvgpu-to-nvvm-convert-nvgpu-dialect-to-nvvm-dialect>¶</a></h3><p>This pass converts supported NVGPU ops to NVVM dialect intrinsics.</p><h3 id=-convert-openacc-to-llvm-convert-the-openacc-ops-to-llvm-dialect><code>-convert-openacc-to-llvm</code>: Convert the OpenACC ops to LLVM dialect&nbsp;<a class=headline-hash href=#-convert-openacc-to-llvm-convert-the-openacc-ops-to-llvm-dialect>¶</a></h3><h3 id=-convert-openacc-to-scf-convert-the-openacc-ops-to-openacc-with-scf-dialect><code>-convert-openacc-to-scf</code>: Convert the OpenACC ops to OpenACC with SCF dialect&nbsp;<a class=headline-hash href=#-convert-openacc-to-scf-convert-the-openacc-ops-to-openacc-with-scf-dialect>¶</a></h3><h3 id=-convert-openmp-to-llvm-convert-the-openmp-ops-to-openmp-ops-with-llvm-dialect><code>-convert-openmp-to-llvm</code>: Convert the OpenMP ops to OpenMP ops with LLVM dialect&nbsp;<a class=headline-hash href=#-convert-openmp-to-llvm-convert-the-openmp-ops-to-openmp-ops-with-llvm-dialect>¶</a></h3><h3 id=-convert-parallel-loops-to-gpu-convert-mapped-scfparallel-ops-to-gpu-launch-operations><code>-convert-parallel-loops-to-gpu</code>: Convert mapped scf.parallel ops to gpu launch operations&nbsp;<a class=headline-hash href=#-convert-parallel-loops-to-gpu-convert-mapped-scfparallel-ops-to-gpu-launch-operations>¶</a></h3><h3 id=-convert-pdl-to-pdl-interp-convert-pdl-ops-to-pdl-interpreter-ops><code>-convert-pdl-to-pdl-interp</code>: Convert PDL ops to PDL interpreter ops&nbsp;<a class=headline-hash href=#-convert-pdl-to-pdl-interp-convert-pdl-ops-to-pdl-interpreter-ops>¶</a></h3><h3 id=-convert-scf-to-cf-convert-scf-dialect-to-controlflow-dialect-replacing-structured-control-flow-with-a-cfg><code>-convert-scf-to-cf</code>: Convert SCF dialect to ControlFlow dialect, replacing structured control flow with a CFG&nbsp;<a class=headline-hash href=#-convert-scf-to-cf-convert-scf-dialect-to-controlflow-dialect-replacing-structured-control-flow-with-a-cfg>¶</a></h3><h3 id=-convert-scf-to-openmp-convert-scf-parallel-loop-to-openmp-parallel--workshare-constructs><code>-convert-scf-to-openmp</code>: Convert SCF parallel loop to OpenMP parallel + workshare constructs.&nbsp;<a class=headline-hash href=#-convert-scf-to-openmp-convert-scf-parallel-loop-to-openmp-parallel--workshare-constructs>¶</a></h3><h3 id=-convert-scf-to-spirv-convert-scf-dialect-to-spir-v-dialect><code>-convert-scf-to-spirv</code>: Convert SCF dialect to SPIR-V dialect.&nbsp;<a class=headline-hash href=#-convert-scf-to-spirv-convert-scf-dialect-to-spir-v-dialect>¶</a></h3><p>This pass converts SCF ops into SPIR-V structured control flow ops.
SPIR-V structured control flow ops does not support yielding values.
So for SCF ops yielding values, SPIR-V variables are created for
holding the values and load/store operations are emitted for updating
them.</p><h3 id=-convert-shape-constraints-convert-shape-constraint-operations-to-the-standard-dialect><code>-convert-shape-constraints</code>: Convert shape constraint operations to the standard dialect&nbsp;<a class=headline-hash href=#-convert-shape-constraints-convert-shape-constraint-operations-to-the-standard-dialect>¶</a></h3><p>This pass eliminates shape constraints from the program, converting them to
eager (side-effecting) error handling code.</p><p>This pass is separate from the regular convert-shape-to-standard, despite
converting between the same dialects, because converting shape constraints
can happen at a different part of the program than general shape
computation lowering.</p><h3 id=-convert-shape-to-std-convert-operations-from-the-shape-dialect-into-the-standard-dialect><code>-convert-shape-to-std</code>: Convert operations from the shape dialect into the standard dialect&nbsp;<a class=headline-hash href=#-convert-shape-to-std-convert-operations-from-the-shape-dialect-into-the-standard-dialect>¶</a></h3><h3 id=-convert-spirv-to-llvm-convert-spir-v-dialect-to-llvm-dialect><code>-convert-spirv-to-llvm</code>: Convert SPIR-V dialect to LLVM dialect&nbsp;<a class=headline-hash href=#-convert-spirv-to-llvm-convert-spir-v-dialect-to-llvm-dialect>¶</a></h3><p>See <a href=https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/>https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/</a>
for more details.</p><h3 id=-convert-tensor-to-spirv-convert-tensor-dialect-to-spir-v-dialect><code>-convert-tensor-to-spirv</code>: Convert Tensor dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-tensor-to-spirv-convert-tensor-dialect-to-spir-v-dialect>¶</a></h3><h4 id=options-18>Options&nbsp;<a class=headline-hash href=#options-18>¶</a></h4><pre><code>-emulate-non-32-bit-scalar-types : Emulate non-32-bit scalar types with 32-bit ones if missing native support
</code></pre><h3 id=-convert-vector-to-gpu-lower-the-operations-from-the-vector-dialect-into-the-gpu-dialect><code>-convert-vector-to-gpu</code>: Lower the operations from the vector dialect into the GPU dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-gpu-lower-the-operations-from-the-vector-dialect-into-the-gpu-dialect>¶</a></h3><h3 id=-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect><code>-convert-vector-to-llvm</code>: Lower the operations from the vector dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect>¶</a></h3><p>Convert operations from the vector dialect into the LLVM IR dialect
operations. The lowering pass provides several options to control
the kinds of optimizations that are allowed. It also provides options
that enable the use of one or more architectural-specific dialects
(AMX, X86Vector, ArmNeon, ArmSVE, etc.) in combination with the
architectural-neutral vector dialect lowering.</p><h4 id=options-19>Options&nbsp;<a class=headline-hash href=#options-19>¶</a></h4><pre><code>-reassociate-fp-reductions  : Allows llvm to reassociate floating-point reductions for speed
-force-32bit-vector-indices : Allows compiler to assume vector indices fit in 32-bit if that yields faster code
-enable-amx                 : Enables the use of AMX dialect while lowering the vector dialect.
-enable-arm-neon            : Enables the use of ArmNeon dialect while lowering the vector dialect.
-enable-arm-sve             : Enables the use of ArmSVE dialect while lowering the vector dialect.
-enable-x86vector           : Enables the use of X86Vector dialect while lowering the vector dialect.
</code></pre><h3 id=-convert-vector-to-rocdl-lower-the-operations-from-the-vector-dialect-into-the-rocdl-dialect><code>-convert-vector-to-rocdl</code>: Lower the operations from the vector dialect into the ROCDL dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-rocdl-lower-the-operations-from-the-vector-dialect-into-the-rocdl-dialect>¶</a></h3><h3 id=-convert-vector-to-scf-lower-the-operations-from-the-vector-dialect-into-the-scf-dialect><code>-convert-vector-to-scf</code>: Lower the operations from the vector dialect into the SCF dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-scf-lower-the-operations-from-the-vector-dialect-into-the-scf-dialect>¶</a></h3><h4 id=options-20>Options&nbsp;<a class=headline-hash href=#options-20>¶</a></h4><pre><code>-full-unroll            : Perform full unrolling when converting vector transfers to SCF
-target-rank            : Target vector rank to which transfer ops should be lowered
-lower-permutation-maps : Replace permutation maps with vector transposes/broadcasts before lowering transfer ops
-lower-tensors          : Lower transfer ops that operate on tensors
</code></pre><h3 id=-convert-vector-to-spirv-convert-vector-dialect-to-spir-v-dialect><code>-convert-vector-to-spirv</code>: Convert Vector dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-spirv-convert-vector-dialect-to-spir-v-dialect>¶</a></h3><h3 id=-gpu-to-llvm-convert-gpu-dialect-to-llvm-dialect-with-gpu-runtime-calls><code>-gpu-to-llvm</code>: Convert GPU dialect to LLVM dialect with GPU runtime calls&nbsp;<a class=headline-hash href=#-gpu-to-llvm-convert-gpu-dialect-to-llvm-dialect-with-gpu-runtime-calls>¶</a></h3><h3 id=-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls><code>-launch-func-to-vulkan</code>: Convert vulkanLaunch external call to Vulkan runtime external calls&nbsp;<a class=headline-hash href=#-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls>¶</a></h3><p>This pass is only intended for the mlir-vulkan-runner.</p><h3 id=-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-scf-operations><code>-lower-affine</code>: Lower Affine operations to a combination of Standard and SCF operations&nbsp;<a class=headline-hash href=#-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-scf-operations>¶</a></h3><p>Convert operations from the affine dialect into operations from the SCF and
standard dialects.</p><p><code>affine.for</code> operations are converted to <code>scf.for</code> operations that are free
of certain structural restrictions (on their bounds and step). <code>affine.if</code>
is similarly converted to the <code>scf.if</code> operation. <code>affine.apply</code> operations
are converted into sequences of primitive arithmetic operations from the
standard dialect that have the same effect, using operands of the <code>index</code>
type. Consequently, named maps and sets thare are no longer in use may be
removed from the module.</p><p>For example, <code>%r = affine.apply affine_map&lt;(d0, d1)[s0] -> (d0 + 2*d1 + s0)>(%d0, %d1)[%s0]</code>
can be converted into:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%d0</span> <span class=p>=</span> <span class=p>&lt;...&gt;</span>
<span class=nv>%d1</span> <span class=p>=</span> <span class=p>&lt;...&gt;</span>
<span class=nv>%s0</span> <span class=p>=</span> <span class=p>&lt;...&gt;</span>
<span class=nv>%0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>2</span> <span class=p>:</span> <span class=k>index</span>
<span class=nv>%1</span> <span class=p>=</span> arith<span class=p>.</span>muli <span class=nv>%0</span><span class=p>,</span> <span class=nv>%d1</span>
<span class=nv>%2</span> <span class=p>=</span> arith<span class=p>.</span>addi <span class=nv>%d0</span><span class=p>,</span> <span class=nv>%1</span>
<span class=nv>%r</span> <span class=p>=</span> arith<span class=p>.</span>addi <span class=nv>%2</span><span class=p>,</span> <span class=nv>%s0</span>
</code></pre></div><h4 id=input-invariant-1>Input invariant&nbsp;<a class=headline-hash href=#input-invariant-1>¶</a></h4><ul><li>no <code>Tensor</code> types;</li></ul><p>These restrictions may be lifted in the future.</p><h4 id=output-ir-1>Output IR&nbsp;<a class=headline-hash href=#output-ir-1>¶</a></h4><p>Functions with <code>affine.for</code> and <code>affine.if</code> operations eliminated. These
functions may contain operations from the Standard dialect in addition to
those already present before the pass.</p><h4 id=invariants>Invariants&nbsp;<a class=headline-hash href=#invariants>¶</a></h4><ul><li>Functions without a body are not modified.</li><li>The semantics of the other functions is preserved.</li><li>Individual operations other than those mentioned above are not modified
if they do not depend on the loop iterator value or on the result of
<code>affine.apply</code>.</li></ul><h3 id=-lower-host-to-llvm-lowers-the-host-module-code-and-gpulaunch_func-to-llvm><code>-lower-host-to-llvm</code>: Lowers the host module code and <code>gpu.launch_func</code> to LLVM&nbsp;<a class=headline-hash href=#-lower-host-to-llvm-lowers-the-host-module-code-and-gpulaunch_func-to-llvm>¶</a></h3><h3 id=-reconcile-unrealized-casts-simplify-and-eliminate-unrealized-conversion-casts><code>-reconcile-unrealized-casts</code>: Simplify and eliminate unrealized conversion casts&nbsp;<a class=headline-hash href=#-reconcile-unrealized-casts-simplify-and-eliminate-unrealized-conversion-casts>¶</a></h3><p>Eliminate <code>unrealized_conversion_cast</code> operations, commonly introduced by
partial dialect conversions, that transitively convert a value to another
value of the same type, that is:</p><pre><code>%0 = &quot;producer.op&quot;() : () -&gt; !type.A
%1 = unrealized_conversion_cast %0 : !type.A to !type.B
%2 = unrealized_conversion_cast %1 : !type.B to !type.A
&quot;consumer.op&quot;(%2) : (!type.A) -&gt; ()
</code></pre><p>Such situations appear when the consumer operation is converted by one pass
and the producer operation is converted by another pass, each of which
produces an unrealized cast. This pass can be used to clean up the IR.</p><h3 id=-tosa-to-arith-lower-tosa-to-the-arith-dialect><code>-tosa-to-arith</code>: Lower TOSA to the Arith dialect&nbsp;<a class=headline-hash href=#-tosa-to-arith-lower-tosa-to-the-arith-dialect>¶</a></h3><p>Pass that converts TOSA operations to the equivalent operations using the
operations in the Arith dialect. The ApplyScale operator is optionally
included as it is often preserved until the final invocation.</p><h4 id=options-21>Options&nbsp;<a class=headline-hash href=#options-21>¶</a></h4><pre><code>-include-apply-rescale : Whether to include the lowering for tosa.apply_rescale to arith
</code></pre><h3 id=-tosa-to-linalg-lower-tosa-to-linalg-on-tensors><code>-tosa-to-linalg</code>: Lower TOSA to LinAlg on tensors&nbsp;<a class=headline-hash href=#-tosa-to-linalg-lower-tosa-to-linalg-on-tensors>¶</a></h3><p>Pass that converts TOSA operations to the equivalent operations using the
tensor operations in LinAlg.</p><h3 id=-tosa-to-linalg-named-lower-tosa-to-linalg-named-operations><code>-tosa-to-linalg-named</code>: Lower TOSA to LinAlg named operations&nbsp;<a class=headline-hash href=#-tosa-to-linalg-named-lower-tosa-to-linalg-named-operations>¶</a></h3><p>Pass that converts TOSA operations to the equivalent operations using the
Linalg named operations.</p><h3 id=-tosa-to-scf-lower-tosa-to-the-scf-dialect><code>-tosa-to-scf</code>: Lower TOSA to the SCF dialect&nbsp;<a class=headline-hash href=#-tosa-to-scf-lower-tosa-to-the-scf-dialect>¶</a></h3><p>Pass that converts TOSA&rsquo;s control flow operations to the equivalent SCF
operations.</p><h3 id=-tosa-to-tensor-lower-tosa-to-the-tensor-dialect><code>-tosa-to-tensor</code>: Lower TOSA to the Tensor dialect&nbsp;<a class=headline-hash href=#-tosa-to-tensor-lower-tosa-to-the-tensor-dialect>¶</a></h3><p>Pass that converts TOSA operations to the equivalent operations using the
operations in the Tensor dialect.</p><h2 id=async-dialect-passes><code>async</code> Dialect Passes&nbsp;<a class=headline-hash href=#async-dialect-passes>¶</a></h2><h3 id=-async-parallel-for-convert-scfparallel-operations-to-multiple-async-compute-ops-executed-concurrently-for-non-overlapping-iteration-ranges><code>-async-parallel-for</code>: Convert scf.parallel operations to multiple async compute ops executed concurrently for non-overlapping iteration ranges&nbsp;<a class=headline-hash href=#-async-parallel-for-convert-scfparallel-operations-to-multiple-async-compute-ops-executed-concurrently-for-non-overlapping-iteration-ranges>¶</a></h3><h4 id=options-22>Options&nbsp;<a class=headline-hash href=#options-22>¶</a></h4><pre><code>-async-dispatch : Dispatch async compute tasks using recursive work splitting. If `false` async compute tasks will be launched using simple for loop in the caller thread.
-num-workers    : The number of available workers to execute async operations. If `-1` the value will be retrieved from the runtime.
-min-task-size  : The minimum task size for sharding parallel operation.
</code></pre><h3 id=-async-runtime-policy-based-ref-counting-policy-based-reference-counting-for-async-runtime-operations><code>-async-runtime-policy-based-ref-counting</code>: Policy based reference counting for Async runtime operations&nbsp;<a class=headline-hash href=#-async-runtime-policy-based-ref-counting-policy-based-reference-counting-for-async-runtime-operations>¶</a></h3><p>This pass works at the async runtime abtraction level, after all
<code>async.execute</code> and <code>async.await</code> operations are lowered to the async
runtime API calls, and async coroutine operations.</p><p>This pass doesn&rsquo;t rely on reference counted values liveness analysis, and
instead uses simple policy to create reference counting operations. If the
program violates any of the assumptions, then this pass might lead to
memory leaks or runtime errors.</p><p>The default reference counting policy assumptions:</p><ol><li>Async token can be awaited or added to the group only once.</li><li>Async value or group can be awaited only once.</li></ol><p>Under these assumptions reference counting only needs to drop reference:</p><ol><li>After <code>async.runtime.await</code> operation for async tokens and groups
(until error handling is not implemented for the sync await).</li><li>After <code>async.runtime.is_error</code> operation for async tokens and groups
(this is the last operation in the coroutine resume function).</li><li>After <code>async.runtime.load</code> operation for async values.</li></ol><p>This pass introduces significanly less runtime overhead compared to the
automatic reference counting.</p><h3 id=-async-runtime-ref-counting-automatic-reference-counting-for-async-runtime-operations><code>-async-runtime-ref-counting</code>: Automatic reference counting for Async runtime operations&nbsp;<a class=headline-hash href=#-async-runtime-ref-counting-automatic-reference-counting-for-async-runtime-operations>¶</a></h3><p>This pass works at the async runtime abtraction level, after all
<code>async.execute</code> and <code>async.await</code> operations are lowered to the async
runtime API calls, and async coroutine operations.</p><p>It relies on the LLVM coroutines switched-resume lowering semantics for
the correct placing of the reference counting operations.</p><p>See: <a href=https://llvm.org/docs/Coroutines.html#switched-resume-lowering>https://llvm.org/docs/Coroutines.html#switched-resume-lowering</a></p><h3 id=-async-runtime-ref-counting-opt-optimize-automatic-reference-counting-operations-for-theasync-runtime-by-removing-redundant-operations><code>-async-runtime-ref-counting-opt</code>: Optimize automatic reference counting operations for theAsync runtime by removing redundant operations&nbsp;<a class=headline-hash href=#-async-runtime-ref-counting-opt-optimize-automatic-reference-counting-operations-for-theasync-runtime-by-removing-redundant-operations>¶</a></h3><h3 id=-async-to-async-runtime-lower-high-level-async-operations-eg-asyncexecute-to-theexplicit-asyncruntime-and-asynccoro-operations><code>-async-to-async-runtime</code>: Lower high level async operations (e.g. async.execute) to theexplicit async.runtime and async.coro operations&nbsp;<a class=headline-hash href=#-async-to-async-runtime-lower-high-level-async-operations-eg-asyncexecute-to-theexplicit-asyncruntime-and-asynccoro-operations>¶</a></h3><h4 id=options-23>Options&nbsp;<a class=headline-hash href=#options-23>¶</a></h4><pre><code>-eliminate-blocking-await-ops : Rewrite functions with blocking async.runtime.await as coroutines with async.runtime.await_and_resume.
</code></pre><h2 id=affine-dialect-passes><code>affine</code> Dialect Passes&nbsp;<a class=headline-hash href=#affine-dialect-passes>¶</a></h2><h3 id=-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations><code>-affine-data-copy-generate</code>: Generate explicit copying for affine memory operations&nbsp;<a class=headline-hash href=#-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations>¶</a></h3><h4 id=options-24>Options&nbsp;<a class=headline-hash href=#options-24>¶</a></h4><pre><code>-fast-mem-capacity          : Set fast memory space capacity in KiB (default: unlimited)
-fast-mem-space             : Fast memory space identifier for copy generation (default: 1)
-generate-dma               : Generate DMA instead of point-wise copy
-min-dma-transfer           : Minimum DMA transfer size supported by the target in bytes
-slow-mem-space             : Slow memory space identifier for copy generation (default: 0)
-skip-non-unit-stride-loops : Testing purposes: avoid non-unit stride loop choice depths for copy placement
-tag-mem-space              : Tag memory space identifier for copy generation (default: 0)
</code></pre><h3 id=-affine-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop><code>-affine-loop-coalescing</code>: Coalesce nested loops with independent bounds into a single loop&nbsp;<a class=headline-hash href=#-affine-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop>¶</a></h3><h3 id=-affine-loop-fusion-fuse-affine-loop-nests><code>-affine-loop-fusion</code>: Fuse affine loop nests&nbsp;<a class=headline-hash href=#-affine-loop-fusion-fuse-affine-loop-nests>¶</a></h3><p>This pass performs fusion of loop nests using a slicing-based approach. It
combines two fusion strategies: producer-consumer fusion and sibling fusion.
Producer-consumer fusion is aimed at fusing pairs of loops where the first
one writes to a memref that the second reads. Sibling fusion targets pairs
of loops that share no dependences between them but that load from the same
memref. The fused loop nests, when possible, are rewritten to access
significantly smaller local buffers instead of the original memref&rsquo;s, and
the latter are often either completely optimized away or contracted. This
transformation leads to enhanced locality and lower memory footprint through
the elimination or contraction of temporaries/intermediate memref&rsquo;s. These
benefits are sometimes achieved at the expense of redundant computation
through a cost model that evaluates available choices such as the depth at
which a source slice should be materialized in the designation slice.</p><p>Example 1: Producer-consumer fusion.
Input:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@producer_consumer_fusion</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>{</span>
  <span class=nv>%0</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%1</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%cst</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0.000000e+00</span> <span class=p>:</span> <span class=k>f32</span>
  affine<span class=p>.</span>for <span class=nv>%arg2</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
    affine<span class=p>.</span>store <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>store <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
  affine<span class=p>.</span>for <span class=nv>%arg2</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
    <span class=nv>%2</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%3</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%2</span><span class=p>,</span> <span class=nv>%2</span> <span class=p>:</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%3</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
  affine<span class=p>.</span>for <span class=nv>%arg2</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
    <span class=nv>%2</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%3</span> <span class=p>=</span> arith<span class=p>.</span>mulf <span class=nv>%2</span><span class=p>,</span> <span class=nv>%2</span> <span class=p>:</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%3</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><p>Output:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@producer_consumer_fusion</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>{</span>
  <span class=nv>%0</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%1</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%cst</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0.000000e+00</span> <span class=p>:</span> <span class=k>f32</span>
  affine<span class=p>.</span>for <span class=nv>%arg2</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
    affine<span class=p>.</span>store <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%0</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>store <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%2</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%3</span> <span class=p>=</span> arith<span class=p>.</span>mulf <span class=nv>%2</span><span class=p>,</span> <span class=nv>%2</span> <span class=p>:</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%3</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%4</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%0</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%5</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%4</span><span class=p>,</span> <span class=nv>%4</span> <span class=p>:</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%5</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><p>Example 2: Sibling fusion.
Input:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@sibling_fusion</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;,</span>
                     <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=nv>%arg3</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;,</span>
                     <span class=nv>%arg4</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>{</span>
  affine<span class=p>.</span>for <span class=nv>%arg5</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>3</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%arg6</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>3</span> <span class=p>{</span>
      <span class=nv>%0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%2</span> <span class=p>=</span> arith<span class=p>.</span>mulf <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>:</span> <span class=k>f32</span>
      affine<span class=p>.</span>store <span class=nv>%2</span><span class=p>,</span> <span class=nv>%arg3</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=p>}</span>
  <span class=p>}</span>
  affine<span class=p>.</span>for <span class=nv>%arg5</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>3</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%arg6</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>3</span> <span class=p>{</span>
      <span class=nv>%0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg2</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%2</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>:</span> <span class=k>f32</span>
      affine<span class=p>.</span>store <span class=nv>%2</span><span class=p>,</span> <span class=nv>%arg4</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=p>}</span>
  <span class=p>}</span>
  <span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><p>Output:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@sibling_fusion</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;,</span>
                     <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=nv>%arg3</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;,</span>
                     <span class=nv>%arg4</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>{</span>
  affine<span class=p>.</span>for <span class=nv>%arg5</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>3</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%arg6</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>3</span> <span class=p>{</span>
      <span class=nv>%0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%2</span> <span class=p>=</span> arith<span class=p>.</span>mulf <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>:</span> <span class=k>f32</span>
      affine<span class=p>.</span>store <span class=nv>%2</span><span class=p>,</span> <span class=nv>%arg3</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%4</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg2</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%5</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%3</span><span class=p>,</span> <span class=nv>%4</span> <span class=p>:</span> <span class=k>f32</span>
      affine<span class=p>.</span>store <span class=nv>%5</span><span class=p>,</span> <span class=nv>%arg4</span><span class=p>[</span><span class=nv>%arg5</span><span class=p>,</span> <span class=nv>%arg6</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=p>}</span>
  <span class=p>}</span>
  <span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><h4 id=options-25>Options&nbsp;<a class=headline-hash href=#options-25>¶</a></h4><pre><code>-fusion-compute-tolerance   : Fractional increase in additional computation tolerated while fusing
-fusion-fast-mem-space      : Faster memory space number to promote fusion buffers to
-fusion-local-buf-threshold : Threshold size (KiB) for promoting local buffers to fast memory space
-fusion-maximal             : Enables maximal loop fusion
-mode                       : fusion mode to attempt
</code></pre><h3 id=-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops><code>-affine-loop-invariant-code-motion</code>: Hoist loop invariant instructions outside of affine loops&nbsp;<a class=headline-hash href=#-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops>¶</a></h3><h3 id=-affine-loop-normalize-apply-normalization-transformations-to-affine-loop-like-ops><code>-affine-loop-normalize</code>: Apply normalization transformations to affine loop-like ops&nbsp;<a class=headline-hash href=#-affine-loop-normalize-apply-normalization-transformations-to-affine-loop-like-ops>¶</a></h3><h3 id=-affine-loop-tile-tile-affine-loop-nests><code>-affine-loop-tile</code>: Tile affine loop nests&nbsp;<a class=headline-hash href=#-affine-loop-tile-tile-affine-loop-nests>¶</a></h3><h4 id=options-26>Options&nbsp;<a class=headline-hash href=#options-26>¶</a></h4><pre><code>-cache-size : Set size of cache to tile for in KiB
-separate   : Separate full and partial tiles
-tile-size  : Use this tile size for all loops
-tile-sizes : List of tile sizes for each perfect nest (overridden by -tile-size)
</code></pre><h3 id=-affine-loop-unroll-unroll-affine-loops><code>-affine-loop-unroll</code>: Unroll affine loops&nbsp;<a class=headline-hash href=#-affine-loop-unroll-unroll-affine-loops>¶</a></h3><h4 id=options-27>Options&nbsp;<a class=headline-hash href=#options-27>¶</a></h4><pre><code>-unroll-factor         : Use this unroll factor for all loops being unrolled
-unroll-up-to-factor   : Allow unrolling up to the factor specified
-unroll-full           : Fully unroll loops
-unroll-num-reps       : Unroll innermost loops repeatedly this many times
-unroll-full-threshold : Unroll all loops with trip count less than or equal to this
</code></pre><h3 id=-affine-loop-unroll-jam-unroll-and-jam-affine-loops><code>-affine-loop-unroll-jam</code>: Unroll and jam affine loops&nbsp;<a class=headline-hash href=#-affine-loop-unroll-jam-unroll-and-jam-affine-loops>¶</a></h3><h4 id=options-28>Options&nbsp;<a class=headline-hash href=#options-28>¶</a></h4><pre><code>-unroll-jam-factor : Use this unroll jam factor for all loops (default 4)
</code></pre><h3 id=-affine-parallelize-convert-affinefor-ops-into-1-d-affineparallel><code>-affine-parallelize</code>: Convert affine.for ops into 1-D affine.parallel&nbsp;<a class=headline-hash href=#-affine-parallelize-convert-affinefor-ops-into-1-d-affineparallel>¶</a></h3><h4 id=options-29>Options&nbsp;<a class=headline-hash href=#options-29>¶</a></h4><pre><code>-max-nested          : Maximum number of nested parallel loops to produce. Defaults to unlimited (UINT_MAX).
-parallel-reductions : Whether to parallelize reduction loops. Defaults to false.
</code></pre><h3 id=-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy><code>-affine-pipeline-data-transfer</code>: Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy&nbsp;<a class=headline-hash href=#-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy>¶</a></h3><p>This pass performs a transformation to overlap non-blocking DMA operations
in a loop with computations through double buffering. This is achieved by
advancing dma_start operations with respect to other operations.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@pipelinedatatransfer</span><span class=p>()</span> <span class=p>{</span>
  <span class=nv>%0</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%1</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
  <span class=nv>%2</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%c0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
  <span class=nv>%c128</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>128</span> <span class=p>:</span> <span class=k>index</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>8</span> <span class=p>{</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%i0</span><span class=p>],</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>],</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>],</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>],</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%4</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%4</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@pipelinedatatransfer</span><span class=p>()</span> <span class=p>{</span>
    <span class=nv>%c8</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>8</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%0</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%c0_0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c128</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>128</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%1</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%2</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%c0</span><span class=p>],</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%c0</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%c0</span><span class=p>],</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)],</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>1</span> to <span class=m>8</span> <span class=p>{</span>
      affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg0</span><span class=p>],</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%arg0</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>],</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%arg0</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)],</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%8</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map3</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>)</span>
      <span class=nv>%9</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%8</span><span class=p>)</span>
      <span class=nv>%10</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%8</span><span class=p>)</span>
      affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)],</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%11</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
      <span class=nv>%12</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%11</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
      affine<span class=p>.</span>store <span class=nv>%12</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=p>}</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map3</span><span class=p>(</span><span class=nv>%c8</span><span class=p>)</span>
    <span class=nv>%4</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span>
    <span class=nv>%5</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)],</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%6</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%7</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%6</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%7</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=kt>memref</span><span class=p>.</span>dealloc <span class=nv>%2</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=kt>memref</span><span class=p>.</span>dealloc <span class=nv>%1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=kt>return</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><h3 id=-affine-scalrep-replace-affine-memref-acceses-by-scalars-by-forwarding-stores-to-loads-and-eliminating-redundant-loads><code>-affine-scalrep</code>: Replace affine memref acceses by scalars by forwarding stores to loads and eliminating redundant loads&nbsp;<a class=headline-hash href=#-affine-scalrep-replace-affine-memref-acceses-by-scalars-by-forwarding-stores-to-loads-and-eliminating-redundant-loads>¶</a></h3><p>This pass performs store to load forwarding and redundant load elimination
for affine memref accesses and potentially eliminates the entire memref
if all its accesses are forwarded.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@store_load_affine_apply</span><span class=p>()</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
  <span class=nv>%cf7</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>7.0</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=nv>%m</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
      affine<span class=p>.</span>store <span class=nv>%cf7</span><span class=p>,</span> <span class=nv>%m</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%v0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%m</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%v1</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%v0</span><span class=p>,</span> <span class=nv>%v0</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=p>}</span>
  <span class=p>}</span>
  <span class=kt>return</span> <span class=nv>%m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@store_load_affine_apply</span><span class=p>()</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
    <span class=nv>%cst</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>7.000000e+00</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=nv>%0</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
      affine<span class=p>.</span>for <span class=nv>%arg1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
        affine<span class=p>.</span>store <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg0</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
        <span class=nv>%1</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%cst</span> <span class=p>:</span> <span class=k>f32</span>
      <span class=p>}</span>
    <span class=p>}</span>
    <span class=kt>return</span> <span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><h3 id=-affine-simplify-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs><code>-affine-simplify-structures</code>: Simplify affine expressions in maps/sets and normalize memrefs&nbsp;<a class=headline-hash href=#-affine-simplify-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs>¶</a></h3><h3 id=-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction><code>-affine-super-vectorize</code>: Vectorize to a target independent n-D vector abstraction&nbsp;<a class=headline-hash href=#-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction>¶</a></h3><h4 id=options-30>Options&nbsp;<a class=headline-hash href=#options-30>¶</a></h4><pre><code>-virtual-vector-size  : Specify an n-D virtual vector size for vectorization
-test-fastest-varying : Specify a 1-D, 2-D or 3-D pattern of fastest varying memory dimensions to match. See defaultPatterns in Vectorize.cpp for a description and examples. This is used for testing purposes
-vectorize-reductions : Vectorize known reductions expressed via iter_args. Switched off by default.
</code></pre><h2 id=arith-dialect-passes><code>arith</code> Dialect Passes&nbsp;<a class=headline-hash href=#arith-dialect-passes>¶</a></h2><h3 id=-arith-bufferize-bufferize-arithmetic-dialect-ops><code>-arith-bufferize</code>: Bufferize Arithmetic dialect ops.&nbsp;<a class=headline-hash href=#-arith-bufferize-bufferize-arithmetic-dialect-ops>¶</a></h3><p>This pass bufferizes arith dialect ops.</p><p>This pass needs to be a module pass because it inserts memref.global
ops into the module, which cannot be done safely from a function pass due to
multi-threading. Most other bufferization passes can run in parallel at
function granularity.</p><h4 id=options-31>Options&nbsp;<a class=headline-hash href=#options-31>¶</a></h4><pre><code>-alignment : Create global memrefs with a specified alignment
</code></pre><h3 id=-arith-expand-legalize-arithmetic-ops-to-be-convertible-to-llvm><code>-arith-expand</code>: Legalize Arithmetic ops to be convertible to LLVM.&nbsp;<a class=headline-hash href=#-arith-expand-legalize-arithmetic-ops-to-be-convertible-to-llvm>¶</a></h3><h2 id=func-dialect-passes><code>func</code> Dialect Passes&nbsp;<a class=headline-hash href=#func-dialect-passes>¶</a></h2><h3 id=-func-bufferize-bufferize-funccallreturn-ops><code>-func-bufferize</code>: Bufferize func/call/return ops&nbsp;<a class=headline-hash href=#-func-bufferize-bufferize-funccallreturn-ops>¶</a></h3><p>A bufferize pass that bufferizes func.func and func.call ops.</p><p>Because this pass updates func.func ops, it must be a module pass. It is
useful to keep this pass separate from other bufferizations so that the
other ones can be run at function-level in parallel.</p><p>This pass must be done atomically because it changes func op signatures,
which requires atomically updating calls as well throughout the entire
module.</p><p>This pass also changes the type of block arguments, which requires that all
successor arguments of predecessors be converted. This is achieved by
rewriting terminators based on the information provided by the
<code>BranchOpInterface</code>.
As this pass rewrites function operations, it also rewrites the
corresponding return operations. Other return-like operations that
implement the <code>ReturnLike</code> trait are not rewritten in general, as they
require that the corresponding parent operation is also rewritten.
Finally, this pass fails for unknown terminators, as we cannot decide
whether they need rewriting.</p><h2 id=gpu-dialect-passes><code>gpu</code> Dialect Passes&nbsp;<a class=headline-hash href=#gpu-dialect-passes>¶</a></h2><h3 id=-gpu-async-region-make-gpu-ops-async><code>-gpu-async-region</code>: Make GPU ops async&nbsp;<a class=headline-hash href=#-gpu-async-region-make-gpu-ops-async>¶</a></h3><h3 id=-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions><code>-gpu-kernel-outlining</code>: Outline gpu.launch bodies to kernel functions&nbsp;<a class=headline-hash href=#-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions>¶</a></h3><h3 id=-gpu-launch-sink-index-computations-sink-index-computations-into-gpulaunch-body><code>-gpu-launch-sink-index-computations</code>: Sink index computations into gpu.launch body&nbsp;<a class=headline-hash href=#-gpu-launch-sink-index-computations-sink-index-computations-into-gpulaunch-body>¶</a></h3><h2 id=linalg-dialect-passes><code>linalg</code> Dialect Passes&nbsp;<a class=headline-hash href=#linalg-dialect-passes>¶</a></h2><h3 id=-convert-elementwise-to-linalg-convert-elementwisemappable-ops-to-linalg><code>-convert-elementwise-to-linalg</code>: Convert ElementwiseMappable ops to linalg&nbsp;<a class=headline-hash href=#-convert-elementwise-to-linalg-convert-elementwisemappable-ops-to-linalg>¶</a></h3><p>Convert ops with the <code>ElementwiseMappable</code> trait to linalg parallel loops.</p><p>This pass only converts ops that operate on ranked tensors. It can be
run on op which contains linalg ops (most commonly a
FunctionOpInterface op).</p><h3 id=-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops><code>-convert-linalg-to-affine-loops</code>: Lower the operations from the linalg dialect into affine loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops>¶</a></h3><h3 id=-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops><code>-convert-linalg-to-loops</code>: Lower the operations from the linalg dialect into loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops>¶</a></h3><h3 id=-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops><code>-convert-linalg-to-parallel-loops</code>: Lower the operations from the linalg dialect into parallel loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops>¶</a></h3><h3 id=-linalg-bufferize-bufferize-the-linalg-dialect><code>-linalg-bufferize</code>: Bufferize the linalg dialect&nbsp;<a class=headline-hash href=#-linalg-bufferize-bufferize-the-linalg-dialect>¶</a></h3><h3 id=-linalg-detensorize-detensorize-linalg-ops><code>-linalg-detensorize</code>: Detensorize linalg ops&nbsp;<a class=headline-hash href=#-linalg-detensorize-detensorize-linalg-ops>¶</a></h3><p>Detensoring is the process through which a tensor value is converted to one
or potentially more primitive value(s). During this process, operations with
such detensored operands are also converted to an equivalent form that works
on primitives.</p><p>The detensoring process is driven by linalg-on-tensor ops. In particular, a
linalg-on-tensor op is checked to see whether <em>all</em> its operands can be
detensored. If so, those operands are converted to their primitive
counterparts and the linalg op is replaced by an equivalent op that takes
those new primitive values as operands. Therefore, detensoring an op can be
divided into 2 main logical phases:</p><ol><li>Detect/match an op that can be detensored.</li><li>Detensor the operands of the op and replace it with a primitive
equivalent.</li></ol><p>In addition to detensoring individual ops, this pass detensors internal
control flow inside a function. All blocks except for the entry block are
detensored by converting their arguments whenever possible.</p><p>This can be run on any FunctionOpInterface op and must not be
run on others. This is because it performs specific legalization of the
blocks that make up the body, which it assumes has is a FunctionOpInterface.</p><h4 id=options-32>Options&nbsp;<a class=headline-hash href=#options-32>¶</a></h4><pre><code>-aggressive-mode : Detensorize all ops that qualify for detensoring along with branch operands and basic-block arguments.
</code></pre><h3 id=-linalg-eliminate-init-tensors-try-to-eliminate-all-init_tensor-ops><code>-linalg-eliminate-init-tensors</code>: Try to eliminate all init_tensor ops.&nbsp;<a class=headline-hash href=#-linalg-eliminate-init-tensors-try-to-eliminate-all-init_tensor-ops>¶</a></h3><p>This pass tries to eliminate all insert_slice op-anchored init_tensor ops.
I.e., when a value that is aliasing with an init_tensor op is inserted into
another tensor, this pass tries to rewrite the IR in such a way that the
destination tensor of the insert_slice op is used directly instead of the
init_tensor result.</p><h3 id=-linalg-fold-unit-extent-dims-remove-unit-extent-dimension-in-linalg-ops-on-tensors><code>-linalg-fold-unit-extent-dims</code>: Remove unit-extent dimension in Linalg ops on tensors&nbsp;<a class=headline-hash href=#-linalg-fold-unit-extent-dims-remove-unit-extent-dimension-in-linalg-ops-on-tensors>¶</a></h3><h4 id=options-33>Options&nbsp;<a class=headline-hash href=#options-33>¶</a></h4><pre><code>-fold-one-trip-loops-only : Only folds the one-trip loops from Linalg ops on tensors (for testing purposes only)
</code></pre><h3 id=-linalg-fuse-elementwise-ops-fuse-elementwise-operations-on-tensors><code>-linalg-fuse-elementwise-ops</code>: Fuse elementwise operations on tensors&nbsp;<a class=headline-hash href=#-linalg-fuse-elementwise-ops-fuse-elementwise-operations-on-tensors>¶</a></h3><h3 id=-linalg-generalize-named-ops-convert-named-ops-into-generic-ops><code>-linalg-generalize-named-ops</code>: Convert named ops into generic ops&nbsp;<a class=headline-hash href=#-linalg-generalize-named-ops-convert-named-ops-into-generic-ops>¶</a></h3><h3 id=-linalg-inline-scalar-operands-inline-scalar-operands-into-linalg-generic-ops><code>-linalg-inline-scalar-operands</code>: Inline scalar operands into linalg generic ops&nbsp;<a class=headline-hash href=#-linalg-inline-scalar-operands-inline-scalar-operands-into-linalg-generic-ops>¶</a></h3><h3 id=-linalg-named-op-conversion-convert-from-one-named-linalg-op-to-another><code>-linalg-named-op-conversion</code>: Convert from one named linalg op to another.&nbsp;<a class=headline-hash href=#-linalg-named-op-conversion-convert-from-one-named-linalg-op-to-another>¶</a></h3><h3 id=-linalg-promote-subviews-promote-subview-ops-to-local-buffers><code>-linalg-promote-subviews</code>: Promote subview ops to local buffers&nbsp;<a class=headline-hash href=#-linalg-promote-subviews-promote-subview-ops-to-local-buffers>¶</a></h3><h4 id=options-34>Options&nbsp;<a class=headline-hash href=#options-34>¶</a></h4><pre><code>-test-promote-dynamic : Test generation of dynamic promoted buffers
-test-use-alloca      : Test generation of alloca'ed buffers.
</code></pre><h3 id=-linalg-strategy-decompose-pass-configurable-pass-to-apply-pattern-based-generalization><code>-linalg-strategy-decompose-pass</code>: Configurable pass to apply pattern-based generalization.&nbsp;<a class=headline-hash href=#-linalg-strategy-decompose-pass-configurable-pass-to-apply-pattern-based-generalization>¶</a></h3><h4 id=options-35>Options&nbsp;<a class=headline-hash href=#options-35>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-enable-pass-configurable-pass-to-enable-the-application-of-other-pattern-based-linalg-passes><code>-linalg-strategy-enable-pass</code>: Configurable pass to enable the application of other pattern-based linalg passes.&nbsp;<a class=headline-hash href=#-linalg-strategy-enable-pass-configurable-pass-to-enable-the-application-of-other-pattern-based-linalg-passes>¶</a></h3><h4 id=options-36>Options&nbsp;<a class=headline-hash href=#options-36>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-generalize-pass-configurable-pass-to-apply-pattern-based-generalization><code>-linalg-strategy-generalize-pass</code>: Configurable pass to apply pattern-based generalization.&nbsp;<a class=headline-hash href=#-linalg-strategy-generalize-pass-configurable-pass-to-apply-pattern-based-generalization>¶</a></h3><h4 id=options-37>Options&nbsp;<a class=headline-hash href=#options-37>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
-anchor-op   : Which linalg op within the func is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-interchange-pass-configurable-pass-to-apply-pattern-based-iterator-interchange><code>-linalg-strategy-interchange-pass</code>: Configurable pass to apply pattern-based iterator interchange.&nbsp;<a class=headline-hash href=#-linalg-strategy-interchange-pass-configurable-pass-to-apply-pattern-based-iterator-interchange>¶</a></h3><h4 id=options-38>Options&nbsp;<a class=headline-hash href=#options-38>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-lower-vectors-pass-configurable-pass-to-lower-vector-operations><code>-linalg-strategy-lower-vectors-pass</code>: Configurable pass to lower vector operations.&nbsp;<a class=headline-hash href=#-linalg-strategy-lower-vectors-pass-configurable-pass-to-lower-vector-operations>¶</a></h3><h4 id=options-39>Options&nbsp;<a class=headline-hash href=#options-39>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-pad-pass-configurable-pass-to-apply-padding-and-hoisting><code>-linalg-strategy-pad-pass</code>: Configurable pass to apply padding and hoisting.&nbsp;<a class=headline-hash href=#-linalg-strategy-pad-pass-configurable-pass-to-apply-padding-and-hoisting>¶</a></h3><h4 id=options-40>Options&nbsp;<a class=headline-hash href=#options-40>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
-anchor-op   : Which linalg op within the func is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-promote-pass-configurable-pass-to-apply-pattern-based-linalg-promotion><code>-linalg-strategy-promote-pass</code>: Configurable pass to apply pattern-based linalg promotion.&nbsp;<a class=headline-hash href=#-linalg-strategy-promote-pass-configurable-pass-to-apply-pattern-based-linalg-promotion>¶</a></h3><h4 id=options-41>Options&nbsp;<a class=headline-hash href=#options-41>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
-anchor-op   : Which linalg op within the func is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-remove-markers-pass-cleanup-pass-that-drops-markers><code>-linalg-strategy-remove-markers-pass</code>: Cleanup pass that drops markers.&nbsp;<a class=headline-hash href=#-linalg-strategy-remove-markers-pass-cleanup-pass-that-drops-markers>¶</a></h3><h4 id=options-42>Options&nbsp;<a class=headline-hash href=#options-42>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-tile-and-fuse-pass-configurable-pass-to-apply-pattern-based-tiling-and-fusion><code>-linalg-strategy-tile-and-fuse-pass</code>: Configurable pass to apply pattern-based tiling and fusion.&nbsp;<a class=headline-hash href=#-linalg-strategy-tile-and-fuse-pass-configurable-pass-to-apply-pattern-based-tiling-and-fusion>¶</a></h3><h4 id=options-43>Options&nbsp;<a class=headline-hash href=#options-43>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
-anchor-op   : Which linalg op within the func is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-tile-pass-configurable-pass-to-apply-pattern-based-linalg-tiling><code>-linalg-strategy-tile-pass</code>: Configurable pass to apply pattern-based linalg tiling.&nbsp;<a class=headline-hash href=#-linalg-strategy-tile-pass-configurable-pass-to-apply-pattern-based-linalg-tiling>¶</a></h3><h4 id=options-44>Options&nbsp;<a class=headline-hash href=#options-44>¶</a></h4><pre><code>-anchor-func : Which func op is the anchor to latch on.
-anchor-op   : Which linalg op within the func is the anchor to latch on.
</code></pre><h3 id=-linalg-strategy-vectorize-pass-configurable-pass-to-apply-pattern-based-linalg-vectorization><code>-linalg-strategy-vectorize-pass</code>: Configurable pass to apply pattern-based linalg vectorization.&nbsp;<a class=headline-hash href=#-linalg-strategy-vectorize-pass-configurable-pass-to-apply-pattern-based-linalg-vectorization>¶</a></h3><h4 id=options-45>Options&nbsp;<a class=headline-hash href=#options-45>¶</a></h4><pre><code>-anchor-func       : Which func op is the anchor to latch on.
-anchor-op         : Which linalg op within the func is the anchor to latch on.
-vectorize-padding : Enable vectorization of padding ops.
</code></pre><h3 id=-linalg-tile-tile-operations-in-the-linalg-dialect><code>-linalg-tile</code>: Tile operations in the linalg dialect&nbsp;<a class=headline-hash href=#-linalg-tile-tile-operations-in-the-linalg-dialect>¶</a></h3><h4 id=options-46>Options&nbsp;<a class=headline-hash href=#options-46>¶</a></h4><pre><code>-tile-sizes : Tile sizes
-loop-type  : Specify the type of loops to generate: for, parallel
</code></pre><h2 id=llvm-dialect-passes><code>llvm</code> Dialect Passes&nbsp;<a class=headline-hash href=#llvm-dialect-passes>¶</a></h2><h3 id=-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir><code>-llvm-legalize-for-export</code>: Legalize LLVM dialect to be convertible to LLVM IR&nbsp;<a class=headline-hash href=#-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir>¶</a></h3><h2 id=memref-dialect-passes><code>memref</code> Dialect Passes&nbsp;<a class=headline-hash href=#memref-dialect-passes>¶</a></h2><h3 id=-fold-memref-subview-ops-fold-memrefsubview-ops-into-consumer-loadstore-ops><code>-fold-memref-subview-ops</code>: Fold memref.subview ops into consumer load/store ops&nbsp;<a class=headline-hash href=#-fold-memref-subview-ops-fold-memrefsubview-ops-into-consumer-loadstore-ops>¶</a></h3><p>The pass folds loading/storing from/to subview ops to loading/storing
from/to the original memref.</p><h3 id=-memref-expand-legalize-memref-operations-to-be-convertible-to-llvm><code>-memref-expand</code>: Legalize memref operations to be convertible to LLVM.&nbsp;<a class=headline-hash href=#-memref-expand-legalize-memref-operations-to-be-convertible-to-llvm>¶</a></h3><h3 id=-normalize-memrefs-normalize-memrefs><code>-normalize-memrefs</code>: Normalize memrefs&nbsp;<a class=headline-hash href=#-normalize-memrefs-normalize-memrefs>¶</a></h3><p>This pass transforms memref types with a non-trivial
<a href=https://mlir.llvm.org/docs/LangRef/#layout-map>layout map</a> into
memref types with an identity layout map, e.g. (i, j) -> (i, j). This
pass is inter-procedural, in the sense that it can modify function
interfaces and call sites that pass memref types. In order to modify
memref types while preserving the original behavior, users of those
memref types are also modified to incorporate the resulting layout map.
For instance, an [AffineLoadOp]
(<a href=https://mlir.llvm.org/docs/Dialects/Affine/#affineload-affineloadop>https://mlir.llvm.org/docs/Dialects/Affine/#affineload-affineloadop</a>)
will be updated to compose the layout map with with the affine expression
contained in the op. Operations marked with the [MemRefsNormalizable]
(<a href=https://mlir.llvm.org/docs/Traits/#memrefsnormalizable>https://mlir.llvm.org/docs/Traits/#memrefsnormalizable</a>) trait are
expected to be normalizable. Supported operations include affine
operations, memref.alloc, memref.dealloc, and func.return.</p><p>Given an appropriate layout map specified in the code, this transformation
can express tiled or linearized access to multi-dimensional data
structures, but will not modify memref types without an explicit layout
map.</p><p>Currently this pass is limited to only modify
functions where all memref types can be normalized. If a function
contains any operations that are not MemRefNormalizable, then the function
and any functions that call or call it will not be modified.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>#tile</span> <span class=p>=</span> affine_map<span class=p>&lt;(</span>i<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i floordiv <span class=m>4</span><span class=p>,</span> i mod <span class=m>4</span><span class=p>)&gt;</span>
<span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@matmul</span><span class=p>(</span><span class=nv>%A</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;,</span>
             <span class=nv>%B</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%C</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;)</span> <span class=p>{</span>
  affine<span class=p>.</span>for <span class=nv>%arg3</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>16</span> <span class=p>{</span>
        <span class=nv>%a</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%A</span><span class=p>[</span><span class=nv>%arg3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
        <span class=nv>%p</span> <span class=p>=</span> arith<span class=p>.</span>mulf <span class=nv>%a</span><span class=p>,</span> <span class=nv>%a</span> <span class=p>:</span> <span class=k>f64</span>
        affine<span class=p>.</span>store <span class=nv>%p</span><span class=p>,</span> <span class=nv>%A</span><span class=p>[</span><span class=nv>%arg3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=nv>%c</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
  <span class=nv>%d</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%c</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
  <span class=kt>return</span> <span class=nv>%A</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@matmul</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>&gt;)</span>
  <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span> <span class=p>{</span>
  affine<span class=p>.</span>for <span class=nv>%arg3</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>16</span> <span class=p>{</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg3</span> floordiv <span class=m>4</span><span class=p>,</span> <span class=nv>%arg3</span> mod <span class=m>4</span><span class=p>]:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
    <span class=nv>%4</span> <span class=p>=</span> arith<span class=p>.</span>mulf <span class=nv>%3</span><span class=p>,</span> <span class=nv>%3</span> <span class=p>:</span> <span class=k>f64</span>
    affine<span class=p>.</span>store <span class=nv>%4</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg3</span> floordiv <span class=m>4</span><span class=p>,</span> <span class=nv>%arg3</span> mod <span class=m>4</span><span class=p>]:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=nv>%0</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
  <span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map1</span><span class=p>()</span>
  <span class=nv>%2</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%0</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
  <span class=kt>return</span> <span class=nv>%arg0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Input</p><pre><code>#linear8 = affine_map&lt;(i, j) -&gt; (i * 8 + j)&gt;
func.func @linearize(%arg0: memref&lt;8x8xi32, #linear8&gt;,
                %arg1: memref&lt;8x8xi32, #linear8&gt;,
                %arg2: memref&lt;8x8xi32, #linear8&gt;) {
  %c8 = arith.constant 8 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  affine.for %arg3 = %c0 to %c8  {
  affine.for %arg4 = %c0 to %c8  {
    affine.for %arg5 = %c0 to %c8 {
      %0 = affine.load %arg0[%arg3, %arg5] : memref&lt;8x8xi32, #linear8&gt;
      %1 = affine.load %arg1[%arg5, %arg4] : memref&lt;8x8xi32, #linear8&gt;
      %2 = affine.load %arg2[%arg3, %arg4] : memref&lt;8x8xi32, #linear8&gt;
      %3 = arith.muli %0, %1 : i32
      %4 = arith.addi %2, %3 : i32
      affine.store %4, %arg2[%arg3, %arg4] : memref&lt;8x8xi32, #linear8&gt;
    }
  }
  }
  return
}
</code></pre><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@linearize</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;,</span>
                <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;,</span>
                <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;)</span> <span class=p>{</span>
<span class=nv>%c8</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>8</span> <span class=p>:</span> <span class=k>index</span>
<span class=nv>%c0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
affine<span class=p>.</span>for <span class=nv>%arg3</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%c8</span> <span class=p>{</span>
  affine<span class=p>.</span>for <span class=nv>%arg4</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%c8</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%arg5</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%c8</span> <span class=p>{</span>
      <span class=nv>%0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg3</span> <span class=p>*</span> <span class=m>8</span> <span class=err>+</span> <span class=nv>%arg5</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span>
      <span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%arg5</span> <span class=p>*</span> <span class=m>8</span> <span class=err>+</span> <span class=nv>%arg4</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span>
      <span class=nv>%2</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg2</span><span class=p>[</span><span class=nv>%arg3</span> <span class=p>*</span> <span class=m>8</span> <span class=err>+</span> <span class=nv>%arg4</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span>
      <span class=nv>%3</span> <span class=p>=</span> arith<span class=p>.</span>muli <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>:</span> <span class=k>i32</span>
      <span class=nv>%4</span> <span class=p>=</span> arith<span class=p>.</span>addi <span class=nv>%2</span><span class=p>,</span> <span class=nv>%3</span> <span class=p>:</span> <span class=k>i32</span>
      affine<span class=p>.</span>store <span class=nv>%4</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>[</span><span class=nv>%arg3</span> <span class=p>*</span> <span class=m>8</span> <span class=err>+</span> <span class=nv>%arg4</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span>
    <span class=p>}</span>
  <span class=p>}</span>
<span class=p>}</span>
<span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><h3 id=-resolve-ranked-shaped-type-result-dims-resolve-memrefdim-of-result-values-of-ranked-shape-type><code>-resolve-ranked-shaped-type-result-dims</code>: Resolve memref.dim of result values of ranked shape type&nbsp;<a class=headline-hash href=#-resolve-ranked-shaped-type-result-dims-resolve-memrefdim-of-result-values-of-ranked-shape-type>¶</a></h3><p>The pass resolves memref.dim of result of operations that
implement the <code>ReifyRankedShapedTypeOpInterface</code> in terms of
shapes of its operands.</p><h3 id=-resolve-shaped-type-result-dims-resolve-memrefdim-of-result-values><code>-resolve-shaped-type-result-dims</code>: Resolve memref.dim of result values&nbsp;<a class=headline-hash href=#-resolve-shaped-type-result-dims-resolve-memrefdim-of-result-values>¶</a></h3><p>The pass resolves memref.dim of result of operations that
implement the <code>InferShapedTypeOpInterface</code> or
<code>ReifyRankedShapedTypeOpInterface</code> in terms of shapes of its
operands.</p><h2 id=quant-dialect-passes><code>quant</code> Dialect Passes&nbsp;<a class=headline-hash href=#quant-dialect-passes>¶</a></h2><h3 id=-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values><code>-quant-convert-const</code>: Converts constants followed by qbarrier to actual quantized values&nbsp;<a class=headline-hash href=#-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values>¶</a></h3><h3 id=-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts><code>-quant-convert-simulated-quantization</code>: Converts training-time simulated quantization ops to corresponding quantize/dequantize casts&nbsp;<a class=headline-hash href=#-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts>¶</a></h3><h2 id=reducer-passes>Reducer Passes&nbsp;<a class=headline-hash href=#reducer-passes>¶</a></h2><h3 id=-opt-reduction-pass-a-wrapper-pass-that-reduces-the-file-with-optimization-passes><code>-opt-reduction-pass</code>: A wrapper pass that reduces the file with optimization passes&nbsp;<a class=headline-hash href=#-opt-reduction-pass-a-wrapper-pass-that-reduces-the-file-with-optimization-passes>¶</a></h3><h4 id=options-47>Options&nbsp;<a class=headline-hash href=#options-47>¶</a></h4><pre><code>-opt-pass : The optimization passes used for reduction, e.g., symbol-dce
-test     : The location of the tester which tests the file interestingness
-test-arg : arguments of the tester
</code></pre><h3 id=-reduction-tree-reduce-the-input-with-reduction-tree-algorithm><code>-reduction-tree</code>: Reduce the input with reduction-tree algorithm&nbsp;<a class=headline-hash href=#-reduction-tree-reduce-the-input-with-reduction-tree-algorithm>¶</a></h3><h4 id=options-48>Options&nbsp;<a class=headline-hash href=#options-48>¶</a></h4><pre><code>-traversal-mode : The graph traversal mode, the default is single-path mode
-test           : The location of the tester which tests the file interestingness
-test-arg       : arguments of the tester
</code></pre><h2 id=scf-dialect-passes><code>scf</code> Dialect Passes&nbsp;<a class=headline-hash href=#scf-dialect-passes>¶</a></h2><h3 id=-scf-bufferize-bufferize-the-scf-dialect><code>-scf-bufferize</code>: Bufferize the scf dialect.&nbsp;<a class=headline-hash href=#-scf-bufferize-bufferize-the-scf-dialect>¶</a></h3><h3 id=-scf-for-loop-canonicalization-canonicalize-operations-within-scffor-loop-bodies><code>-scf-for-loop-canonicalization</code>: Canonicalize operations within scf.for loop bodies&nbsp;<a class=headline-hash href=#-scf-for-loop-canonicalization-canonicalize-operations-within-scffor-loop-bodies>¶</a></h3><h3 id=-scf-for-loop-peeling-peel-for-loops-at-their-upper-bounds><code>-scf-for-loop-peeling</code>: Peel <code>for</code> loops at their upper bounds.&nbsp;<a class=headline-hash href=#-scf-for-loop-peeling-peel-for-loops-at-their-upper-bounds>¶</a></h3><h4 id=options-49>Options&nbsp;<a class=headline-hash href=#options-49>¶</a></h4><pre><code>-skip-partial : Do not peel loops inside of the last, partial iteration of another already peeled loop.
</code></pre><h3 id=-scf-for-loop-range-folding-fold-addmul-ops-into-loop-range><code>-scf-for-loop-range-folding</code>: Fold add/mul ops into loop range&nbsp;<a class=headline-hash href=#-scf-for-loop-range-folding-fold-addmul-ops-into-loop-range>¶</a></h3><h3 id=-scf-for-loop-specialization-specialize-for-loops-for-vectorization><code>-scf-for-loop-specialization</code>: Specialize <code>for</code> loops for vectorization&nbsp;<a class=headline-hash href=#-scf-for-loop-specialization-specialize-for-loops-for-vectorization>¶</a></h3><h3 id=-scf-for-to-while-convert-scf-for-loops-to-scf-while-loops><code>-scf-for-to-while</code>: Convert SCF for loops to SCF while loops&nbsp;<a class=headline-hash href=#-scf-for-to-while-convert-scf-for-loops-to-scf-while-loops>¶</a></h3><p>This pass transforms SCF.ForOp operations to SCF.WhileOp. The For loop
condition is placed in the &lsquo;before&rsquo; region of the while operation, and the
induction variable incrementation and loop body in the &lsquo;after&rsquo; region.
The loop carried values of the while op are the induction variable (IV) of
the for-loop + any iter_args specified for the for-loop.
Any &lsquo;yield&rsquo; ops in the for-loop are rewritten to additionally yield the
(incremented) induction variable.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  scf<span class=p>.</span>for <span class=nv>%i</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%arg1</span> step <span class=nv>%c1</span> <span class=p>{</span>
    <span class=nv>%0</span> <span class=p>=</span> arith<span class=p>.</span>addi <span class=nv>%arg2</span><span class=p>,</span> <span class=nv>%arg2</span> <span class=p>:</span> <span class=k>i32</span>
    <span class=kt>memref</span><span class=p>.</span>store <span class=nv>%0</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%i</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>i32</span><span class=p>&gt;</span>
  <span class=p>}</span>

<span class=err>#</span> After<span class=p>:</span>
  <span class=nv>%0</span> <span class=p>=</span> scf<span class=p>.</span>while <span class=p>(</span><span class=nv>%i</span> <span class=p>=</span> <span class=nv>%c0</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>index</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>index</span> <span class=p>{</span>
    <span class=nv>%1</span> <span class=p>=</span> arith<span class=p>.</span>cmpi slt<span class=p>,</span> <span class=nv>%i</span><span class=p>,</span> <span class=nv>%arg1</span> <span class=p>:</span> <span class=k>index</span>
    scf<span class=p>.</span>condition<span class=p>(</span><span class=nv>%1</span><span class=p>)</span> <span class=nv>%i</span> <span class=p>:</span> <span class=k>index</span>
  <span class=p>}</span> do <span class=p>{</span>
  <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%i</span><span class=p>:</span> <span class=k>index</span><span class=p>):</span>
    <span class=nv>%1</span> <span class=p>=</span> arith<span class=p>.</span>addi <span class=nv>%i</span><span class=p>,</span> <span class=nv>%c1</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%2</span> <span class=p>=</span> arith<span class=p>.</span>addi <span class=nv>%arg2</span><span class=p>,</span> <span class=nv>%arg2</span> <span class=p>:</span> <span class=k>i32</span>
    <span class=kt>memref</span><span class=p>.</span>store <span class=nv>%2</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%i</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>i32</span><span class=p>&gt;</span>
    scf<span class=p>.</span>yield <span class=nv>%1</span> <span class=p>:</span> <span class=k>index</span>
  <span class=p>}</span>
</code></pre></div><h3 id=-scf-parallel-loop-collapsing-collapse-parallel-loops-to-use-less-induction-variables><code>-scf-parallel-loop-collapsing</code>: Collapse parallel loops to use less induction variables&nbsp;<a class=headline-hash href=#-scf-parallel-loop-collapsing-collapse-parallel-loops-to-use-less-induction-variables>¶</a></h3><h4 id=options-50>Options&nbsp;<a class=headline-hash href=#options-50>¶</a></h4><pre><code>-collapsed-indices-0 : Which loop indices to combine 0th loop index
-collapsed-indices-1 : Which loop indices to combine into the position 1 loop index
-collapsed-indices-2 : Which loop indices to combine into the position 2 loop index
</code></pre><h3 id=-scf-parallel-loop-fusion-fuse-adjacent-parallel-loops><code>-scf-parallel-loop-fusion</code>: Fuse adjacent parallel loops&nbsp;<a class=headline-hash href=#-scf-parallel-loop-fusion-fuse-adjacent-parallel-loops>¶</a></h3><h3 id=-scf-parallel-loop-specialization-specialize-parallel-loops-for-vectorization><code>-scf-parallel-loop-specialization</code>: Specialize parallel loops for vectorization&nbsp;<a class=headline-hash href=#-scf-parallel-loop-specialization-specialize-parallel-loops-for-vectorization>¶</a></h3><h3 id=-scf-parallel-loop-tiling-tile-parallel-loops><code>-scf-parallel-loop-tiling</code>: Tile parallel loops&nbsp;<a class=headline-hash href=#-scf-parallel-loop-tiling-tile-parallel-loops>¶</a></h3><h4 id=options-51>Options&nbsp;<a class=headline-hash href=#options-51>¶</a></h4><pre><code>-parallel-loop-tile-sizes : Factors to tile parallel loops by
-no-min-max-bounds        : Perform tiling with fixed upper bound with inbound check inside the internal loops
</code></pre><h2 id=shape-dialect-passes><code>shape</code> Dialect Passes&nbsp;<a class=headline-hash href=#shape-dialect-passes>¶</a></h2><h3 id=-remove-shape-constraints-replace-all-cstr_-ops-with-a-true-witness><code>-remove-shape-constraints</code>: Replace all cstr_ ops with a true witness&nbsp;<a class=headline-hash href=#-remove-shape-constraints-replace-all-cstr_-ops-with-a-true-witness>¶</a></h3><h3 id=-shape-bufferize-bufferize-the-shape-dialect><code>-shape-bufferize</code>: Bufferize the shape dialect.&nbsp;<a class=headline-hash href=#-shape-bufferize-bufferize-the-shape-dialect>¶</a></h3><h3 id=-shape-to-shape-lowering-legalize-shape-dialect-to-be-convertible-to-arithmetic><code>-shape-to-shape-lowering</code>: Legalize Shape dialect to be convertible to Arithmetic&nbsp;<a class=headline-hash href=#-shape-to-shape-lowering-legalize-shape-dialect-to-be-convertible-to-arithmetic>¶</a></h3><h2 id=sparse_tensor-dialect-passes><code>sparse_tensor</code> Dialect Passes&nbsp;<a class=headline-hash href=#sparse_tensor-dialect-passes>¶</a></h2><h3 id=-sparse-tensor-conversion-apply-conversion-rules-to-sparse-tensor-primitives-and-types><code>-sparse-tensor-conversion</code>: Apply conversion rules to sparse tensor primitives and types&nbsp;<a class=headline-hash href=#-sparse-tensor-conversion-apply-conversion-rules-to-sparse-tensor-primitives-and-types>¶</a></h3><p>A pass that converts sparse tensor primitives to calls into a runtime
support library. All sparse tensor types are converted into opaque
pointers to the underlying sparse storage schemes.</p><p>Note that this is a current implementation choice to keep the conversion
relatively simple. In principle, these primitives could also be
converted to actual elaborate IR code that implements the primitives
on the selected sparse tensor storage schemes.</p><p>Example of the conversion:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  Before<span class=p>:</span>
    <span class=nv>%c1</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>1</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%0</span> <span class=p>=</span> sparse_tensor<span class=p>.</span>pointers <span class=nv>%arg0</span><span class=p>,</span> <span class=nv>%c1</span>
      <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>8x8x</span><span class=k>f32</span><span class=p>,</span> <span class=nv>#sparse_tensor.encoding</span><span class=p>&lt;{</span>
          <span class=nl>dimLevelType =</span> <span class=p>[</span> <span class=s>&#34;dense&#34;</span><span class=p>,</span> <span class=s>&#34;compressed&#34;</span> <span class=p>],</span>
          <span class=nl>pointerBitWidth =</span> <span class=m>0</span><span class=p>,</span>
          <span class=nl>indexBitWidth =</span> <span class=m>0</span>
        <span class=p>}&gt;&gt;</span> to <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>index</span><span class=p>&gt;</span>

  After<span class=p>:</span>
    <span class=nv>%c1</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>1</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%0</span> <span class=p>=</span> call <span class=nf>@sparsePointers</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>,</span> <span class=nv>%c1</span><span class=p>)</span> <span class=p>:</span> <span class=p>(!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=k>i8</span><span class=p>&gt;,</span> <span class=k>index</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>index</span><span class=p>&gt;</span>
</code></pre></div><h4 id=options-52>Options&nbsp;<a class=headline-hash href=#options-52>¶</a></h4><pre><code>-s2s-strategy : Set the strategy for sparse-to-sparse conversion
</code></pre><h3 id=-sparsification-automatically-generate-sparse-tensor-code-from-sparse-tensor-types><code>-sparsification</code>: Automatically generate sparse tensor code from sparse tensor types&nbsp;<a class=headline-hash href=#-sparsification-automatically-generate-sparse-tensor-code-from-sparse-tensor-types>¶</a></h3><p>A pass that implements the core functionality of a <strong>sparse compiler</strong>.
Each Linalg operation (MLIR&rsquo;s tensor index notation) that operates on
sparse tensor types is converted into code in which the sparsity is
explicit both in terms of co-iterating looping logic as well as
selected sparse storage schemes.</p><p>See the <code>SparseTensor</code> dialect documentation for more background.</p><p>Example input:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>#matvec</span> <span class=p>=</span> <span class=p>{</span>
  <span class=nl>indexing_maps =</span> <span class=p>[</span>
    affine_map<span class=p>&lt;(</span>i<span class=p>,</span>j<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>,</span>j<span class=p>)&gt;,</span> <span class=c>// A
</span><span class=c></span>    affine_map<span class=p>&lt;(</span>i<span class=p>,</span>j<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>j<span class=p>)&gt;,</span>   <span class=c>// b
</span><span class=c></span>    affine_map<span class=p>&lt;(</span>i<span class=p>,</span>j<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>)&gt;</span>    <span class=c>// x (out)
</span><span class=c></span>  <span class=p>],</span>
  <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;reduction&#34;</span><span class=p>],</span>
  <span class=nl>doc =</span> <span class=s>&#34;X(i) += A(i,j) * B(j)&#34;</span>
<span class=p>}</span>

<span class=c>// Multiply a sparse matrix A with a dense vector b into a dense vector x.
</span><span class=c></span><span class=kt>func</span><span class=p>.</span><span class=kt>func</span> <span class=nf>@kernel_matvec</span><span class=p>(</span><span class=nv>%arga</span><span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#SparseMatrix</span><span class=p>&gt;,</span>
                    <span class=nv>%argb</span><span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f64</span><span class=p>&gt;,</span>
                    <span class=nv>%argx</span><span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f64</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f64</span><span class=p>&gt;</span> <span class=p>{</span>
  <span class=nv>%0</span> <span class=p>=</span> linalg<span class=p>.</span>generic <span class=nv>#matvec</span>
    ins<span class=p>(</span><span class=nv>%arga</span><span class=p>,</span> <span class=nv>%argb</span><span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#SparseMatrix</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f64</span><span class=p>&gt;)</span>
    outs<span class=p>(</span><span class=nv>%argx</span><span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f64</span><span class=p>&gt;)</span> <span class=p>{</span>
    <span class=nl>^bb</span><span class=p>(</span><span class=nv>%a</span><span class=p>:</span> <span class=k>f64</span><span class=p>,</span> <span class=nv>%b</span><span class=p>:</span> <span class=k>f64</span><span class=p>,</span> <span class=nv>%x</span><span class=p>:</span> <span class=k>f64</span><span class=p>):</span>
      <span class=nv>%0</span> <span class=p>=</span> arith<span class=p>.</span>mulf <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span> <span class=p>:</span> <span class=k>f64</span>
      <span class=nv>%1</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%x</span><span class=p>,</span> <span class=nv>%0</span> <span class=p>:</span> <span class=k>f64</span>
      linalg<span class=p>.</span>yield <span class=nv>%1</span> <span class=p>:</span> <span class=k>f64</span>
  <span class=p>}</span> <span class=p>-&gt;</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f64</span><span class=p>&gt;</span>
  <span class=kt>return</span> <span class=nv>%0</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f64</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><h4 id=options-53>Options&nbsp;<a class=headline-hash href=#options-53>¶</a></h4><pre><code>-parallelization-strategy : Set the parallelization strategy
-vectorization-strategy   : Set the vectorization strategy
-vl                       : Set the vector length
-enable-simd-index32      : Enable i32 indexing into vectors (for efficiency)
-enable-vla-vectorization : Enable vector length agnostic vectorization
</code></pre><h2 id=spv-dialect-passes><code>spv</code> Dialect Passes&nbsp;<a class=headline-hash href=#spv-dialect-passes>¶</a></h2><h3 id=-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info><code>-decorate-spirv-composite-type-layout</code>: Decorate SPIR-V composite type with layout info&nbsp;<a class=headline-hash href=#-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info>¶</a></h3><h3 id=-spirv-canonicalize-glsl-run-canonicalization-involving-glsl-ops><code>-spirv-canonicalize-glsl</code>: Run canonicalization involving GLSL ops&nbsp;<a class=headline-hash href=#-spirv-canonicalize-glsl-run-canonicalization-involving-glsl-ops>¶</a></h3><h3 id=-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info><code>-spirv-lower-abi-attrs</code>: Decorate SPIR-V composite type with layout info&nbsp;<a class=headline-hash href=#-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info>¶</a></h3><h3 id=-spirv-rewrite-inserts-rewrite-sequential-chains-of-spvcompositeinsert-operations-into-spvcompositeconstruct-operations><code>-spirv-rewrite-inserts</code>: Rewrite sequential chains of spv.CompositeInsert operations into spv.CompositeConstruct operations&nbsp;<a class=headline-hash href=#-spirv-rewrite-inserts-rewrite-sequential-chains-of-spvcompositeinsert-operations-into-spvcompositeconstruct-operations>¶</a></h3><h3 id=-spirv-unify-aliased-resource-unify-access-of-multiple-aliased-resources-into-access-of-one-single-resource><code>-spirv-unify-aliased-resource</code>: Unify access of multiple aliased resources into access of one single resource&nbsp;<a class=headline-hash href=#-spirv-unify-aliased-resource-unify-access-of-multiple-aliased-resources-into-access-of-one-single-resource>¶</a></h3><h3 id=-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops><code>-spirv-update-vce</code>: Deduce and attach minimal (version, capabilities, extensions) requirements to spv.module ops&nbsp;<a class=headline-hash href=#-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops>¶</a></h3><h2 id=tensor-dialect-passes><code>tensor</code> Dialect Passes&nbsp;<a class=headline-hash href=#tensor-dialect-passes>¶</a></h2><h3 id=-tensor-bufferize-bufferize-the-tensor-dialect><code>-tensor-bufferize</code>: Bufferize the <code>tensor</code> dialect&nbsp;<a class=headline-hash href=#-tensor-bufferize-bufferize-the-tensor-dialect>¶</a></h3><h2 id=vector-dialect-passes><code>vector</code> Dialect Passes&nbsp;<a class=headline-hash href=#vector-dialect-passes>¶</a></h2><h3 id=-vector-bufferize-bufferize-vector-dialect-ops><code>-vector-bufferize</code>: Bufferize Vector dialect ops&nbsp;<a class=headline-hash href=#-vector-bufferize-bufferize-vector-dialect-ops>¶</a></h3><h2 id=tosa-dialect-passes>TOSA Dialect Passes&nbsp;<a class=headline-hash href=#tosa-dialect-passes>¶</a></h2><h3 id=-tosa-infer-shapes-propagate-shapes-across-tosa-operations><code>-tosa-infer-shapes</code>: Propagate shapes across TOSA operations&nbsp;<a class=headline-hash href=#-tosa-infer-shapes-propagate-shapes-across-tosa-operations>¶</a></h3><p>Pass that uses operand types and propagates shapes to TOSA operations.
This includes legalizing rankless and dynamic shapes towards static.</p><h3 id=-tosa-make-broadcastable-tosa-rank-reshape-to-enable-broadcasting><code>-tosa-make-broadcastable</code>: TOSA rank Reshape to enable Broadcasting&nbsp;<a class=headline-hash href=#-tosa-make-broadcastable-tosa-rank-reshape-to-enable-broadcasting>¶</a></h3><p>Pass that enables broadcast by making all input arrays have the same
number of dimensions. Insert RESHAPE operations to prepend dimensions
of size one until the number of dimensions is equal. Implements
approach similar to step 1 of Numpy 4-step broadcasting:
<a href=https://numpy.org/doc/stable/reference/ufuncs.html#broadcasting>https://numpy.org/doc/stable/reference/ufuncs.html#broadcasting</a></p><h3 id=-tosa-optional-decompositions-applies-tosa-operations-optional-decompositions><code>-tosa-optional-decompositions</code>: Applies Tosa operations optional decompositions&nbsp;<a class=headline-hash href=#-tosa-optional-decompositions-applies-tosa-operations-optional-decompositions>¶</a></h3><p>Pass to apply the Tosa operations decompositions
exposed as populate functions in include/mlir/Dialect/Tosa/Transforms/Passes.h</p><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/PassManagement/ title="Pass Infrastructure"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Pass Infrastructure</a>
<a class="nav nav-next" href=/docs/PatternRewriter/ title="Pattern Rewriting : Generic DAG-to-DAG Rewriting">Next - Pattern Rewriting : Generic DAG-to-DAG Rewriting <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/pubs/>MLIR Related Publications</a></li><li><a href=/talks/>Talks</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=/docs/Tools/mlir-reduce/>MLIR Reduce</a></li></ul></li><li><a href=/docs/BufferDeallocationInternals/>Buffer Deallocation - Internals</a></li><li><a href=/docs/Bufferization/>Bufferization</a></li><li><a href=/docs/DataLayout/>Data Layout Modeling</a></li><li><a href=/docs/DebugActions/>Debug Actions</a></li><li><a href=/docs/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=/docs/DefiningDialects/>Defining Dialects</a></li><li><a href=/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li class=has-sub-menu><a href=/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=/docs/Dialects/ArithmeticOps/>'arith' Dialect</a></li><li><a href=/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=/docs/Dialects/GPU/>'gpu' Dialect</a></li><li class=has-sub-menu><a href=/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li><a href=/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li><a href=/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>'spv' Dialect</a></li><li><a href=/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li><a href=/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=/docs/ExtensibleDialects/>Extensible dialects</a></li><li><a href=/docs/Interfaces/>Interfaces</a></li><li><a href=/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=/docs/CAPI/>MLIR C API</a></li><li><a href=/docs/LangRef/>MLIR Language Reference</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=/docs/OpDefinitions/>Operation Definition Specification (ODS)</a></li><li><a href=/docs/PassManagement/>Pass Infrastructure</a></li><li class=active><a href=/docs/Passes/>Passes</a></li><li><a href=/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=/docs/ShapeInference/>Shape Inference</a></li><li><a href=/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/Traits/>Traits</a></li><li class=has-sub-menu><a href=/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>