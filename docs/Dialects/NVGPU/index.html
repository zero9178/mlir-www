<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>'nvgpu' Dialect - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.80.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Dialects/NVGPU/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>'nvgpu' Dialect</h1><p>This <code>NVGPU</code> dialect provides a bridge between the target agnostic GPU and
Vector dialects and the lower level LLVM IR based NVVM dialect. This allow
representing PTX specific operations while using MLIR high level concepts
like memref and 2-D vector.</p><p><nav id=TableOfContents><ul><li><a href=#operation-definition>Operation definition</a><ul><li><a href=#nvgpuldmatrix-mlirnvgpuldmatrixop><code>nvgpu.ldmatrix</code> (::mlir::nvgpu::LdMatrixOp)</a></li><li><a href=#nvgpummasync-mlirnvgpummasyncop><code>nvgpu.mma.sync</code> (::mlir::nvgpu::MmaSyncOp)</a></li></ul></li></ul></nav><h2 id=operation-definition>Operation definition&nbsp;<a class=headline-hash href=#operation-definition>¶</a></h2><h3 id=nvgpuldmatrix-mlirnvgpuldmatrixop><code>nvgpu.ldmatrix</code> (::mlir::nvgpu::LdMatrixOp)&nbsp;<a class=headline-hash href=#nvgpuldmatrix-mlirnvgpuldmatrixop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `nvgpu.ldmatrix` $srcMemref`[` $indices `]` attr-dict `:` type($srcMemref) `-&gt;` type($res)
</code></pre><p>The <code>nvgpu.ldmatrix</code> op represents loading a matrix fragment from
memory. The load source and result type must be compatible with lowering
to the <code>nvvm.ldmatrix</code> instruction. This op is meant to represent
the distributed version of a <code>vector.transfer_read</code> as an intermediate
step between lowering from <code>vector.transfer_read</code> to <code>nvvm.ldmatrix</code>.</p><p>This operation is meant to follow the semantic of described here:
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-ldmatrix>https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-ldmatrix</a></p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%0</span> <span class=p>=</span> nvgpu<span class=p>.</span>ldmatrix <span class=nv>%sm</span><span class=p>[</span><span class=nv>%c0</span><span class=p>,</span> <span class=nv>%c0</span><span class=p>]</span> <span class=p>{</span><span class=nl>numTiles =</span> <span class=m>4</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>transpose =</span> false<span class=p>}</span> <span class=p>:</span>
  <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f16</span><span class=p>,</span> <span class=m>3</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x2x</span><span class=k>f16</span><span class=p>&gt;</span>
</code></pre></div><p>Interfaces: MemoryEffectOpInterface (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{MemoryEffects::Read on ::mlir::SideEffects::DefaultResource}</p><h4 id=attributes>Attributes:&nbsp;<a class=headline-hash href=#attributes>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transpose</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td style=text-align:center><code>numTiles</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></tbody></table><h4 id=operands>Operands:&nbsp;<a class=headline-hash href=#operands>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>srcMemref</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>index</td></tr></tbody></table><h4 id=results>Results:&nbsp;<a class=headline-hash href=#results>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=nvgpummasync-mlirnvgpummasyncop><code>nvgpu.mma.sync</code> (::mlir::nvgpu::MmaSyncOp)&nbsp;<a class=headline-hash href=#nvgpummasync-mlirnvgpummasyncop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `nvgpu.mma.sync` `(` $matrixA`,` $matrixB`,` $matrixC `)` attr-dict
              `:` `(` type($matrixA) `,` type($matrixB) `,` type($matrixC) `)` `-&gt;` type($res)
</code></pre><p>The <code>nvgpu.mma.sync</code> op represents the distributed form of a collective
matrix-multiply-and-accumulate (mma) operation that is compatible with
<code>nvvm.mma.sync</code>. The operands and results are fragments of the full matrix
operands. The full shape of the distributed mma operation is given by the
<code>mmaShape</code> attribute in the form of a list of dimensions <code>[m, n, k]</code>.</p><p>This operation is meant to be lowered to the <code>nvvm.mma.sync</code> instruction, and
is an intermediate point between lowering from <code>vector.contract</code> to
<code>nvvm.mma.sync</code>.</p><p>This operation is meant to follow the semantic of described here:
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-mma>https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-mma</a></p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>nvgpu<span class=p>.</span>mma<span class=p>.</span>sync <span class=p>(</span><span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>,</span> <span class=nv>%c</span><span class=p>)</span> <span class=p>:</span>
  <span class=p>(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x2x</span><span class=k>f16</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x2x</span><span class=k>f16</span><span class=p>&gt;</span>
</code></pre></div><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=attributes-1>Attributes:&nbsp;<a class=headline-hash href=#attributes-1>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>mmaShape</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr></tbody></table><h4 id=operands-1>Operands:&nbsp;<a class=headline-hash href=#operands-1>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matrixA</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>matrixB</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>matrixC</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-1>Results:&nbsp;<a class=headline-hash href=#results-1>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>vector of any type values</td></tr></tbody></table><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/Dialects/MLProgramOps/ title="'ml_program' Dialect"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - 'ml_program' Dialect</a>
<a class="nav nav-next" href=/docs/Dialects/NVVMDialect/ title="'nvvm' Dialect">Next - 'nvvm' Dialect <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/pubs/>MLIR Related Publications</a></li><li><a href=/talks/>Talks</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=/docs/Tools/mlir-reduce/>MLIR Reduce</a></li></ul></li><li><a href=/docs/BufferDeallocationInternals/>Buffer Deallocation - Internals</a></li><li><a href=/docs/Bufferization/>Bufferization</a></li><li><a href=/docs/DataLayout/>Data Layout Modeling</a></li><li><a href=/docs/DebugActions/>Debug Actions</a></li><li><a href=/docs/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=/docs/DefiningDialects/>Defining Dialects</a></li><li><a href=/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li class="parent has-sub-menu"><a href=/docs/Dialects/>Dialects<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=/docs/Dialects/ArithmeticOps/>'arith' Dialect</a></li><li><a href=/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=/docs/Dialects/GPU/>'gpu' Dialect</a></li><li class=has-sub-menu><a href=/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li class=active><a href=/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li><a href=/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>'spv' Dialect</a></li><li><a href=/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li><a href=/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=/docs/ExtensibleDialects/>Extensible dialects</a></li><li><a href=/docs/Interfaces/>Interfaces</a></li><li><a href=/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=/docs/CAPI/>MLIR C API</a></li><li><a href=/docs/LangRef/>MLIR Language Reference</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=/docs/OpDefinitions/>Operation Definition Specification (ODS)</a></li><li><a href=/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=/docs/Passes/>Passes</a></li><li><a href=/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=/docs/ShapeInference/>Shape Inference</a></li><li><a href=/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/Traits/>Traits</a></li><li class=has-sub-menu><a href=/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>