<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>'tensor' Dialect - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.80.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Dialects/TensorOps/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>'tensor' Dialect</h1><p>The <code>tensor</code> dialect is intended to hold core tensor creation and
manipulation ops, which are not strongly associated with any particular
other dialect or domain abstraction. The primary smoke test of this is ops
that make sense for any tensor element type.</p><p>We leave it to other dialects to hold the vast swath of possible
computations one might want to do on a tensor.</p><p>The <code>tensor</code> type is (for better or for worse) used to represent all kinds
of things, and supports an open-ended set of element types. Examples:</p><ul><li>representing large, dense aggregations of primitive types, suitable for
high-performance numerical computing.</li><li>representing shapes in the <code>shape</code> dialect, which consist of small
1D tensors of <code>index</code> data type.</li><li>representing aggregations of strings or “variant” types.</li><li>representing large, sparse aggregations of primitive types, suitable
for high-performance numerical computing.</li></ul><p>Thus, for the <code>tensor</code> dialect, we prefer for now to constrain the
scope as much as possible. The expectation is that at some point
in the future, the <code>tensor</code> dialect’s scope may be broadened through a
careful discussion of the tradeoffs.</p><p>The <code>tensor</code> type is actually a builtin type (it lives in the builtin
dialect), and does not live in this dialect.</p><p><nav id=TableOfContents><ul><li><a href=#operation-definition>Operation definition</a><ul><li><a href=#tensorcast-mlirtensorcastop><code>tensor.cast</code> (::mlir::tensor::CastOp)</a></li><li><a href=#tensorcollapse_shape-mlirtensorcollapseshapeop><code>tensor.collapse_shape</code> (::mlir::tensor::CollapseShapeOp)</a></li><li><a href=#tensordim-mlirtensordimop><code>tensor.dim</code> (::mlir::tensor::DimOp)</a></li><li><a href=#tensorexpand_shape-mlirtensorexpandshapeop><code>tensor.expand_shape</code> (::mlir::tensor::ExpandShapeOp)</a></li><li><a href=#tensorextract-mlirtensorextractop><code>tensor.extract</code> (::mlir::tensor::ExtractOp)</a></li><li><a href=#tensorextract_slice-mlirtensorextractsliceop><code>tensor.extract_slice</code> (::mlir::tensor::ExtractSliceOp)</a></li><li><a href=#tensorfrom_elements-mlirtensorfromelementsop><code>tensor.from_elements</code> (::mlir::tensor::FromElementsOp)</a></li><li><a href=#tensorgenerate-mlirtensorgenerateop><code>tensor.generate</code> (::mlir::tensor::GenerateOp)</a></li><li><a href=#tensorinsert-mlirtensorinsertop><code>tensor.insert</code> (::mlir::tensor::InsertOp)</a></li><li><a href=#tensorinsert_slice-mlirtensorinsertsliceop><code>tensor.insert_slice</code> (::mlir::tensor::InsertSliceOp)</a></li><li><a href=#tensorpad-mlirtensorpadop><code>tensor.pad</code> (::mlir::tensor::PadOp)</a></li><li><a href=#tensorrank-mlirtensorrankop><code>tensor.rank</code> (::mlir::tensor::RankOp)</a></li><li><a href=#tensorreshape-mlirtensorreshapeop><code>tensor.reshape</code> (::mlir::tensor::ReshapeOp)</a></li><li><a href=#tensorsplat-mlirtensorsplatop><code>tensor.splat</code> (::mlir::tensor::SplatOp)</a></li><li><a href=#tensoryield-mlirtensoryieldop><code>tensor.yield</code> (::mlir::tensor::YieldOp)</a></li></ul></li></ul></nav><h2 id=operation-definition>Operation definition&nbsp;<a class=headline-hash href=#operation-definition>¶</a></h2><h3 id=tensorcast-mlirtensorcastop><code>tensor.cast</code> (::mlir::tensor::CastOp)&nbsp;<a class=headline-hash href=#tensorcast-mlirtensorcastop>¶</a></h3><p>tensor cast operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.cast` $source attr-dict `:` type($source) `to` type($dest)
</code></pre><p>Convert a tensor from one type to an equivalent type without changing any
data elements. The source and destination types must both be tensor types
with the same element type. If both are ranked, then the rank should be the
same and static dimensions should match. The operation is invalid if
converting to a mismatching constant dimension.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Convert from unknown rank to rank 2 with unknown dimension sizes.
</span><span class=c></span><span class=nv>%2</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>cast <span class=nv>%1</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;*</span>xf32<span class=p>&gt;</span> to <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Convert to a type with more known dimensions.
</span><span class=c></span><span class=nv>%3</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>cast <span class=nv>%2</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>4x?x</span><span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Discard static dimension and rank information.
</span><span class=c></span><span class=nv>%4</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>cast <span class=nv>%3</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>4x?x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=nv>%5</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>cast <span class=nv>%4</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>tensor</span><span class=p>&lt;*</span>xf32<span class=p>&gt;</span>
</code></pre></div><p>Interfaces: CastOpInterface, NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands>Operands:&nbsp;<a class=headline-hash href=#operands>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>tensor of any type values</td></tr></tbody></table><h4 id=results>Results:&nbsp;<a class=headline-hash href=#results>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dest</code></td><td>tensor of any type values</td></tr></tbody></table><h3 id=tensorcollapse_shape-mlirtensorcollapseshapeop><code>tensor.collapse_shape</code> (::mlir::tensor::CollapseShapeOp)&nbsp;<a class=headline-hash href=#tensorcollapse_shape-mlirtensorcollapseshapeop>¶</a></h3><p>operation to produce a tensor with a smaller rank</p><p>Syntax:</p><pre><code>operation ::= `tensor.collapse_shape` $src $reassociation attr-dict `:` type($src) `into` type($result)
</code></pre><p>The <code>tensor.collapse_shape</code> op produces a new tensor with a smaller
rank whose sizes are a reassociation of the original <code>src</code>.</p><p>A reassociation is defined as a continuous grouping of dimensions and is
represented with an array of I64ArrayAttr attribute.</p><p>The verification rule is that the reassociation maps are applied to the
operand tensor with the higher rank to obtain the result tensor with the
smaller rank.</p><p>The result tensor type of a reshape can be zero-ranked if the operand
tensor type is statically shaped with all dimensions being unit extent. In
such case the reassociation map is empty.</p><p>Examples:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Dimension collapse (i, j) -&gt; i&#39; and k -&gt; k&#39;
</span><span class=c></span><span class=nv>%b</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>collapse_shape <span class=nv>%a</span> <span class=p>[[</span><span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>],</span> <span class=p>[</span><span class=m>2</span><span class=p>]]</span>
    <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=attributes>Attributes:&nbsp;<a class=headline-hash href=#attributes>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>reassociation</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>Array of 64-bit integer array attributes</td></tr></tbody></table><h4 id=operands-1>Operands:&nbsp;<a class=headline-hash href=#operands-1>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>tensor of any type values</td></tr></tbody></table><h4 id=results-1>Results:&nbsp;<a class=headline-hash href=#results-1>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>tensor of any type values</td></tr></tbody></table><h3 id=tensordim-mlirtensordimop><code>tensor.dim</code> (::mlir::tensor::DimOp)&nbsp;<a class=headline-hash href=#tensordim-mlirtensordimop>¶</a></h3><p>dimension index operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.dim` attr-dict $source `,` $index `:` type($source)
</code></pre><p>The <code>tensor.dim</code> operation takes a tensor and a dimension operand of type
<code>index</code>. It returns the size of the requested dimension of the given
tensor. If the dimension index is out of bounds, the behavior is undefined.</p><p>The specified tensor type is that of the first operand.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Always returns 4, can be constant folded:
</span><span class=c></span><span class=nv>%c0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
<span class=nv>%x</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>dim <span class=nv>%A</span><span class=p>,</span> <span class=nv>%c0</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>4x?x</span><span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Returns the dynamic dimension of %A.
</span><span class=c></span><span class=nv>%c1</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>1</span> <span class=p>:</span> <span class=k>index</span>
<span class=nv>%y</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>dim <span class=nv>%A</span><span class=p>,</span> <span class=nv>%c1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x?x</span><span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Equivalent generic form:
</span><span class=c></span><span class=nv>%x</span> <span class=p>=</span> <span class=s>&#34;tensor.dim&#34;</span><span class=p>(</span><span class=nv>%A</span><span class=p>,</span> <span class=nv>%c0</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=k>index</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>index</span>
<span class=nv>%y</span> <span class=p>=</span> <span class=s>&#34;tensor.dim&#34;</span><span class=p>(</span><span class=nv>%A</span><span class=p>,</span> <span class=nv>%c1</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=k>index</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>index</span>
</code></pre></div><p>Interfaces: InferTypeOpInterface, NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands-2>Operands:&nbsp;<a class=headline-hash href=#operands-2>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>tensor of any type values</td></tr><tr><td style=text-align:center><code>index</code></td><td>index</td></tr></tbody></table><h4 id=results-2>Results:&nbsp;<a class=headline-hash href=#results-2>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>index</td></tr></tbody></table><h3 id=tensorexpand_shape-mlirtensorexpandshapeop><code>tensor.expand_shape</code> (::mlir::tensor::ExpandShapeOp)&nbsp;<a class=headline-hash href=#tensorexpand_shape-mlirtensorexpandshapeop>¶</a></h3><p>operation to produce a tensor with a higher rank</p><p>Syntax:</p><pre><code>operation ::= `tensor.expand_shape` $src $reassociation attr-dict `:` type($src) `into` type($result)
</code></pre><p>The <code>tensor.expand_shape</code> op produces a new tensor with a higher
rank whose sizes are a reassociation of the original <code>src</code>.</p><p>A reassociation is defined as a continuous grouping of dimensions and is
represented with an array of I64ArrayAttr attribute.</p><p>The verification rule is that the reassociation maps are applied to the
result tensor with the higher rank to obtain the operand tensor with the
smaller rank.</p><p>The operand tensor type of a reshape can be zero-ranked if the result
tensor type is statically shaped with all dimensions being unit extent. In
such cases the reassociation map is empty.</p><p>Examples:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Dimension expansion i -&gt; (i&#39;, j&#39;) and (k) -&gt; (k&#39;)
</span><span class=c></span><span class=nv>%b</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>expand_shape <span class=nv>%a</span> <span class=p>[[</span><span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>],</span> <span class=p>[</span><span class=m>2</span><span class=p>]]</span>
    <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=attributes-1>Attributes:&nbsp;<a class=headline-hash href=#attributes-1>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>reassociation</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>Array of 64-bit integer array attributes</td></tr></tbody></table><h4 id=operands-3>Operands:&nbsp;<a class=headline-hash href=#operands-3>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>tensor of any type values</td></tr></tbody></table><h4 id=results-3>Results:&nbsp;<a class=headline-hash href=#results-3>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>tensor of any type values</td></tr></tbody></table><h3 id=tensorextract-mlirtensorextractop><code>tensor.extract</code> (::mlir::tensor::ExtractOp)&nbsp;<a class=headline-hash href=#tensorextract-mlirtensorextractop>¶</a></h3><p>element extraction operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.extract` $tensor `[` $indices `]` attr-dict `:` type($tensor)
</code></pre><p>The <code>tensor.extract</code> op reads a tensor and returns one
element from it specified by an index list. The output of the op is a
new value with the same type as the elements of the tensor. The
arity of indices must match the rank of the accessed value (i.e., if a
tensor is of rank 3, then 3 indices are required for the extract. The
indices should all be of <code>index</code> type.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%4</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>extract <span class=nv>%t</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>i32</span><span class=p>&gt;</span>
<span class=nv>%5</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>extract <span class=nv>%rt</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>i32</span><span class=p>&gt;</span>
<span class=nv>%6</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>extract <span class=nv>%ut</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;*</span>xi32<span class=p>&gt;</span>
</code></pre></div><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands-4>Operands:&nbsp;<a class=headline-hash href=#operands-4>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tensor</code></td><td>tensor of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>index</td></tr></tbody></table><h4 id=results-4>Results:&nbsp;<a class=headline-hash href=#results-4>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>any type</td></tr></tbody></table><h3 id=tensorextract_slice-mlirtensorextractsliceop><code>tensor.extract_slice</code> (::mlir::tensor::ExtractSliceOp)&nbsp;<a class=headline-hash href=#tensorextract_slice-mlirtensorextractsliceop>¶</a></h3><p>extract slice operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.extract_slice` $source ``
              custom&lt;OperandsOrIntegersOffsetsOrStridesList&gt;($offsets, $static_offsets)
              custom&lt;OperandsOrIntegersSizesList&gt;($sizes, $static_sizes)
              custom&lt;OperandsOrIntegersOffsetsOrStridesList&gt;($strides, $static_strides)
              attr-dict `:` type($source) `to` type($result)
</code></pre><p>The &ldquo;extract_slice&rdquo; operation extract a tensor from another tensor as
specified by the operation&rsquo;s offsets, sizes and strides arguments.</p><p>The extract_slice operation supports the following arguments:</p><ul><li>source: the &ldquo;base&rdquo; tensor from which to extract a slice.</li><li>offsets: tensor-rank number of offsets into the &ldquo;base&rdquo; tensor from which
to extract the slice.</li><li>sizes: tensor-rank number of sizes which specify the sizes of the result
tensor type.</li><li>strides: tensor-rank number of strides specifying subsampling in each
dimension.</li></ul><p>The representation based on offsets, sizes and strides support a
partially-static specification via attributes specified through the
<code>static_offsets</code>, <code>static_sizes</code> and <code>static_strides</code> arguments. A special
sentinel value ShapedType::kDynamicSize and
ShapedType::kDynamicStrideOrOffset encodes that the corresponding entry has
a dynamic value.</p><p>After buffer allocation, the &ldquo;extract_slice&rdquo; op is expected to lower into a
memref.subview op.</p><p>An extract_slice operation may additionally reduce the rank of the resulting
tensor by removing dimensions that are statically known to be of size 1.
This rank-reduction behavior is not required by the op semantics: this
flexibility allows to progressively drop unit dimensions while lowering
between different flavors of ops on that operate on tensors.</p><p>Example:</p><pre><code>// Rank-reducing extract_slice.
%1 = tensor.extract_slice %0[0, 0, 0][1, 16, 4][1, 1, 1] :
  tensor&lt;8x16x4xf32&gt; to tensor&lt;16x4xf32&gt;
%3 = tensor.extract_slice %2[%o0, 4, %o2][1, %sz1, 1][1, %st1, 1] :
  tensor&lt;8x16x4xf32&gt; to tensor&lt;1x?xf32&gt;
</code></pre><p>Traits: AttrSizedOperandSegments</p><p>Interfaces: NoSideEffect (MemoryEffectOpInterface), OffsetSizeAndStrideOpInterface, ReifyRankedShapedTypeOpInterface</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=attributes-2>Attributes:&nbsp;<a class=headline-hash href=#attributes-2>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>static_offsets</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>static_sizes</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>static_strides</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr></tbody></table><h4 id=operands-5>Operands:&nbsp;<a class=headline-hash href=#operands-5>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>ranked tensor of any type values</td></tr><tr><td style=text-align:center><code>offsets</code></td><td>index</td></tr><tr><td style=text-align:center><code>sizes</code></td><td>index</td></tr><tr><td style=text-align:center><code>strides</code></td><td>index</td></tr></tbody></table><h4 id=results-5>Results:&nbsp;<a class=headline-hash href=#results-5>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>ranked tensor of any type values</td></tr></tbody></table><h3 id=tensorfrom_elements-mlirtensorfromelementsop><code>tensor.from_elements</code> (::mlir::tensor::FromElementsOp)&nbsp;<a class=headline-hash href=#tensorfrom_elements-mlirtensorfromelementsop>¶</a></h3><p>tensor from elements operation.</p><p>Syntax:</p><pre><code>operation ::= `tensor.from_elements` $elements attr-dict `:` type($result)
</code></pre><p>Create a N-D tensor from a range of same-type arguments. The number of
provided <code>elements</code> should equal to the number of the elements in the
result type. The <code>elements</code> correspond to a flattened tensor.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>tensor</span><span class=p>.</span>from_elements <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>,</span> <span class=nv>%c</span><span class=p>,</span> <span class=nv>%d</span><span class=p>,</span> <span class=nv>%e</span><span class=p>,</span> <span class=nv>%f</span> <span class=p>:</span>  <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x3x</span><span class=k>index</span><span class=p>&gt;</span>
</code></pre></div><p>will result in a tensor</p><p>[[%a, %b, %c]
[%d, %e, %f]]</p><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands-6>Operands:&nbsp;<a class=headline-hash href=#operands-6>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>elements</code></td><td>any type</td></tr></tbody></table><h4 id=results-6>Results:&nbsp;<a class=headline-hash href=#results-6>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>statically shaped tensor of any type values</td></tr></tbody></table><h3 id=tensorgenerate-mlirtensorgenerateop><code>tensor.generate</code> (::mlir::tensor::GenerateOp)&nbsp;<a class=headline-hash href=#tensorgenerate-mlirtensorgenerateop>¶</a></h3><p>Creates a dynamically sized tensor from elements</p><p>Syntax:</p><pre><code>operation ::= `tensor.generate` $dynamicExtents $body attr-dict `:` type($result)
</code></pre><p>This operation creates a dynamically sized tensor with elements of any type.
It expects one index operand per dynamic extent of the result tensor.</p><p>The body region defines the tensor&rsquo;s elements. It takes index operands as
its region arguments that span the index space. The element at the given
position is yielded with the <code>yield</code> operation (see <code>YieldOp</code>). There is
no defined ordering to the invocations of the body. It is conceptually
a &ldquo;parallel map&rdquo; operation.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%tnsr</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>generate <span class=nv>%m</span><span class=p>,</span> <span class=nv>%n</span> <span class=p>{</span>
  <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%i</span> <span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%j</span> <span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%k</span> <span class=p>:</span> <span class=k>index</span><span class=p>):</span>
    <span class=p>...</span>
    yield <span class=nv>%elem</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=p>}</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x3x</span><span class=err>?</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>Traits: RecursiveSideEffects, SingleBlockImplicitTerminator<a href=mlir::tensor::YieldOp>mlir::tensor::YieldOp</a></p><p>Interfaces: ReifyRankedShapedTypeOpInterface</p><h4 id=operands-7>Operands:&nbsp;<a class=headline-hash href=#operands-7>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dynamicExtents</code></td><td>index</td></tr></tbody></table><h4 id=results-7>Results:&nbsp;<a class=headline-hash href=#results-7>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>ranked tensor of any type values</td></tr></tbody></table><h3 id=tensorinsert-mlirtensorinsertop><code>tensor.insert</code> (::mlir::tensor::InsertOp)&nbsp;<a class=headline-hash href=#tensorinsert-mlirtensorinsertop>¶</a></h3><p>element insertion operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.insert` $scalar `into` $dest `[` $indices `]` attr-dict `:` type($dest)
</code></pre><p>The <code>tensor.insert</code> op writes a tensor into a tensor <code>dest</code>as specified by
the operation&rsquo;s indices.</p><p>It returns a copy of <code>dest</code> with the proper slice updated with the value
of <code>scalar</code>.</p><p>The arity of indices must match the rank of the tensor <code>dest</code> (i.e., if a
tensor is of rank 3, then 3 indices are required for the extract. The
indices should all be of <code>index</code> type.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%4</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>insert <span class=nv>%t</span> into <span class=nv>%dest</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>i32</span><span class=p>&gt;</span>
<span class=nv>%5</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>insert <span class=nv>%rt</span> into <span class=nv>%dest</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>i32</span><span class=p>&gt;</span>
<span class=nv>%6</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>insert <span class=nv>%ut</span> into <span class=nv>%dest</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;*</span>xi32<span class=p>&gt;</span>
</code></pre></div><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands-8>Operands:&nbsp;<a class=headline-hash href=#operands-8>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>scalar</code></td><td>any type</td></tr><tr><td style=text-align:center><code>dest</code></td><td>tensor of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>index</td></tr></tbody></table><h4 id=results-8>Results:&nbsp;<a class=headline-hash href=#results-8>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>tensor of any type values</td></tr></tbody></table><h3 id=tensorinsert_slice-mlirtensorinsertsliceop><code>tensor.insert_slice</code> (::mlir::tensor::InsertSliceOp)&nbsp;<a class=headline-hash href=#tensorinsert_slice-mlirtensorinsertsliceop>¶</a></h3><p>insert_slice operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.insert_slice` $source `into` $dest ``
              custom&lt;OperandsOrIntegersOffsetsOrStridesList&gt;($offsets, $static_offsets)
              custom&lt;OperandsOrIntegersSizesList&gt;($sizes, $static_sizes)
              custom&lt;OperandsOrIntegersOffsetsOrStridesList&gt;($strides, $static_strides)
              attr-dict `:` type($source) `into` type($dest)
</code></pre><p>The &ldquo;insert_slice&rdquo; operation insert a tensor <code>source</code> into another
tensor <code>dest</code> as specified by the operation&rsquo;s offsets, sizes and strides
arguments.</p><p>It returns a copy of <code>dest</code> with the proper slice updated with the value
of <code>source</code>.</p><p>The insert_slice operation supports the following arguments:</p><ul><li>source: the tensor that is inserted.</li><li>dest: the tensor into which the source tensor is inserted.</li><li>offsets: tensor-rank number of offsets into the <code>dest</code> tensor into which
the slice is inserted.</li><li>sizes: tensor-rank number of sizes which specify the sizes of the result
tensor type.</li><li>strides: tensor-rank number of strides that specify subsampling in each
dimension.</li></ul><p>The representation based on offsets, sizes and strides support a
partially-static specification via attributes specified through the
<code>static_offsets</code>, <code>static_sizes</code> and <code>static_strides</code> arguments. A special
sentinel value ShapedType::kDynamicSize and
ShapedType::kDynamicStrideOrOffset encodes that the corresponding entry has
a dynamic value.</p><p>After buffer allocation, the &ldquo;insert_slice&rdquo; op is expected to lower into a
memref.subview op.</p><p>An insert_slice operation may additionally specify insertion into a tensor
of higher rank than the source tensor, along dimensions that are statically
known to be of size 1.
This rank-altering behavior is not required by the op semantics: this
flexibility allows to progressively drop unit dimensions while lowering
between different flavors of ops on that operate on tensors.
The rank-altering behavior of tensor.insert_slice matches the rank-reducing
behavior of tensor.extract_slice.</p><p>Example:</p><pre><code>// Rank-altering insert_slice.
%1 = tensor.insert_slice %t into %0[0, 0, 0][1, 16, 4][1, 1, 1] :
  tensor&lt;16x4xf32&gt; into tensor&lt;8x16x4xf32&gt;
%3 = tensor.insert_slice %tt into %2[%o0, 4, %o2][1, %sz1, 1][1, %st1, 1] :
  tensor&lt;1x?xf32&gt; into tensor&lt;8x16x4xf32&gt;
</code></pre><p>Traits: AttrSizedOperandSegments</p><p>Interfaces: NoSideEffect (MemoryEffectOpInterface), OffsetSizeAndStrideOpInterface, ReifyRankedShapedTypeOpInterface</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=attributes-3>Attributes:&nbsp;<a class=headline-hash href=#attributes-3>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>static_offsets</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>static_sizes</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>static_strides</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr></tbody></table><h4 id=operands-9>Operands:&nbsp;<a class=headline-hash href=#operands-9>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>ranked tensor of any type values</td></tr><tr><td style=text-align:center><code>dest</code></td><td>ranked tensor of any type values</td></tr><tr><td style=text-align:center><code>offsets</code></td><td>index</td></tr><tr><td style=text-align:center><code>sizes</code></td><td>index</td></tr><tr><td style=text-align:center><code>strides</code></td><td>index</td></tr></tbody></table><h4 id=results-9>Results:&nbsp;<a class=headline-hash href=#results-9>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>ranked tensor of any type values</td></tr></tbody></table><h3 id=tensorpad-mlirtensorpadop><code>tensor.pad</code> (::mlir::tensor::PadOp)&nbsp;<a class=headline-hash href=#tensorpad-mlirtensorpadop>¶</a></h3><p>tensor pad operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.pad` $source
              (`nofold` $nofold^)?
              `low` `` custom&lt;OperandsOrIntegersSizesList&gt;($low, $static_low)
              `high` `` custom&lt;OperandsOrIntegersSizesList&gt;($high, $static_high)
              $region attr-dict `:` type($source) `to` type($result)
</code></pre><p><code>tensor.pad</code> is an operation that pads the <code>source</code> tensor
with given <code>low</code> and <code>high</code> padding config.</p><p>The PadOp operation supports the following arguments:</p><ul><li>source: the &ldquo;base&rdquo; tensor on which to pad.</li><li>low: A list contains the padding along the start of each
dimension, i.e <code>low</code>.</li><li>high: A list contains the padding along the end of each
dimension, i.e. <code>high</code>.</li><li>nofold: indicates that the operation should not be folded when source and
result types are equal.</li></ul><p>The result tensor dimensions are <code>low</code> + <code>dim</code> + <code>high</code> along that
dimension. The number of elements of <code>low</code> and <code>high</code> must match
the rank of the input tensor. They can be either a constant or a
dynamic value.</p><p>The region of the <code>tensor.pad</code> operation returns the value to use
for the padding. The arguments of the region represent the index
of the source being accessed. There should be as many arguments as
the rank of the <code>source</code> tensor. The value <code>yield</code>-ed by the
region is used as the value of the view at the given position.</p><p>If <code>nofold</code> is set, the padding operation will not be folded away even
if the source type and the padded type have the same static shape. This can
be used, e.g., for packing or promotion to faster memory.</p><p>Example 1:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%pad_value</span> <span class=p>=</span> <span class=p>...</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=nv>%0</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>pad <span class=nv>%0</span> low<span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span> high<span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>3</span><span class=p>]</span> <span class=p>{</span>
  <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg0</span> <span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%arg1</span> <span class=p>:</span> <span class=k>index</span><span class=p>):</span>
    <span class=kt>tensor</span><span class=p>.</span>yield <span class=nv>%pad_value</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=p>}</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>Example 2:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%pad_value</span> <span class=p>=</span> <span class=p>...</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=nv>%0</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>pad <span class=nv>%arg0</span> low<span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>,</span> <span class=m>3</span><span class=p>,</span> <span class=m>3</span><span class=p>]</span> high<span class=p>[</span><span class=m>3</span><span class=p>,</span> <span class=m>3</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span> <span class=p>{</span>
  <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg2</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%arg3</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%arg4</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%arg5</span><span class=p>:</span> <span class=k>index</span><span class=p>):</span>
      <span class=kt>tensor</span><span class=p>.</span>yield <span class=nv>%pad_value</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=p>}</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>1x2x2x?x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>6x?x?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>Example 3:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%pad_value</span> <span class=p>=</span> <span class=p>...</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=nv>%0</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>pad <span class=nv>%arg0</span> low<span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> high<span class=p>[</span><span class=nv>%ub0</span><span class=p>,</span> <span class=nv>%ub1</span><span class=p>]</span> <span class=p>{</span>
  <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg1</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>:</span> <span class=k>index</span><span class=p>):</span>
    <span class=kt>tensor</span><span class=p>.</span>yield <span class=nv>%pad_value</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=p>}</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x3x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>Example 4:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=c>// Force a padded value to be always exist with `nofold`.
</span><span class=c></span>  <span class=nv>%pad_value</span> <span class=p>=</span> <span class=p>...</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=nv>%0</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>pad <span class=nv>%arg0</span> nofold low<span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> high<span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> <span class=p>{</span>
  <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg1</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>:</span> <span class=k>index</span><span class=p>):</span>
    <span class=kt>tensor</span><span class=p>.</span>yield <span class=nv>%pad_value</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=p>}</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x3x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x3x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>Traits: AttrSizedOperandSegments, SingleBlockImplicitTerminator<a href=mlir::tensor::YieldOp>mlir::tensor::YieldOp</a></p><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=attributes-4>Attributes:&nbsp;<a class=headline-hash href=#attributes-4>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>static_low</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>static_high</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>nofold</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-10>Operands:&nbsp;<a class=headline-hash href=#operands-10>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>tensor of any type values</td></tr><tr><td style=text-align:center><code>low</code></td><td>index</td></tr><tr><td style=text-align:center><code>high</code></td><td>index</td></tr></tbody></table><h4 id=results-10>Results:&nbsp;<a class=headline-hash href=#results-10>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>tensor of any type values</td></tr></tbody></table><h3 id=tensorrank-mlirtensorrankop><code>tensor.rank</code> (::mlir::tensor::RankOp)&nbsp;<a class=headline-hash href=#tensorrank-mlirtensorrankop>¶</a></h3><p>rank operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.rank` $tensor attr-dict `:` type($tensor)
</code></pre><p>The <code>tensor.rank</code> operation takes a tensor operand and returns its rank.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%0</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>rank <span class=nv>%arg0</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;*</span>xf32<span class=p>&gt;</span>
<span class=nv>%1</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>rank <span class=nv>%arg1</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>Interfaces: InferTypeOpInterface, NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands-11>Operands:&nbsp;<a class=headline-hash href=#operands-11>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tensor</code></td><td>tensor of any type values</td></tr></tbody></table><h4 id=results-11>Results:&nbsp;<a class=headline-hash href=#results-11>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>«unnamed»</td><td>index</td></tr></tbody></table><h3 id=tensorreshape-mlirtensorreshapeop><code>tensor.reshape</code> (::mlir::tensor::ReshapeOp)&nbsp;<a class=headline-hash href=#tensorreshape-mlirtensorreshapeop>¶</a></h3><p>tensor reshape operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.reshape` $source `(` $shape `)` attr-dict `:` functional-type(operands, results)
</code></pre><p>The <code>reshape</code> operation converts a tensor from one type to an equivalent
type with a provided shape. The source and destination types are compatible
if both have the same element type, same number of elements. The following
combinations are possible:</p><p>a. Source type is ranked or unranked. Shape argument has static size.
Result type is ranked.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Reshape statically-shaped tensor.
</span><span class=c></span><span class=nv>%dst</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>reshape <span class=nv>%src</span><span class=p>(</span><span class=nv>%shape</span><span class=p>)</span>
         <span class=p>:</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>4x1x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>i32</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=nv>%dst0</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>reshape <span class=nv>%src</span><span class=p>(</span><span class=nv>%shape0</span><span class=p>)</span>
         <span class=p>:</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>4x1x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>i32</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x2x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=c>// Flatten unranked tensor.
</span><span class=c></span><span class=nv>%dst</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>reshape <span class=nv>%src</span><span class=p>(</span><span class=nv>%shape</span><span class=p>)</span>
         <span class=p>:</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;*</span>xf32<span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>i32</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><p>b. Source type is ranked or unranked. Shape argument has dynamic size.
Result type is unranked.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Reshape dynamically-shaped 1D tensor.
</span><span class=c></span><span class=nv>%dst</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>reshape <span class=nv>%src</span><span class=p>(</span><span class=nv>%shape</span><span class=p>)</span>
         <span class=p>:</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>i32</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=kt>tensor</span><span class=p>&lt;*</span>xf32<span class=p>&gt;</span>
<span class=c>// Reshape unranked tensor.
</span><span class=c></span><span class=nv>%dst</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>reshape <span class=nv>%src</span><span class=p>(</span><span class=nv>%shape</span><span class=p>)</span>
         <span class=p>:</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;*</span>xf32<span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>i32</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=kt>tensor</span><span class=p>&lt;*</span>xf32<span class=p>&gt;</span>
</code></pre></div><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands-12>Operands:&nbsp;<a class=headline-hash href=#operands-12>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>tensor of any type values</td></tr><tr><td style=text-align:center><code>shape</code></td><td>1D tensor of signless integer or index values</td></tr></tbody></table><h4 id=results-12>Results:&nbsp;<a class=headline-hash href=#results-12>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>tensor of any type values</td></tr></tbody></table><h3 id=tensorsplat-mlirtensorsplatop><code>tensor.splat</code> (::mlir::tensor::SplatOp)&nbsp;<a class=headline-hash href=#tensorsplat-mlirtensorsplatop>¶</a></h3><p>tensor splat or broadcast operation</p><p>Syntax:</p><pre><code>operation ::= `tensor.splat` $input attr-dict `:` type($aggregate)
</code></pre><p>Broadcast the operand to all elements of the result tensor. The operand is
required to be of integer/index/float type, and the result tensor must be
statically shaped.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%s</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>10.1</span> <span class=p>:</span> <span class=k>f32</span>
<span class=nv>%t</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>splat <span class=nv>%s</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>8x16x</span><span class=k>i32</span><span class=p>&gt;</span>
</code></pre></div><p>TODO: This operation is easy to extend to broadcast to dynamically shaped
tensors:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Broadcasts %s to a 2-d dynamically shaped tensor, with %m, %n binding
</span><span class=c>// to the sizes of the two dynamic dimensions.
</span><span class=c></span><span class=nv>%m</span> <span class=p>=</span> <span class=s>&#34;foo&#34;</span><span class=p>()</span> <span class=p>:</span> <span class=p>()</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>index</span><span class=p>)</span>
<span class=nv>%n</span> <span class=p>=</span> <span class=s>&#34;bar&#34;</span><span class=p>()</span> <span class=p>:</span> <span class=p>()</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>index</span><span class=p>)</span>
<span class=nv>%t</span> <span class=p>=</span> <span class=kt>tensor</span><span class=p>.</span>splat <span class=nv>%s</span> <span class=p>[</span><span class=nv>%m</span><span class=p>,</span> <span class=nv>%n</span><span class=p>]</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>i32</span><span class=p>&gt;</span>
</code></pre></div><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands-13>Operands:&nbsp;<a class=headline-hash href=#operands-13>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>input</code></td><td>integer/index/float type</td></tr></tbody></table><h4 id=results-13>Results:&nbsp;<a class=headline-hash href=#results-13>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>aggregate</code></td><td>statically shaped tensor of any type values</td></tr></tbody></table><h3 id=tensoryield-mlirtensoryieldop><code>tensor.yield</code> (::mlir::tensor::YieldOp)&nbsp;<a class=headline-hash href=#tensoryield-mlirtensoryieldop>¶</a></h3><p>Yield a value from a region</p><p>Syntax:</p><pre><code>operation ::= `tensor.yield` $value attr-dict `:` type($value)
</code></pre><p>This operation is used to yield a single value from a within a region. It
is used to create dynamically sized tensors
(see <code>tensor.generate</code> and <code>tensor.pad</code> ops).</p><p>Traits: HasParent&lt;::mlir::tensor::GenerateOp, ::mlir::tensor::PadOp>, ReturnLike, Terminator</p><p>Interfaces: NoSideEffect (MemoryEffectOpInterface)</p><p>Effects: MemoryEffects::Effect{}</p><h4 id=operands-14>Operands:&nbsp;<a class=headline-hash href=#operands-14>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td>any type</td></tr></tbody></table><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/Dialects/SPIR-V/ title="'spv' Dialect"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - 'spv' Dialect</a>
<a class="nav nav-next" href=/docs/Dialects/Vector/ title="'vector' Dialect">Next - 'vector' Dialect <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/pubs/>MLIR Related Publications</a></li><li><a href=/talks/>Talks</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=/docs/Tools/mlir-reduce/>MLIR Reduce</a></li></ul></li><li><a href=/docs/BufferDeallocationInternals/>Buffer Deallocation - Internals</a></li><li><a href=/docs/Bufferization/>Bufferization</a></li><li><a href=/docs/DataLayout/>Data Layout Modeling</a></li><li><a href=/docs/DebugActions/>Debug Actions</a></li><li><a href=/docs/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=/docs/DefiningDialects/>Defining Dialects</a></li><li><a href=/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li class="parent has-sub-menu"><a href=/docs/Dialects/>Dialects<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=/docs/Dialects/ArithmeticOps/>'arith' Dialect</a></li><li><a href=/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=/docs/Dialects/GPU/>'gpu' Dialect</a></li><li class=has-sub-menu><a href=/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li><a href=/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li><a href=/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>'spv' Dialect</a></li><li class=active><a href=/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li><a href=/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=/docs/ExtensibleDialects/>Extensible dialects</a></li><li><a href=/docs/Interfaces/>Interfaces</a></li><li><a href=/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=/docs/CAPI/>MLIR C API</a></li><li><a href=/docs/LangRef/>MLIR Language Reference</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=/docs/OpDefinitions/>Operation Definition Specification (ODS)</a></li><li><a href=/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=/docs/Passes/>Passes</a></li><li><a href=/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=/docs/ShapeInference/>Shape Inference</a></li><li><a href=/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/Traits/>Traits</a></li><li class=has-sub-menu><a href=/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>