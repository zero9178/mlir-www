<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MLIR</title><link>https://mlir.llvm.org/</link><description>Recent content on MLIR</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 19 Oct 2017 15:26:15 +0000</lastBuildDate><atom:link href="https://mlir.llvm.org/index.xml" rel="self" type="application/rss+xml"/><item><title>Debugging Tips</title><link>https://mlir.llvm.org/getting_started/Debugging/</link><pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Debugging/</guid><description>Inspecting compilation There&amp;rsquo;s no silver bullet for debugging the compilation process. Standard debugging techniques (printf debugging, gdb/lldb, IDE graphical debuggers, etc.) are of course applicable, but below are MLIR-specific facilities that are quite useful before diving into a generic debug flow. These facilities assume that you have reduced your problem to a form that can be reproduced with mlir-opt or another program that hooks into MLIR&amp;rsquo;s option parsing, if this is not the case, see section &amp;ldquo;Isolating test case&amp;rdquo; below.</description></item><item><title>FAQ</title><link>https://mlir.llvm.org/getting_started/Faq/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Faq/</guid><description>How to refer to MLIR in publications? Is there an accompanying paper? MLIR has been presented in the 2021 IEEE/ACM International Symposium on Code Generation and Optimization, the full text of the paper is available from IEEE. A pre-publication draft is available on arXiv but may be missing improvements and corrections. Please also note that MLIR keeps evolving and IR snippets presented in the paper may no longer use modern syntax, refer to the MLIR documentation for the new syntax.</description></item><item><title>How to Contribute</title><link>https://mlir.llvm.org/getting_started/Contributing/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Contributing/</guid><description>Everyone is welcome to contribute to MLIR. There are several ways of getting involved and contributing including reporting bugs, improving documentation and tutorials.
Community Guidelines Please be mindful of the LLVM Code of Conduct, which pledges to foster an open and welcoming environment.
Contributing code We don&amp;rsquo;t accept pull-request on GitHub, instead we use Phabricator. At the moment you need to also join this group to enable build and test of your Phabricator revisions.</description></item><item><title>Developer Guide</title><link>https://mlir.llvm.org/getting_started/DeveloperGuide/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/DeveloperGuide/</guid><description>This document attempts to describe a few developer policies used in MLIR (such as coding standards used) as well as development approach (such as, testing methods).
Style guide MLIR follows the LLVM style guide. We also adhere to the following (which deviate from or are not specified in the LLVM style guide):
Adopts camelBack; Uses Doxygen-style (///) comments for top-level and class member definitions, regardless of them being visible as public APIs.</description></item><item><title>Open Projects</title><link>https://mlir.llvm.org/getting_started/openprojects/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/openprojects/</guid><description>Below is a list of projects that can be suitable for Google Summer of Code (GSOC) or just for someone to get started with contributing to MLIR. See also the &amp;ldquo;beginner&amp;rdquo; issues on the bugtracker. If you&amp;rsquo;re interested in one of these projects, feel free to discuss it on the MLIR section of the LLVM forums or on the MLIR channel of the LLVM discord server. The mentors are indicative and suggestion of first point of contact for starting on these projects.</description></item><item><title>Glossary</title><link>https://mlir.llvm.org/getting_started/Glossary/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Glossary/</guid><description>This glossary contains definitions of MLIR-specific terminology. It is intended to be a quick reference document. For terms which are well-documented elsewhere, definitions are kept brief and the header links to the more in-depth documentation.
Block A sequential list of operations without control flow.
Also called a basic block.
Conversion The transformation of code represented in one dialect into a semantically equivalent representation in another dialect (i.e. inter-dialect conversion) or the same dialect (i.</description></item><item><title>Testing Guide</title><link>https://mlir.llvm.org/getting_started/TestingGuide/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/TestingGuide/</guid><description>Testing is an integral part of any software infrastructure. In general, all commits to the MLIR repository should include an accompanying test of some form. Commits that include no functional changes, such as API changes like symbol renaming, should be tagged with NFC(no functional changes). This signals to the reviewer why the change doesn&amp;rsquo;t/shouldn&amp;rsquo;t include a test.
MLIR generally separates testing into three main categories, Check tests, Unit tests, and Integration tests.</description></item><item><title>'acc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</guid><description>An OpenACC dialect for MLIR. This dialect models the construct from the OpenACC 3.1 directive language.
Attribute constraint definition DefaultValue Clause built-in reduction operations supported by OpenACC Attribute definition ClauseDefaultValueAttr ReductionOpAttr Operation definition acc.data (::mlir::acc::DataOp) acc.enter_data (::mlir::acc::EnterDataOp) acc.exit_data (::mlir::acc::ExitDataOp) acc.init (::mlir::acc::InitOp) acc.loop (::mlir::acc::LoopOp) acc.parallel (::mlir::acc::ParallelOp) acc.shutdown (::mlir::acc::ShutdownOp) acc.terminator (::mlir::acc::TerminatorOp) acc.update (::mlir::acc::UpdateOp) acc.wait (::mlir::acc::WaitOp) acc.yield (::mlir::acc::YieldOp) Attribute constraint definition DefaultValue Clause built-in reduction operations supported by OpenACC Attribute definition ClauseDefaultValueAttr DefaultValue Clause</description></item><item><title>'affine' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Affine/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Affine/</guid><description>This dialect provides a powerful abstraction for affine operations and analyses.
Polyhedral Structures Dimensions and Symbols Restrictions on Dimensions and Symbols Affine Expressions Affine Maps Semi-affine maps Integer Sets Operations affine.apply (mlir::AffineApplyOp) affine.for (mlir::AffineForOp) affine.if (mlir::AffineIfOp) affine.load (mlir::AffineLoadOp) affine.max (mlir::AffineMaxOp) affine.min (mlir::AffineMinOp) affine.parallel (mlir::AffineParallelOp) affine.prefetch (mlir::AffinePrefetchOp) affine.store (mlir::AffineStoreOp) affine.vector_load (mlir::AffineVectorLoadOp) affine.vector_store (mlir::AffineVectorStoreOp) affine.yield (mlir::AffineYieldOp) &amp;lsquo;affine.store&amp;rsquo; operation &amp;lsquo;affine.dma_start&amp;rsquo; operation &amp;lsquo;affine.dma_wait&amp;rsquo; operation Polyhedral Structures MLIR uses techniques from polyhedral compilation to make dependence analysis and loop transformations efficient and reliable.</description></item><item><title>'amx' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMX/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMX/</guid><description>The Intel Advanced Matrix Extensions (AMX) provide a tile matrix multiply unit (TMUL), a tile control register (TILECFG), and eight tile registers TMM0 through TMM7 (TILEDATA).
This AMX dialect provides a bridge between MLIR concepts such as vectors and memrefs and the lower level LLVM IR support of AMX. The dialect is split into user-facing AMX ops (AMX_Op) and backend-facing intrinsic ops (AMX_IntrOp).
Note that since configuration changes (implicit at dialect level) are costly, it is highly recommended to use the AMX dialect on same-shaped vectors, at least within a single method.</description></item><item><title>'arith' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArithmeticOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArithmeticOps/</guid><description>The arithmetic dialect is intended to hold basic integer and floating point mathematical operations. This includes unary, binary, and ternary arithmetic ops, bitwise and shift ops, cast ops, and compare ops. Operations in this dialect also accept vectors and tensors of integers or floats.
Operation definition arith.addf (::mlir::arith::AddFOp) arith.addi (::mlir::arith::AddIOp) arith.andi (::mlir::arith::AndIOp) arith.bitcast (::mlir::arith::BitcastOp) arith.ceildivsi (::mlir::arith::CeilDivSIOp) arith.ceildivui (::mlir::arith::CeilDivUIOp) arith.cmpf (::mlir::arith::CmpFOp) arith.cmpi (::mlir::arith::CmpIOp) arith.constant (::mlir::arith::ConstantOp) arith.divf (::mlir::arith::DivFOp) arith.divsi (::mlir::arith::DivSIOp) arith.</description></item><item><title>'arm_neon' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmNeon/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmNeon/</guid><description>Operation definition arm_neon.intr.smull (::mlir::arm_neon::SMullOp) arm_neon.2d.sdot (::mlir::arm_neon::Sdot2dOp) arm_neon.intr.sdot (::mlir::arm_neon::SdotOp) Type constraint definition LLVM dialect-compatible type Operation definition arm_neon.intr.smull (::mlir::arm_neon::SMullOp) smull roundscale op
Syntax:
operation ::= `arm_neon.intr.smull` $a `,` $b attr-dict `:` type($a) `to` type($res) Signed Multiply Long (vector). This instruction multiplies corresponding signed integer values in the lower or upper half of the vectors of the two source SIMD&amp;amp;FP registers, places the results in a vector, and writes the vector to the destination SIMD&amp;amp;FP register.</description></item><item><title>'arm_sve' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSVE/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSVE/</guid><description>Basic dialect to target Arm SVE architectures This dialect contains the definitions necessary to target specific Arm SVE scalable vector operations.
Operation definition arm_sve.intr.fadd (::mlir::arm_sve::ScalableMaskedAddFIntrOp) arm_sve.masked.addf (::mlir::arm_sve::ScalableMaskedAddFOp) arm_sve.intr.add (::mlir::arm_sve::ScalableMaskedAddIIntrOp) arm_sve.masked.addi (::mlir::arm_sve::ScalableMaskedAddIOp) arm_sve.intr.fdiv (::mlir::arm_sve::ScalableMaskedDivFIntrOp) arm_sve.masked.divf (::mlir::arm_sve::ScalableMaskedDivFOp) arm_sve.intr.fmul (::mlir::arm_sve::ScalableMaskedMulFIntrOp) arm_sve.masked.mulf (::mlir::arm_sve::ScalableMaskedMulFOp) arm_sve.intr.mul (::mlir::arm_sve::ScalableMaskedMulIIntrOp) arm_sve.masked.muli (::mlir::arm_sve::ScalableMaskedMulIOp) arm_sve.intr.sdiv (::mlir::arm_sve::ScalableMaskedSDivIIntrOp) arm_sve.masked.divi_signed (::mlir::arm_sve::ScalableMaskedSDivIOp) arm_sve.intr.fsub (::mlir::arm_sve::ScalableMaskedSubFIntrOp) arm_sve.masked.subf (::mlir::arm_sve::ScalableMaskedSubFOp) arm_sve.intr.sub (::mlir::arm_sve::ScalableMaskedSubIIntrOp) arm_sve.masked.subi (::mlir::arm_sve::ScalableMaskedSubIOp) arm_sve.intr.udiv (::mlir::arm_sve::ScalableMaskedUDivIIntrOp) arm_sve.masked.divi_unsigned (::mlir::arm_sve::ScalableMaskedUDivIOp) arm_sve.intr.sdot (::mlir::arm_sve::SdotIntrOp) arm_sve.sdot (::mlir::arm_sve::SdotOp) arm_sve.intr.smmla (::mlir::arm_sve::SmmlaIntrOp) arm_sve.smmla (::mlir::arm_sve::SmmlaOp) arm_sve.intr.udot (::mlir::arm_sve::UdotIntrOp) arm_sve.</description></item><item><title>'async' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</guid><description>Types and operations for async dialect This dialect contains operations for modeling asynchronous execution.
Type constraint definition coroutine handle switched-resume coroutine identifier saved coroutine state async group type async token type async value type Operation definition async.add_to_group (::mlir::async::AddToGroupOp) async.await_all (::mlir::async::AwaitAllOp) async.await (::mlir::async::AwaitOp) async.coro.begin (::mlir::async::CoroBeginOp) async.coro.end (::mlir::async::CoroEndOp) async.coro.free (::mlir::async::CoroFreeOp) async.coro.id (::mlir::async::CoroIdOp) async.coro.save (::mlir::async::CoroSaveOp) async.coro.suspend (::mlir::async::CoroSuspendOp) async.create_group (::mlir::async::CreateGroupOp) async.execute (::mlir::async::ExecuteOp) async.runtime.add_ref (::mlir::async::RuntimeAddRefOp) async.runtime.add_to_group (::mlir::async::RuntimeAddToGroupOp) async.runtime.await_and_resume (::mlir::async::RuntimeAwaitAndResumeOp) async.runtime.await (::mlir::async::RuntimeAwaitOp) async.</description></item><item><title>'bufferization' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</guid><description>Bufferization in MLIR is the process of converting the tensor type to the memref type. The bufferization dialect is intended to collect operations/interfaces specific to the bufferization passes.
Overview of the bufferization infrastructure and important conceptual details related to using the MLIR dialect conversion infrastructure can be found in bufferization and buffer deallocation.
Operation definition bufferization.clone (::mlir::bufferization::CloneOp) bufferization.to_memref (::mlir::bufferization::ToMemrefOp) bufferization.to_tensor (::mlir::bufferization::ToTensorOp) Operation definition bufferization.clone (::mlir::bufferization::CloneOp) Syntax:</description></item><item><title>'cf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</guid><description>This dialect contains low-level, i.e. non-region based, control flow constructs. These constructs generally represent control flow directly on SSA blocks of a control flow graph.
Operation definition cf.assert (::mlir::cf::AssertOp) cf.br (::mlir::cf::BranchOp) cf.cond_br (::mlir::cf::CondBranchOp) cf.switch (::mlir::cf::SwitchOp) Operation definition cf.assert (::mlir::cf::AssertOp) Assert operation with message attribute
Syntax:
operation ::= `cf.assert` $arg `,` $msg attr-dict Assert operation with single boolean operand and an error message attribute. If the argument is true this operation has no effect.</description></item><item><title>'complex' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ComplexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ComplexOps/</guid><description>The complex dialect is intended to hold complex numbers creation and arithmetic ops.
Operation definition complex.abs (::mlir::complex::AbsOp) complex.add (::mlir::complex::AddOp) complex.constant (::mlir::complex::ConstantOp) complex.cos (::mlir::complex::CosOp) complex.create (::mlir::complex::CreateOp) complex.div (::mlir::complex::DivOp) complex.eq (::mlir::complex::EqualOp) complex.exp (::mlir::complex::ExpOp) complex.im (::mlir::complex::ImOp) complex.log1p (::mlir::complex::Log1pOp) complex.log (::mlir::complex::LogOp) complex.mul (::mlir::complex::MulOp) complex.neg (::mlir::complex::NegOp) complex.neq (::mlir::complex::NotEqualOp) complex.re (::mlir::complex::ReOp) complex.sign (::mlir::complex::SignOp) complex.sin (::mlir::complex::SinOp) complex.sub (::mlir::complex::SubOp) Operation definition complex.abs (::mlir::complex::AbsOp) computes absolute value of a complex number
Syntax:
operation ::= `complex.</description></item><item><title>'dlti' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</guid><description>The Data Layout and Target Information (DLTI) dialect is intended to hold attributes and other components pertaining to descriptions of in-memory data layout and compilation targets.
Attribute constraint definition Target data layout entry Target data layout specification Attribute constraint definition Target data layout entry Target data layout specification</description></item><item><title>'emitc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/EmitC/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/EmitC/</guid><description>Dialect to generate C/C++ from MLIR. The EmitC dialect allows to convert operations from other MLIR dialects to EmitC ops. Those can be translated to C/C++ via the Cpp emitter.
The following convention is followed:
If template arguments are passed to an emitc.call operation, C++ is generated. If tensors are used, C++ is generated. If multiple return values are used within in a functions or an emitc.call operation, C++11 is required.</description></item><item><title>'func' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Func/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Func/</guid><description>This dialect provides documentation for operations within the Func dialect.
This dialect contains operations surrounding high order function abstractions, such as calls.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations func.call_indirect (::mlir::func::CallIndirectOp) func.call (::mlir::func::CallOp) func.constant (::mlir::func::ConstantOp) func.func (::mlir::func::FuncOp) func.return (::mlir::func::ReturnOp) Operations func.call_indirect (::mlir::func::CallIndirectOp) indirect call operation
Syntax:
operation ::= `func.call_indirect` $callee `(` $callee_operands `)` attr-dict `:` type($callee) The func.</description></item><item><title>'gpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/GPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/GPU/</guid><description>Note: this dialect is more likely to change than others in the near future; use with caution.
This dialect provides middle-level abstractions for launching GPU kernels following a programming model similar to that of CUDA or OpenCL. It provides abstractions for kernel invocations (and may eventually provide those for device management) that are not present at the lower level (e.g., as LLVM IR intrinsics for GPUs). Its goal is to abstract away device- and driver-specific manipulations to launch a GPU kernel and provide a simple path towards GPU execution from MLIR.</description></item><item><title>'llvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/LLVM/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LLVM/</guid><description>This dialect maps LLVM IR into MLIR by defining the corresponding operations and types. LLVM IR metadata is usually represented as MLIR attributes, which offer additional structure verification.
We use &amp;ldquo;LLVM IR&amp;rdquo; to designate the intermediate representation of LLVM and &amp;ldquo;LLVM dialect&amp;rdquo; or &amp;ldquo;LLVM IR dialect&amp;rdquo; to refer to this MLIR dialect.
Unless explicitly stated otherwise, the semantics of the LLVM dialect operations must correspond to the semantics of LLVM IR instructions and any divergence is considered a bug.</description></item><item><title>'math' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MathOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MathOps/</guid><description>The math dialect is intended to hold mathematical operations on integer and floating type beyond simple arithmetics.
Operation definition math.abs (::mlir::math::AbsOp) math.atan2 (::mlir::math::Atan2Op) math.atan (::mlir::math::AtanOp) math.ceil (::mlir::math::CeilOp) math.copysign (::mlir::math::CopySignOp) math.cos (::mlir::math::CosOp) math.ctlz (::mlir::math::CountLeadingZerosOp) math.cttz (::mlir::math::CountTrailingZerosOp) math.ctpop (::mlir::math::CtPopOp) math.erf (::mlir::math::ErfOp) math.exp2 (::mlir::math::Exp2Op) math.expm1 (::mlir::math::ExpM1Op) math.exp (::mlir::math::ExpOp) math.floor (::mlir::math::FloorOp) math.fma (::mlir::math::FmaOp) math.log10 (::mlir::math::Log10Op) math.log1p (::mlir::math::Log1pOp) math.log2 (::mlir::math::Log2Op) math.log (::mlir::math::LogOp) math.powf (::mlir::math::PowFOp) math.rsqrt (::mlir::math::RsqrtOp) math.sin (::mlir::math::SinOp) math.sqrt (::mlir::math::SqrtOp) math.tanh (::mlir::math::TanhOp) Operation definition math.</description></item><item><title>'memref' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MemRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MemRef/</guid><description>This dialect provides documentation for operations within the MemRef dialect.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations Operation definition memref.assume_alignment (::mlir::memref::AssumeAlignmentOp) memref.atomic_rmw (::mlir::memref::AtomicRMWOp) memref.atomic_yield (::mlir::memref::AtomicYieldOp) memref.copy (::mlir::memref::CopyOp) memref.generic_atomic_rmw (::mlir::memref::GenericAtomicRMWOp) memref.load (::mlir::memref::LoadOp) memref.alloc (::mlir::memref::AllocOp) memref.alloca (::mlir::memref::AllocaOp) memref.alloca_scope (::mlir::memref::AllocaScopeOp) memref.alloca_scope.return (::mlir::memref::AllocaScopeReturnOp) memref.cast (::mlir::memref::CastOp) memref.collapse_shape (::mlir::memref::CollapseShapeOp) memref.dealloc (::mlir::memref::DeallocOp) memref.dim (::mlir::memref::DimOp) memref.dma_start (::mlir::memref::DmaStartOp) memref.dma_wait (::mlir::memref::DmaWaitOp) memref.expand_shape (::mlir::memref::ExpandShapeOp) memref.get_global (::mlir::memref::GetGlobalOp) memref.global (::mlir::memref::GlobalOp) memref.prefetch (::mlir::memref::PrefetchOp) memref.</description></item><item><title>'ml_program' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</guid><description>The MLProgram dialect contains structural operations and types for defining a compiled Machine-Learning program, as created from common ML frameworks, such as TensorFlow, PyTorch, JAX, etc. It does not itself define computation ops common to such frameworks but establishes a common programming model for establishing modules, functions, globals and memory model components appropriate for such an abstract level of detail.
This dialect is under active development, and while stability is an eventual goal, it is not guaranteed at this juncture.</description></item><item><title>'nvgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVGPU/</guid><description>This NVGPU dialect provides a bridge between the target agnostic GPU and Vector dialects and the lower level LLVM IR based NVVM dialect. This allow representing PTX specific operations while using MLIR high level concepts like memref and 2-D vector.
Operation definition nvgpu.ldmatrix (::mlir::nvgpu::LdMatrixOp) nvgpu.mma.sync (::mlir::nvgpu::MmaSyncOp) Operation definition nvgpu.ldmatrix (::mlir::nvgpu::LdMatrixOp) Syntax:
operation ::= `nvgpu.ldmatrix` $srcMemref`[` $indices `]` attr-dict `:` type($srcMemref) `-&amp;gt;` type($res) The nvgpu.ldmatrix op represents loading a matrix fragment from memory.</description></item><item><title>'nvvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</guid><description>Attribute constraint definition MMA binary operations NVVM MMA frag type MMA overflow options NVVM MMA layout NVVM MMA types NVVM shuffle kind Attribute definition MMAB1OpAttr MMAFragAttr MMAIntOverflowAttr MMALayoutAttr MMATypesAttr ShflKindAttr Operation definition nvvm.barrier0 (::mlir::NVVM::Barrier0Op) nvvm.read.ptx.sreg.ntid.x (::mlir::NVVM::BlockDimXOp) nvvm.read.ptx.sreg.ntid.y (::mlir::NVVM::BlockDimYOp) nvvm.read.ptx.sreg.ntid.z (::mlir::NVVM::BlockDimZOp) nvvm.read.ptx.sreg.ctaid.x (::mlir::NVVM::BlockIdXOp) nvvm.read.ptx.sreg.ctaid.y (::mlir::NVVM::BlockIdYOp) nvvm.read.ptx.sreg.ctaid.z (::mlir::NVVM::BlockIdZOp) nvvm.cp.async.commit.group (::mlir::NVVM::CpAsyncCommitGroupOp) nvvm.cp.async.shared.global (::mlir::NVVM::CpAsyncOp) nvvm.cp.async.wait.group (::mlir::NVVM::CpAsyncWaitGroupOp) nvvm.read.ptx.sreg.nctaid.x (::mlir::NVVM::GridDimXOp) nvvm.read.ptx.sreg.nctaid.y (::mlir::NVVM::GridDimYOp) nvvm.read.ptx.sreg.nctaid.z (::mlir::NVVM::GridDimZOp) nvvm.read.ptx.sreg.laneid (::mlir::NVVM::LaneIdOp) nvvm.ldmatrix (::mlir::NVVM::LdMatrixOp) nvvm.</description></item><item><title>'omp' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/OpenMPDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenMPDialect/</guid><description>Attribute constraint definition CancellationConstructType Clause depend clause MemoryOrderKind Clause OrderKind Clause ProcBindKind Clause ScheduleKind Clause OpenMP Schedule Modifier Attribute definition ClauseCancellationConstructTypeAttr ClauseDependAttr ClauseMemoryOrderKindAttr ClauseOrderKindAttr ClauseProcBindKindAttr ClauseScheduleKindAttr ScheduleModifierAttr Operation definition omp.atomic.capture (::mlir::omp::AtomicCaptureOp) omp.atomic.read (::mlir::omp::AtomicReadOp) omp.atomic.update (::mlir::omp::AtomicUpdateOp) omp.atomic.write (::mlir::omp::AtomicWriteOp) omp.barrier (::mlir::omp::BarrierOp) omp.cancel (::mlir::omp::CancelOp) omp.cancellationpoint (::mlir::omp::CancellationPointOp) omp.critical.declare (::mlir::omp::CriticalDeclareOp) omp.critical (::mlir::omp::CriticalOp) omp.flush (::mlir::omp::FlushOp) omp.master (::mlir::omp::MasterOp) omp.ordered (::mlir::omp::OrderedOp) omp.ordered_region (::mlir::omp::OrderedRegionOp) omp.parallel (::mlir::omp::ParallelOp) omp.reduction.declare (::mlir::omp::ReductionDeclareOp) omp.reduction (::mlir::omp::ReductionOp) omp.section (::mlir::omp::SectionOp) omp.</description></item><item><title>'pdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLOps/</guid><description>High level pattern definition dialect PDL presents a high level abstraction for the rewrite pattern infrastructure available in MLIR. This abstraction allows for representing patterns transforming MLIR, as MLIR. This allows for applying all of the benefits that the general MLIR infrastructure provides, to the infrastructure itself. This means that pattern matching can be more easily verified for correctness, targeted by frontends, and optimized.
PDL abstracts over various different aspects of patterns and core MLIR data structures.</description></item><item><title>'pdl_interp' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</guid><description>Interpreted pattern execution dialect The PDL Interpreter dialect provides a lower level abstraction compared to the PDL dialect, and is targeted towards low level optimization and interpreter code generation. The dialect operations encapsulates low-level pattern match and rewrite &amp;ldquo;primitives&amp;rdquo;, such as navigating the IR (Operation::getOperand), creating new operations (OpBuilder::create), etc. Many of the operations within this dialect also fuse branching control flow with some form of a predicate comparison operation. This type of fusion reduces the amount of work that an interpreter must do when executing.</description></item><item><title>'quant' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/QuantDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/QuantDialect/</guid><description>Type constraint definition UniformQuantizedType Operation definition quant.const_fake_quant (::mlir::quant::ConstFakeQuant) quant.const_fake_quant_per_axis (::mlir::quant::ConstFakeQuantPerAxis) quant.coupled_ref (::mlir::quant::CoupledRefOp) quant.dcast (::mlir::quant::DequantizeCastOp) quant.qcast (::mlir::quant::QuantizeCastOp) quant.region (::mlir::quant::QuantizeRegionOp) quant.return (::mlir::quant::ReturnOp) quant.stats (::mlir::quant::StatisticsOp) quant.stats_ref (::mlir::quant::StatisticsRefOp) quant.scast (::mlir::quant::StorageCastOp) Type constraint definition UniformQuantizedType Operation definition quant.const_fake_quant (::mlir::quant::ConstFakeQuant) Simulates the effect of uniform quantization with const range. Given a const min, max, num_bits and narrow_range attribute, applies the same uniform quantization simulation as is done by the TensorFlow fake_quant_with_min_max_args op.</description></item><item><title>'rocdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</guid><description>Operation definition rocdl.barrier (::mlir::ROCDL::BarrierOp) rocdl.workgroup.dim.x (::mlir::ROCDL::BlockDimXOp) rocdl.workgroup.dim.y (::mlir::ROCDL::BlockDimYOp) rocdl.workgroup.dim.z (::mlir::ROCDL::BlockDimZOp) rocdl.workgroup.id.x (::mlir::ROCDL::BlockIdXOp) rocdl.workgroup.id.y (::mlir::ROCDL::BlockIdYOp) rocdl.workgroup.id.z (::mlir::ROCDL::BlockIdZOp) rocdl.grid.dim.x (::mlir::ROCDL::GridDimXOp) rocdl.grid.dim.y (::mlir::ROCDL::GridDimYOp) rocdl.grid.dim.z (::mlir::ROCDL::GridDimZOp) rocdl.buffer.load (::mlir::ROCDL::MubufLoadOp) rocdl.buffer.store (::mlir::ROCDL::MubufStoreOp) rocdl.workitem.id.x (::mlir::ROCDL::ThreadIdXOp) rocdl.workitem.id.y (::mlir::ROCDL::ThreadIdYOp) rocdl.workitem.id.z (::mlir::ROCDL::ThreadIdZOp) rocdl.mfma.f32.16x16x16f16 (::mlir::ROCDL::mfma_f32_16x16x16f16) rocdl.mfma.f32.16x16x1f32 (::mlir::ROCDL::mfma_f32_16x16x1f32) rocdl.mfma.f32.16x16x2bf16 (::mlir::ROCDL::mfma_f32_16x16x2bf16) rocdl.mfma.f32.16x16x4f16 (::mlir::ROCDL::mfma_f32_16x16x4f16) rocdl.mfma.f32.16x16x4f32 (::mlir::ROCDL::mfma_f32_16x16x4f32) rocdl.mfma.f32.16x16x8bf16 (::mlir::ROCDL::mfma_f32_16x16x8bf16) rocdl.mfma.f32.32x32x1f32 (::mlir::ROCDL::mfma_f32_32x32x1f32) rocdl.mfma.f32.32x32x2bf16 (::mlir::ROCDL::mfma_f32_32x32x2bf16) rocdl.mfma.f32.32x32x2f32 (::mlir::ROCDL::mfma_f32_32x32x2f32) rocdl.mfma.f32.32x32x4bf16 (::mlir::ROCDL::mfma_f32_32x32x4bf16) rocdl.mfma.f32.32x32x4f16 (::mlir::ROCDL::mfma_f32_32x32x4f16) rocdl.mfma.f32.32x32x8f16 (::mlir::ROCDL::mfma_f32_32x32x8f16) rocdl.mfma.f32.4x4x1f32 (::mlir::ROCDL::mfma_f32_4x4x1f32) rocdl.mfma.f32.4x4x2bf16 (::mlir::ROCDL::mfma_f32_4x4x2bf16) rocdl.mfma.f32.4x4x4f16 (::mlir::ROCDL::mfma_f32_4x4x4f16) rocdl.mfma.i32.16x16x16i8 (::mlir::ROCDL::mfma_i32_16x16x16i8) rocdl.mfma.i32.16x16x4i8 (::mlir::ROCDL::mfma_i32_16x16x4i8) rocdl.mfma.i32.32x32x4i8 (::mlir::ROCDL::mfma_i32_32x32x4i8) rocdl.</description></item><item><title>'scf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SCFDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SCFDialect/</guid><description>Operation definition scf.condition (::mlir::scf::ConditionOp) scf.execute_region (::mlir::scf::ExecuteRegionOp) scf.for (::mlir::scf::ForOp) scf.if (::mlir::scf::IfOp) scf.parallel (::mlir::scf::ParallelOp) scf.reduce (::mlir::scf::ReduceOp) scf.reduce.return (::mlir::scf::ReduceReturnOp) scf.while (::mlir::scf::WhileOp) scf.yield (::mlir::scf::YieldOp) Operation definition scf.condition (::mlir::scf::ConditionOp) loop continuation condition
Syntax:
operation ::= `scf.condition` `(` $condition `)` attr-dict ($args^ `:` type($args))? This operation accepts the continuation (i.e., inverse of exit) condition of the scf.while construct. If its first argument is true, the &amp;ldquo;after&amp;rdquo; region of scf.while is executed, with the remaining arguments forwarded to the entry block of the region.</description></item><item><title>'shape' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</guid><description>Description of operations &amp;amp; types within the Shape dialect as well as their usage.
Types and operations for shape dialect This dialect contains operations for shape inference.
Note: Unless explicitly stated, all functions that return a shape and take shapes as input, return the invalid shape if one of its operands is an invalid shape. This avoids flagging multiple errors for one verification failure. The dialect itself does not specify how errors should be combined (there are multiple different options, from always choosing first operand, concatting etc.</description></item><item><title>'sparse_tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</guid><description>The SparseTensor dialect supports all the attributes, types, operations, and passes that are required to make sparse tensor types first class citizens within the MLIR compiler infrastructure. The dialect forms a bridge between high-level operations on sparse tensors types and lower-level operations on the actual sparse storage schemes consisting of pointers, indices, and values. Lower-level support may consist of fully generated code or may be provided by means of a small sparse runtime support library.</description></item><item><title>'spv' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SPIR-V/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SPIR-V/</guid><description>This document describes the design of the SPIR-V dialect in MLIR. It lists various design choices we made for modeling different SPIR-V mechanisms, and their rationale.
This document also explains in a high-level manner how different components are organized and implemented in the code and gives steps to follow for extending them.
This document assumes familiarity with SPIR-V. SPIR-V is the Khronos Group’s binary intermediate language for representing graphics shaders and compute kernels.</description></item><item><title>'tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TensorOps/</guid><description>The tensor dialect is intended to hold core tensor creation and manipulation ops, which are not strongly associated with any particular other dialect or domain abstraction. The primary smoke test of this is ops that make sense for any tensor element type.
We leave it to other dialects to hold the vast swath of possible computations one might want to do on a tensor.
The tensor type is (for better or for worse) used to represent all kinds of things, and supports an open-ended set of element types.</description></item><item><title>'vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Vector/</guid><description>Positioning in the Codegen Infrastructure Components of a Generic Retargetable Vector-Level Dialect Short Description of the Existing Infrastructure LLVM level Hardware Vector Ops Virtual Vector Ops Virtual Vector Rewrite Patterns Virtual Vector to Hardware Vector Lowering Rationale Hardware as vector Machines of Minimum Granularity Transformations Problems Avoided The Big Out-Of-Scope Piece: Automatic Vectorization Bikeshed Naming Discussion DeeperDive Alternatives For Lowering an n-D Vector Type to LLVM Constraints Inherited from LLVM (see LangRef) Nested Aggregate Flattened 1-D Vector Type Discussion Relationship to LLVM matrix type proposal.</description></item><item><title>'x86vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/X86Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/X86Vector/</guid><description>Operation definition x86vector.avx.intr.dp.ps.256 (::mlir::x86vector::DotIntrOp) x86vector.avx.intr.dot (::mlir::x86vector::DotOp) x86vector.avx512.intr.mask.compress (::mlir::x86vector::MaskCompressIntrOp) x86vector.avx512.mask.compress (::mlir::x86vector::MaskCompressOp) x86vector.avx512.mask.rndscale (::mlir::x86vector::MaskRndScaleOp) x86vector.avx512.intr.mask.rndscale.pd.512 (::mlir::x86vector::MaskRndScalePDIntrOp) x86vector.avx512.intr.mask.rndscale.ps.512 (::mlir::x86vector::MaskRndScalePSIntrOp) x86vector.avx512.mask.scalef (::mlir::x86vector::MaskScaleFOp) x86vector.avx512.intr.mask.scalef.pd.512 (::mlir::x86vector::MaskScaleFPDIntrOp) x86vector.avx512.intr.mask.scalef.ps.512 (::mlir::x86vector::MaskScaleFPSIntrOp) x86vector.avx.intr.rsqrt.ps.256 (::mlir::x86vector::RsqrtIntrOp) x86vector.avx.rsqrt (::mlir::x86vector::RsqrtOp) x86vector.avx512.intr.vp2intersect.d.512 (::mlir::x86vector::Vp2IntersectDIntrOp) x86vector.avx512.vp2intersect (::mlir::x86vector::Vp2IntersectOp) x86vector.avx512.intr.vp2intersect.q.512 (::mlir::x86vector::Vp2IntersectQIntrOp) Operation definition x86vector.avx.intr.dp.ps.256 (::mlir::x86vector::DotIntrOp) Interfaces: InferTypeOpInterface, NoSideEffect (MemoryEffectOpInterface)
Effects: MemoryEffects::Effect{}
Operands: Operand Description a vector of 32-bit float values of length 8 b vector of 32-bit float values of length 8 c 8-bit signless integer Results: Result Description res vector of 32-bit float values of length 8 x86vector.</description></item><item><title>Buffer Deallocation - Internals</title><link>https://mlir.llvm.org/docs/BufferDeallocationInternals/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/BufferDeallocationInternals/</guid><description>This section covers the internal functionality of the BufferDeallocation transformation. The transformation consists of several passes. The main pass called BufferDeallocation can be applied via “-buffer-deallocation” on MLIR programs.
Requirements In order to use BufferDeallocation on an arbitrary dialect, several control-flow interfaces have to be implemented when using custom operations. This is particularly important to understand the implicit control-flow dependencies between different parts of the input program. Without implementing the following interfaces, control-flow relations cannot be discovered properly and the resulting program can become invalid:</description></item><item><title>Bufferization</title><link>https://mlir.llvm.org/docs/Bufferization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Bufferization/</guid><description>Overview What is One-Shot Bufferize? Goals of Bufferization Destination-Passing Style Using One-Shot Bufferize Buffer Deallocation Memory Layouts Extending One-Shot Bufferize Debugging Buffer Copies Understanding the SSA Use-Def Chain Analysis Migrating from Dialect Conversion-based Bufferization Bufferization Function Graphs Dialect Conversion-based Bufferization Bufferization&amp;rsquo;s place in a compilation pipeline General structure of the bufferization process Example How to write a partial bufferization pass Other partial bufferization examples How to write a finalizing bufferization pass Changes since the talk Overview Bufferization in MLIR is the process of converting ops with tensor semantics to ops with memref semantics.</description></item><item><title>Builtin Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Builtin/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Builtin/</guid><description>The builtin dialect contains a core set of Attributes, Operations, and Types that have wide applicability across a very large number of domains and abstractions. Many of the components of this dialect are also instrumental in the implementation of the core IR. As such, this dialect is implicitly loaded in every MLIRContext, and available directly to all users of MLIR.
Given the far-reaching nature of this dialect and the fact that MLIR is extensible by design, any potential additions are heavily scrutinized.</description></item><item><title>Chapter 1: Toy Language and AST</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/</guid><description>The Language The AST The Language This tutorial will be illustrated with a toy language that we’ll call “Toy” (naming is hard&amp;hellip;). Toy is a tensor-based language that allows you to define functions, perform some math computation, and print results.
Given that we want to keep things simple, the codegen will be limited to tensors of rank &amp;lt;= 2, and the only datatype in Toy is a 64-bit floating point type (aka ‘double’ in C parlance).</description></item><item><title>Chapter 2: Emitting Basic MLIR</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/</guid><description>Introduction: Multi-Level Intermediate Representation Interfacing with MLIR Opaque API Defining a Toy Dialect Defining Toy Operations Op vs Operation: Using MLIR Operations Using the Operation Definition Specification (ODS) Framework Complete Toy Example Now that we&amp;rsquo;re familiar with our language and the AST, let&amp;rsquo;s see how MLIR can help to compile Toy.
Introduction: Multi-Level Intermediate Representation Other compilers, like LLVM (see the Kaleidoscope tutorial), offer a fixed set of predefined types and (usually low-level / RISC-like) instructions.</description></item><item><title>Chapter 3: High-level Language-Specific Analysis and Transformation</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/</guid><description>Optimize Transpose using C++ style pattern-match and rewrite Optimize Reshapes using DRR Creating a dialect that closely represents the semantics of an input language enables analyses, transformations and optimizations in MLIR that require high-level language information and are generally performed on the language AST. For example, clang has a fairly heavy mechanism for performing template instantiation in C++.
We divide compiler transformations into two categories: local and global.</description></item><item><title>Chapter 4: Enabling Generic Transformation with Interfaces</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/</guid><description>Background: Grappling with an Extensible IR Shape Inference: Preparing for Code Generation Inlining Intraprocedural Shape Inference Background: Grappling with an Extensible IR Through dialects, MLIR allows for the representation of many different levels of abstraction; the Toy dialect that we have previously defined is one such example. Though these different dialects may represent different abstractions, there is often a set of common transformations and analyses that we would like to perform.</description></item><item><title>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/</guid><description>Conversion Target Conversion Patterns Partial Lowering Design Considerations With Partial Lowering Complete Toy Example Taking Advantage of Affine Optimization At this point, we are eager to generate actual code and see our Toy language take life. We will use LLVM to generate code, but just showing the LLVM builder interface here wouldn&amp;rsquo;t be very exciting. Instead, we will show how to perform progressive lowering through a mix of dialects coexisting in the same function.</description></item><item><title>Chapter 6: Lowering to LLVM and CodeGeneration</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/</guid><description>Lowering to LLVM Conversion Target Type Converter Conversion Patterns Full Lowering CodeGen: Getting Out of MLIR Emitting LLVM IR Setting up a JIT In the previous chapter, we introduced the dialect conversion framework and partially lowered many of the Toy operations to affine loop nests for optimization. In this chapter, we will finally lower to LLVM for code generation.
Lowering to LLVM For this lowering, we will again use the dialect conversion framework to perform the heavy lifting.</description></item><item><title>Chapter 7: Adding a Composite Type to Toy</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/</guid><description>Defining a struct in Toy Defining a struct in MLIR Defining the Type Class Exposing to ODS Parsing and Printing Operating on StructType In the previous chapter, we demonstrated an end-to-end compilation flow from our Toy front-end to LLVM IR. In this chapter, we will extend the Toy language to support a new composite struct type.
Defining a struct in Toy The first thing we need to define is the interface of this type in our toy source language.</description></item><item><title>Creating a Dialect</title><link>https://mlir.llvm.org/docs/Tutorials/CreatingADialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/CreatingADialect/</guid><description>CMake best practices TableGen Targets Library Targets CMake best practices Public dialects are typically separated into at least 3 directories:
mlir/include/mlir/Dialect/Foo (for public include files) mlir/lib/Dialect/Foo (for sources) mlir/lib/Dialect/Foo/IR (for operations) mlir/lib/Dialect/Foo/Transforms (for transforms) mlir/test/Dialect/Foo (for tests) Along with other public headers, the &amp;lsquo;include&amp;rsquo; directory contains a TableGen file in the ODS format, describing the operations in the dialect. This is used to generate operation declarations (FooOps.</description></item><item><title>Data Layout Modeling</title><link>https://mlir.llvm.org/docs/DataLayout/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DataLayout/</guid><description>Data layout information allows the compiler to answer questions related to how a value of a particular type is stored in memory. For example, the size of a value or its address alignment requirements. It enables, among others, the generation of various linear memory addressing schemes for containers of abstract types and deeper reasoning about vectors.
The data layout subsystem is designed to scale to MLIR&amp;rsquo;s open type and operation system.</description></item><item><title>Debug Actions</title><link>https://mlir.llvm.org/docs/DebugActions/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DebugActions/</guid><description>Debug Action Debug Action Manager Debug Action Handler Action Specific Handlers Generic Handlers Common Action Handlers This file documents the infrastructure for Debug Actions. This is a DEBUG only API that allows for external entities to control various aspects of compiler execution. This is conceptually similar to something like DebugCounters in LLVM, but at a lower level. This framework doesn&amp;rsquo;t make any assumptions about how the higher level driver is controlling the execution, it merely provides a framework for connecting the two together.</description></item><item><title>Defining Dialect Attributes and Types</title><link>https://mlir.llvm.org/docs/AttributesAndTypes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/AttributesAndTypes/</guid><description>This document describes how to define dialect attributes and types.
LangRef Refresher Attributes Types Attributes and Types Adding a new Attribute or Type definition Class Name Documentation Mnemonic Parameters Traits Interfaces Builders Parsing and Printing Verification Storage Classes Mutable attributes and types Extra declarations Registering with the Dialect LangRef Refresher Before diving into how to define these constructs, below is a quick refresher from the MLIR LangRef.</description></item><item><title>Defining Dialects</title><link>https://mlir.llvm.org/docs/DefiningDialects/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DefiningDialects/</guid><description>This document describes how to define Dialects.
LangRef Refresher Defining a Dialect Initialization Documentation Class Name C++ Namespace Dependent Dialects Extra declarations hasConstantMaterializer: Materializing Constants from Attributes hasNonDefaultDestructor: Providing a custom destructor Discardable Attribute Verification Operation Interface Fallback Default Attribute/Type Parsers and Printers Dialect-wide Canonicalization Patterns C++ Accessor Prefix LangRef Refresher Before diving into how to define these constructs, below is a quick refresher from the MLIR LangRef.</description></item><item><title>Diagnostic Infrastructure</title><link>https://mlir.llvm.org/docs/Diagnostics/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Diagnostics/</guid><description>Source Locations Diagnostic Engine Constructing a Diagnostic Diagnostic Appending arguments Attaching notes InFlight Diagnostic Diagnostic Configuration Options Print Operation On Diagnostic Print StackTrace On Diagnostic Common Diagnostic Handlers Scoped Diagnostic Handler SourceMgr Diagnostic Handler SourceMgr Diagnostic Verifier Handler Parallel Diagnostic Handler This document presents an introduction to using and interfacing with MLIR&amp;rsquo;s diagnostics infrastructure.
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc.</description></item><item><title>Dialect Conversion</title><link>https://mlir.llvm.org/docs/DialectConversion/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DialectConversion/</guid><description>This document describes a framework in MLIR in which to perform operation conversions between, and within dialects. This framework allows for transforming illegal operations to those supported by a provided conversion target, via a set of pattern-based operation rewriting patterns.
Modes of Conversion Conversion Target Recursive Legality Rewrite Pattern Specification Conversion Patterns Type Conversion Type Converter Region Signature Conversion Debugging The dialect conversion framework consists of the following components:</description></item><item><title>Extensible dialects</title><link>https://mlir.llvm.org/docs/ExtensibleDialects/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ExtensibleDialects/</guid><description>This file documents the design and API of the extensible dialects. Extensible dialects are dialects that can be extended with new operations and types defined at runtime. This allows for users to define dialects via with meta-programming, or from another language, without having to recompile C++ code.
Usage Defining an extensible dialect Defining an operation at runtime Using an operation defined at runtime Defining a type at runtime Parsing types defined at runtime in an extensible dialect Using a type defined at runtime Defining an attribute at runtime Parsing attributes defined at runtime in an extensible dialect Using an attribute defined at runtime Implementation details Extensible dialect Operation representation and registration Type representation and registration Usage Defining an extensible dialect Dialects defined in C++ can be extended with new operations, types, etc.</description></item><item><title>Generic DAG Rewriter Infrastructure Rationale</title><link>https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/</guid><description>This document details the rationale behind a general DAG-to-DAG rewrite infrastructure for MLIR. For up-to-date documentation on the user facing API, please look at the main Pattern Rewriting document.
Introduction and Motivation The goal of a compiler IR is to represent code - at various levels of abstraction which pose different sets of tradeoffs in terms of representational capabilities and ease of transformation. However, the ability to represent code is not itself very useful - you also need to be able to implement those transformations.</description></item><item><title>Interfaces</title><link>https://mlir.llvm.org/docs/Interfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Interfaces/</guid><description>MLIR is a generic and extensible framework, representing different dialects with their own attributes, operations, types, and so on. MLIR Dialects can express operations with a wide variety of semantics and different levels of abstraction. The downside to this is that MLIR transformations and analyses need to be able to account for the semantics of every operation, or be overly conservative. Without care, this can result in code with special-cases for each supported operation type.</description></item><item><title>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</title><link>https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/</guid><description>Introduction Positioning Inception Evolution Prior Art Lessons from ONNX Lessons from LIFT Lessons from XLA Lessons from Halide and TVM Lessons from Tensor Comprehensions Lessons from Polyhedral compilers Lessons from the Affine dialect Core Guiding Principles Transformations and Simplicity First Preservation of Information Composable and Declarative Transformations Suitability for Search and Machine Learning Extensibility and Future-Proofness Key Observations Algorithms + Data Structures = Programs The Dialect Need not be Closed Under Transformations Summary of Existing Alternatives a Picture Introduction Positioning This document describes the key design principles that led to the existing implementation of Linalg and aims at exposing the tradeoffs involved when building higher-level Intermediate Representations (IR) and Dialects to facilitate code generation.</description></item><item><title>Linalg OpDSL</title><link>https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/</guid><description>Python based DSL for authoring Linalg op definitions and generating linalg.generic IR based on them for samples.
The Linalg OpDSL is a high level DSL for constructing structured op definitions in a way that can be exported to built-in, named structured ops via YAML-based definitions or used interactively to emit corresponding linalg.generic IR for the composition.
Basic usage The tool is bundled with the MLIR Python bindings. To use from the CMake build tree, MLIR must be build with Python bindings enabled (-DMLIR_ENALBE_BINDINGS_PYTHON=ON).</description></item><item><title>LLVM IR Target</title><link>https://mlir.llvm.org/docs/TargetLLVMIR/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/TargetLLVMIR/</guid><description>This document describes the mechanisms of producing LLVM IR from MLIR. The overall flow is two-stage:
conversion of the IR to a set of dialects translatable to LLVM IR, for example LLVM Dialect or one of the hardware-specific dialects derived from LLVM IR intrinsics such as AMX, X86Vector or ArmNeon; translation of MLIR dialects to LLVM IR. This flow allows the non-trivial transformation to be performed within MLIR using MLIR APIs and makes the translation between MLIR and LLVM IR simple and potentially bidirectional.</description></item><item><title>MLIR : Language Server Protocol</title><link>https://mlir.llvm.org/docs/Tools/MLIRLSP/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tools/MLIRLSP/</guid><description>MLIR LSP Language Server : mlir-lsp-server Supporting custom dialects and passes Features Design Editor Plugins Visual Studio Code This document describes the tools and utilities related to supporting LSP IDE language extensions for the MLIR textual assembly format. An LSP language extension is generally comprised of two components; a language client and a language server. A language client is a piece of code that interacts with the IDE that you are using, such as VSCode.</description></item><item><title>MLIR C API</title><link>https://mlir.llvm.org/docs/CAPI/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/CAPI/</guid><description>Current status: Under development, API unstable, built by default.
Design Many languages can interoperate with C but have a harder time with C++ due to name mangling and memory model differences. Although the C API for MLIR can be used directly from C, it is primarily intended to be wrapped in higher-level language- or library-specific constructs. Therefore the API tends towards simplicity and feature minimalism.
Note: while the C API is expected to be more stable than C++ API, it currently offers no stability guarantees.</description></item><item><title>MLIR Language Reference</title><link>https://mlir.llvm.org/docs/LangRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/LangRef/</guid><description>MLIR (Multi-Level IR) is a compiler intermediate representation with similarities to traditional three-address SSA representations (like LLVM IR or SIL), but which introduces notions from polyhedral loop optimization as first-class concepts. This hybrid design is optimized to represent, analyze, and transform high level dataflow graphs as well as target-specific code generated for high performance data parallel systems. Beyond its representational capabilities, its single continuous design provides a framework to lower from dataflow graphs to high-performance target-specific code.</description></item><item><title>MLIR Python Bindings</title><link>https://mlir.llvm.org/docs/Bindings/Python/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Bindings/Python/</guid><description>Current status: Under development and not enabled by default
Building Pre-requisites CMake variables Recommended development practices Design Use cases Composable modules Submodules Loader Use the C-API Ownership in the Core IR Optionality and argument ordering in the Core IR User-level API Context Management Inspecting IR Objects Creating IR Objects Style Properties vs get*() methods repr methods CamelCase vs snake_case Prefer pseudo-containers Provide one stop helpers for common things Testing Sample FileCheck test Integration with ODS Generating _{DIALECT_NAMESPACE}_ops_gen.</description></item><item><title>MLIR Rationale</title><link>https://mlir.llvm.org/docs/Rationale/Rationale/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/Rationale/</guid><description>This document is intended to capture some of the alternatives considered and open debates in the design of MLIR, along with the rationale for certain decisions we made. This is not intended to be a &amp;ldquo;finely groomed&amp;rdquo; document - we prefer the ability to dump in interesting tidbits without worrying too much about their consistency or readability.
Abstract Introduction and Motivation Design Decisions Loads and stores Symbols and types Block Arguments vs PHI nodes Index type usage and limitations Data layout of non-primitive types Integer signedness semantics Splitting floating point vs integer operations Specifying sign in integer comparison operations Specifying comparison kind as attribute Regions Dialect type extensions Tuple types Assembly forms Examples Non-affine control flow Non-affine loop bounds Reference 2D Convolution Design alternatives and extensions Polyhedral code representation alternatives: schedule lists vs schedules trees vs affine loop/if forms Affine Relations Regions Read/Write/May_Read/May_Write sets for External Functions Memref Extensions affine.</description></item><item><title>MLIR Reduce</title><link>https://mlir.llvm.org/docs/Tools/mlir-reduce/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tools/mlir-reduce/</guid><description>How to Use it Write the script for testing interestingness Available reduction strategies Operation elimination Rewrite patterns into simpler forms Reduce with built-in optimization passes Build a custom mlir-reduce Future works An MLIR input may trigger bugs after series of transformations. To root cause the problem or help verification after fixes, developers want to be able to reduce the size of a reproducer for a bug.</description></item><item><title>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</title><link>https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/</guid><description>The existing documentation about MLIR focuses on long term vision, how its pieces fit together, and the benefits of modular and composable infrastructure in the vast and distant future. While this viewpoint appeals to some, it causes concern for others who are more concerned about the &amp;ldquo;here and now&amp;rdquo; - why does it make sense to make a &amp;ldquo;revolutionary&amp;rdquo; change when any individual problem can be fixed in place?
This document explains that adoption of MLIR to solve graph based problems isn&amp;rsquo;t a revolutionary change: it is an incremental series of steps which build on each other, each of which delivers local value.</description></item><item><title>MLIR: The case for a simplified polyhedral form</title><link>https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/</guid><description>MLIR embraces polyhedral compiler techniques for their many advantages representing and transforming dense numerical kernels, but it uses a form that differs significantly from other polyhedral frameworks.
Disclaimer / Warning
This document is a very early design proposal (which has since been accepted) that explored the tradeoffs of using this simplified form vs the traditional polyhedral schedule list form. At some point, this document could be dusted off and written as a proper academic paper, but until now, it is better to included it in this crafty form than not to.</description></item><item><title>Operation Canonicalization</title><link>https://mlir.llvm.org/docs/Canonicalization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Canonicalization/</guid><description>Canonicalization is an important part of compiler IR design: it makes it easier to implement reliable compiler transformations and to reason about what is better or worse in the code, and it forces interesting discussions about the goals of a particular level of IR. Dan Gohman wrote an article exploring these issues; it is worth reading if you&amp;rsquo;re not familiar with these concepts.
Most compilers have canonicalization passes, and sometimes they have many different ones (e.</description></item><item><title>Operation Definition Specification (ODS)</title><link>https://mlir.llvm.org/docs/OpDefinitions/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/OpDefinitions/</guid><description>In addition to specializing the mlir::Op C++ template, MLIR also supports defining operations and data types in a table-driven manner. This is achieved via TableGen, which is both a generic language and its tooling to maintain records of domain-specific information. Facts regarding an operation are specified concisely into a TableGen record, which will be expanded into an equivalent mlir::Op C++ template specialization at compiler build time.
This manual explains in detail all the available mechanisms for defining operations in such a table-driven manner.</description></item><item><title>Pass Infrastructure</title><link>https://mlir.llvm.org/docs/PassManagement/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PassManagement/</guid><description>Operation Pass OperationPass : Op-Specific OperationPass : Op-Agnostic Dependent Dialects Initialization Analysis Management Querying Analyses Preserving Analyses Pass Failure Pass Manager OpPassManager Dynamic Pass Pipelines Instance Specific Pass Options Pass Statistics Pass Registration Pass Pipeline Registration Textual Pass Pipeline Specification Declarative Pass Specification Tablegen Specification Pass Instrumentation Standard Instrumentations Crash and Failure Reproduction Local Reproducer Generation Passes represent the basic infrastructure for transformation and optimization.</description></item><item><title>Passes</title><link>https://mlir.llvm.org/docs/Passes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Passes/</guid><description>This document describes the available MLIR passes and their contracts.
General Transformation Passes -canonicalize: Canonicalize operations -control-flow-sink: Sink operations into conditional blocks -cse: Eliminate common sub-expressions -inline: Inline function calls -loop-invariant-code-motion: Hoist loop invariant instructions outside of the loop -print-op-stats: Print statistics of operations -sccp: Sparse Conditional Constant Propagation -snapshot-op-locations: Generate new locations from the current IR -strip-debuginfo: Strip debug info from all operations -symbol-dce: Eliminate dead symbols -symbol-privatize: Mark symbols private -view-op-graph: Print Graphviz visualization of an operation Bufferization Passes -buffer-deallocation: Adds all required dealloc operations for all allocations in the input program -buffer-hoisting: Optimizes placement of allocation operations by moving them into common dominators and out of nested regions -buffer-loop-hoisting: Optimizes placement of allocation operations by moving them out of loop nests -buffer-results-to-out-params: Converts memref-typed function results to out-params -finalizing-bufferize: Finalize a partial bufferization -one-shot-bufferize: One-Shot Bufferize -promote-buffers-to-stack: Promotes heap-based allocations to automatically managed stack-based allocations Conversion Passes -arm-neon-2d-to-intr: Convert Arm NEON structured ops to intrinsics -convert-affine-for-to-gpu: Convert top-level AffineFor Ops to GPU kernels -convert-arith-to-llvm: Convert Arithmetic dialect to LLVM dialect -convert-arith-to-spirv: Convert Arithmetic dialect to SPIR-V dialect -convert-async-to-llvm: Convert the operations from the async dialect into the LLVM dialect -convert-bufferization-to-memref: Convert operations from the Bufferization dialect to the MemRef dialect -convert-cf-to-llvm: Convert ControlFlow operations to the LLVM dialect -convert-cf-to-spirv: Convert ControlFlow dialect to SPIR-V dialect -convert-complex-to-llvm: Convert Complex dialect to LLVM dialect -convert-complex-to-standard: Convert Complex dialect to standard dialect -convert-func-to-llvm: Convert from the Func dialect to the LLVM dialect -convert-func-to-spirv: Convert Func dialect to SPIR-V dialect -convert-gpu-launch-to-vulkan-launch: Convert gpu.</description></item><item><title>Pattern Rewriting : Generic DAG-to-DAG Rewriting</title><link>https://mlir.llvm.org/docs/PatternRewriter/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PatternRewriter/</guid><description>Introduction Defining Patterns Benefit Root Operation Name (Optional) match and rewrite implementation Application Recursion Debug Names and Labels Initialization Construction Pattern Rewriter Pattern Application Common Pattern Drivers Dialect Conversion Driver Greedy Pattern Rewrite Driver Debugging Debugging Pattern Filtering Common Pass Utilities This document details the design and API of the pattern rewriting infrastructure present in MLIR, a general DAG-to-DAG transformation framework.</description></item><item><title>PDLL - PDL Language</title><link>https://mlir.llvm.org/docs/PDLL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PDLL/</guid><description>This document details the PDL Language (PDLL), a custom frontend language for writing pattern rewrites targeting MLIR.
Note: This document assumes a familiarity with MLIR concepts; more specifically the concepts detailed within the MLIR Pattern Rewriting and Operation Definition Specification (ODS) documentation.
Introduction Rationale Why build a new language instead of improving TableGen DRR? Why not build a DSL in &amp;ldquo;X&amp;rdquo;? Language Specification Includes Patterns Variables Operation Expression Attribute Expression Type Expression Tuples Constraints Rewriters Introduction Pattern matching is an extremely important component within MLIR, as it encompasses many different facets of the compiler.</description></item><item><title>Quantization</title><link>https://mlir.llvm.org/docs/Quantization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Quantization/</guid><description>This document outlines the design of the MLIR quantization system. While the term &amp;ldquo;quantization&amp;rdquo; is highly overloaded, in this case, it refers to a fairly narrow scope of techniques in use to enable conversion of floating-point computations to corresponding and plausible variants expressed in integer math for inference, as has historically been supported by low-bit depth inference engines such as TFLite, various accelerator hardware, and many DSPs.
Much of this is inspired by the approach taken in this paper with many extensions and adaptations folded in.</description></item><item><title>Quickstart tutorial to adding MLIR graph rewrite</title><link>https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/</guid><description>This document will present a quickstart to adding graph rewrites. We shall start by defining an operation, showing multiple ways to define the rewrite using patterns, as well as defining the rewrite using a graph walker (note: using patterns and the rewrite engine is preferred, showing the walker is for demonstration purposes).
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc. See Table-driven Operation Definition and Declarative Rewrite Rule for the detailed explanation of all available mechanisms for defining operations and rewrites in a table-driven manner.</description></item><item><title>Shape Inference</title><link>https://mlir.llvm.org/docs/ShapeInference/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ShapeInference/</guid><description>Shape inference as discussed here is considered a specific instance of type inference for ShapedType. Type constraints are along (at least) three axis: 1) elemental type, 2) rank (including static or dynamic), 3) dimensions. While some operations have no compile time fixed shape (e.g., output shape is dictated by data) we could still have some knowledge of constraints/bounds in the system for that operation (e.g., the output of a tf.where is at most the size of the input data).</description></item><item><title>SPIR-V Dialect to LLVM Dialect conversion manual</title><link>https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/</guid><description>This manual describes the conversion from SPIR-V Dialect to LLVM Dialect. It assumes familiarity with both, and describes the design choices behind the modelling of SPIR-V concepts in LLVM Dialect. The conversion is an ongoing work, and is expected to grow as more features are implemented.
Conversion can be performed by invoking an appropriate conversion pass:
mlir-opt -convert-spirv-to-llvm &amp;lt;filename.mlir&amp;gt; This pass performs type and operation conversions for SPIR-V operations as described in this document.</description></item><item><title>Symbols and Symbol Tables</title><link>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</guid><description>Symbol Defining or declaring a Symbol Symbol Table Referencing a Symbol Manipulating a Symbol Symbol Visibility With Regions, the multi-level aspect of MLIR is structural in the IR. A lot of infrastructure within the compiler is built around this nesting structure; including the processing of operations within the pass manager. One advantage of the MLIR design is that it is able to process operations in parallel, utilizing multiple threads.</description></item><item><title>Table-driven Declarative Rewrite Rule (DRR)</title><link>https://mlir.llvm.org/docs/DeclarativeRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DeclarativeRewrites/</guid><description>In addition to subclassing the mlir::RewritePattern C++ class, MLIR also supports defining rewrite rules in a declarative manner. Similar to Op Definition Specification (ODS), this is achieved via TableGen, which is a language to maintain records of domain-specific information. The rewrite rules are specified concisely in a TableGen record, which will be expanded into an equivalent mlir::RewritePattern subclass at compiler build time.
This manual explains in detail all of the available mechanisms for defining rewrite rules in such a declarative manner.</description></item><item><title>Tensor Operator Set Architecture (TOSA) Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TOSA/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TOSA/</guid><description>Rationale TOSA and Tensor Level Expressiveness Complete Minimal Numerical Precision TOSA Operator Rationale COND_IF and WHILE_LOOP Using TOSA In A Compiler Quantization Parameters in Ops vs Tensors Operation definitions tosa.abs (mlir::tosa::AbsOp) tosa.add (mlir::tosa::AddOp) tosa.apply_scale (mlir::tosa::ApplyScaleOp) tosa.argmax (mlir::tosa::ArgMaxOp) tosa.arithmetic_right_shift (mlir::tosa::ArithmeticRightShiftOp) tosa.avg_pool2d (mlir::tosa::AvgPool2dOp) tosa.bitwise_and (mlir::tosa::BitwiseAndOp) tosa.bitwise_not (mlir::tosa::BitwiseNotOp) tosa.bitwise_or (mlir::tosa::BitwiseOrOp) tosa.bitwise_xor (mlir::tosa::BitwiseXorOp) tosa.cast (mlir::tosa::CastOp) tosa.ceil (mlir::tosa::CeilOp) tosa.clamp (mlir::tosa::ClampOp) tosa.clz (mlir::tosa::ClzOp) tosa.concat (mlir::tosa::ConcatOp) tosa.</description></item><item><title>Traits</title><link>https://mlir.llvm.org/docs/Traits/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Traits/</guid><description>Defining a Trait Parametric Traits Attaching a Trait Attaching Operation Traits in ODS Using a Trait Operation Traits List AffineScope AutomaticAllocationScope Broadcastable Commutative ElementwiseMappable HasParent IsolatedFromAbove MemRefsNormalizable Single Block Region Single Block with Implicit Terminator SymbolTable Terminator MLIR allows for a truly open ecosystem, as any dialect may define attributes, operations, and types that suit a specific level of abstraction.</description></item><item><title>Transform Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Transform/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Transform/</guid><description>Disclaimer Overview Dialect Extension Mechanism Side Effects Intended Use and Integrations Effects on the Infrastructure Operation definition transform.pdl_match (::mlir::transform::PDLMatchOp) transform.sequence (::mlir::transform::SequenceOp) transform.with_pdl_patterns (::mlir::transform::WithPDLPatternsOp) transform.yield (::mlir::transform::YieldOp) TransformOpInterface (TransformOpInterface) Methods: Fine-grain transformation control dialect
Disclaimer ** Proceed with care: not ready for general use. **
This dialect is evolving rapidly and may change on a very short notice. To decrease the maintenance burden and churn, only a few in-tree use cases are currently supported in the main tree:</description></item><item><title>Understanding the IR Structure</title><link>https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/</guid><description>The MLIR Language Reference describes the High Level Structure, this document illustrates this structure through examples, and introduces at the same time the C++ APIs involved in manipulating it.
We will implement a pass that traverses any MLIR input and prints the entity inside the IR. A pass (or in general almost any piece of IR) is always rooted with an operation. Most of the time the top-level operation is a ModuleOp, the MLIR PassManager is actually limited to operation on a top-level ModuleOp.</description></item><item><title>Usage of 'const' in MLIR, for core IR types</title><link>https://mlir.llvm.org/docs/Rationale/UsageOfConst/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/UsageOfConst/</guid><description>aka, where&amp;rsquo;d const go?
The MLIR data structures that represent the IR itself (Instruction, Block, etc) form a graph-based data structure, and the compiler analyses and passes frequently walk this graph (e.g. traversing from defs to users). The early design of MLIR adopted the const model of LLVM, which is familiar and well understood (even though the LLVM implementation is flawed in many ways).
The design team since decided to change to a different model, which eschews const entirely for the core IR types: you should never see a const method on Operation, should never see the type const Value, and you shouldn&amp;rsquo;t feel bad about this.</description></item><item><title>Writing DataFlow Analyses in MLIR</title><link>https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/</guid><description>Writing dataflow analyses in MLIR, or well any compiler, can often seem quite daunting and/or complex. A dataflow analysis generally involves propagating information about the IR across various different types of control flow constructs, of which MLIR has many (Block-based branches, Region-based branches, CallGraph, etc), and it isn&amp;rsquo;t always clear how best to go about performing the propagation. To help writing these types of analyses in MLIR, this document details several utilities that simplify the process and make it a bit more approachable.</description></item></channel></rss>