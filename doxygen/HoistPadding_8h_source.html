<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: include/mlir/Dialect/Linalg/Transforms/HoistPadding.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MLIR
   &#160;<span id="projectnumber">15.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_5654f77406fb9ceec87e68ef828ceea2.html">mlir</a></li><li class="navelem"><a class="el" href="dir_d07a6fac82475a065a3b2953573f00a0.html">Dialect</a></li><li class="navelem"><a class="el" href="dir_7d4534fbf0715cf3ed7975990f2820c5.html">Linalg</a></li><li class="navelem"><a class="el" href="dir_2bf7b27484b15c8c863e85164c5e8ee5.html">Transforms</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">HoistPadding.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="HoistPadding_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">//===- HoistPadding.h - Hoisting for tensor::PadOp -*- C++ --------------*-===//</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#ifndef MLIR_DIALECT_LINALG_TRANSFORMS_HOISTPADDING_H</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#define MLIR_DIALECT_LINALG_TRANSFORMS_HOISTPADDING_H</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="LogicalResult_8h.html">mlir/Support/LogicalResult.h</a>&quot;</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacemlir.html">mlir</a> {</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="keyword">class </span><a class="code" href="namespacemlir_1_1lsp.html#ad6c31c7b93eb99ad1d173f9b2b97ff7fa689202409e48743b914713f96d93947c">Value</a>;</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00017"></a><span class="lineno"><a class="line" href="namespacemlir_1_1tensor.html">   17</a></span>&#160;<span class="keyword">namespace </span>tensor {</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="keyword">class </span>PadOp;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;} <span class="comment">// namespace tensor</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacelinalg.html">linalg</a> {</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="keyword">class </span>GenericOp;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="comment">/// Mechanically hoist padding operations on tensors by `numLoops` into a new,</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="comment">/// generally larger tensor. This achieves packing of multiple padding ops into</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="comment">/// a larger tensor. On success, `opToHoist` is replaced by the cloned version</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment">/// in the packing loop so the caller can continue reasoning about the padding</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="comment">/// operation. If `transposeVector` is non-empty, hoist padding introduces a</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="comment">/// GenericOp to transpose the padded tensor before inserting it into the packed</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="comment">/// tensor. A `transposeVector` can change the storage order of the padded</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="comment">/// tensor but does not change the order of the pack or compute loops.</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="comment">/// Example in pseudo-mlir:</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment">/// =======================</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="comment">/// If hoistPaddingOnTensors is called with `nLoops` = 2 on the following IR.</span></div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="comment">/// ```</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment">///    scf.for (%i, %j, %k)</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="comment">///      %st0 = tensor.extract_slice f(%i, %k) : ... to tensor&lt;?x?xf32&gt;</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="comment">///      %0 = tensor.pad %st0 low[0, 0] high[...] {</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment">///      ^bb0( ... ):</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="comment">///        linalg.yield %pad</span></div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="comment">///      } : tensor&lt;?x?xf32&gt; to tensor&lt;4x8xf32&gt;</span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="comment">///      compute(%0)</span></div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="comment">/// ```</span></div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="comment">/// IR resembling the following is produced:</span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="comment">/// ```</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="comment">///    scf.for (%i) {</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="comment">///      %packed_init = linalg.init_tensor range(%j) : tensor&lt;?x4x8xf32&gt;</span></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="comment">///      %packed = scf.for (%k) iter_args(%p : %packed_init) {</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="comment">///        %st0 = tensor.extract_slice f(%i, %k) : ... to tensor&lt;?x?xf32&gt;</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="comment">///        %0 = tensor.pad %st0 low[0, 0] high[...] {</span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="comment">///        ^bb0( ... ):</span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="comment">///          linalg.yield %pad</span></div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment">///        } : tensor&lt;?x?xf32&gt; to tensor&lt;4x8xf32&gt;</span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="comment">///        %1 = tensor.insert_slice %0 ...</span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="comment">///            : tensor&lt;4x8xf32&gt; to tensor&lt;?x4x8xf32&gt;</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment">///        scf.yield %1: tensor&lt;?x4x8xf32&gt;</span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment">///      } -&gt; tensor&lt;?x4x8xf32&gt;</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment">///      scf.for (%j, %k) {</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">///        %st0 = tensor.extract_slice %packed [%k, 0, 0][1, 4, 8][1, 1, 1] :</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">///                 tensor&lt;?x4x8xf32&gt; to tensor&lt;4x8xf32&gt;</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment">///        compute(%st0)</span></div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;<span class="comment">///      }</span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment">///    }</span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment">/// ```</span></div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="comment"></span><a class="code" href="classmlir_1_1FailureOr.html">FailureOr&lt;Value&gt;</a> <a class="code" href="namespacemlir_1_1linalg.html#ab376def4934ea3c7c17ce7c9da600a39">hoistPaddingOnTensors</a>(</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    tensor::PadOp opToHoist, <span class="keywordtype">int</span> numLoops, <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> transposeVector,</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    tensor::PadOp &amp;hoistedOp, <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;GenericOp&gt;</a> &amp;transposeOps);</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;} <span class="comment">// namespace linalg</span></div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;} <span class="comment">// namespace mlir</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="preprocessor">#endif // MLIR_DIALECT_LINALG_TRANSFORMS_HOISTPADDING_H</span></div><div class="ttc" id="namespacemlir_html"><div class="ttname"><a href="namespacemlir.html">mlir</a></div><div class="ttdoc">Include the generated interface declarations. </div><div class="ttdef"><b>Definition:</b> <a href="LocalAliasAnalysis_8h_source.html#l00020">LocalAliasAnalysis.h:20</a></div></div>
<div class="ttc" id="classllvm_1_1SmallVectorImpl_html"><div class="ttname"><a href="classllvm_1_1SmallVectorImpl.html">llvm::SmallVectorImpl</a></div><div class="ttdef"><b>Definition:</b> <a href="Support_2LLVM_8h_source.html#l00061">LLVM.h:61</a></div></div>
<div class="ttc" id="classllvm_1_1ArrayRef_html"><div class="ttname"><a href="classllvm_1_1ArrayRef.html">llvm::ArrayRef</a></div><div class="ttdef"><b>Definition:</b> <a href="Support_2LLVM_8h_source.html#l00044">LLVM.h:44</a></div></div>
<div class="ttc" id="classmlir_1_1FailureOr_html"><div class="ttname"><a href="classmlir_1_1FailureOr.html">mlir::FailureOr</a></div><div class="ttdoc">This class provides support for representing a failure result, or a valid value of type T...</div><div class="ttdef"><b>Definition:</b> <a href="LogicalResult_8h_source.html#l00077">LogicalResult.h:77</a></div></div>
<div class="ttc" id="namespacelinalg_html"><div class="ttname"><a href="namespacelinalg.html">linalg</a></div></div>
<div class="ttc" id="namespacemlir_1_1lsp_html_ad6c31c7b93eb99ad1d173f9b2b97ff7fa689202409e48743b914713f96d93947c"><div class="ttname"><a href="namespacemlir_1_1lsp.html#ad6c31c7b93eb99ad1d173f9b2b97ff7fa689202409e48743b914713f96d93947c">mlir::lsp::CompletionItemKind::Value</a></div></div>
<div class="ttc" id="namespacemlir_1_1linalg_html_ab376def4934ea3c7c17ce7c9da600a39"><div class="ttname"><a href="namespacemlir_1_1linalg.html#ab376def4934ea3c7c17ce7c9da600a39">mlir::linalg::hoistPaddingOnTensors</a></div><div class="ttdeci">FailureOr&lt; Value &gt; hoistPaddingOnTensors(tensor::PadOp opToHoist, int numLoops, ArrayRef&lt; int64_t &gt; transposeVector, tensor::PadOp &amp;hoistedOp, SmallVectorImpl&lt; GenericOp &gt; &amp;transposeOps)</div><div class="ttdoc">Mechanically hoist padding operations on tensors by numLoops into a new, generally larger tensor...</div><div class="ttdef"><b>Definition:</b> <a href="HoistPadding_8cpp_source.html#l00397">HoistPadding.cpp:397</a></div></div>
<div class="ttc" id="LogicalResult_8h_html"><div class="ttname"><a href="LogicalResult_8h.html">LogicalResult.h</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed May 4 2022 20:32:52 for MLIR by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
